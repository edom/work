#+TITLE: On remote viewing
#+DATE: 2019-09-07 00:00:00 +0700
#+PERMALINK: /remote-viewing.html
* Introduction
The USA government/military spent /tens of millions of dollars and tens of years/ on remote viewing.
The best thing about it is that /you do not have to believe anything/; just strictly follow the protocols.
The existence of protocols means that it is replicable, and thus it merits scientific investigation.
* On Ingo Swann
Why did he use the term "bio-mind" instead of just "mind"?
Did he knew of "non-bio-minds", such as artificial intelligence?

I should summarize his writings.
I find his writing wordy and jumpy.

Important: Carole K. Silfen's experiments with Ingo Swann,
that shows that remote viewing happens from a /point/ in space.

Google Search returns nothing for Carole Silfen!
What the hell happened to this person!?
* On remote viewing
STAR GATE documents
http://www.remoteviewed.com/star-gate-documents/

Reddit
https://www.reddit.com/r/remoteviewing/

There is evidence of remote viewing, although perhaps one has to experience it himself.

There is a protocol for remote viewing.
It is /reproducible/.
Thus it is a scientific experiment.

Joe McMoneagle 2000 book \cite{mcmoneagle2000remote}.

Russell Targ, in his 2012 book \cite{targ2012reality}, advises us to think twice before enrolling in /expensive/ remote-viewing schools:

#+BEGIN_QUOTE
I believe there is presently no evidence that there is any benefit to paying thousands of dollars to attend any such remote-viewing school—as compared with reading this book or Ingo Swann’s wonderful book "Natural ESP".
But I could be wrong.
The claims many of these schools make are confusing to the public, as implied by their very names—Controlled Remote Viewing (CRV®), Extended Remote Viewing (ERV®), and Technical Remote Viewing (TRV®), for example.
Joe McMoneagle, who was one of the first, and by far the most successful of the army viewers, has also written an excellent book, "Remote Viewing Secrets", in which he unscrambles these acronyms.
He also describes a very clear and sensible approach to learning remote viewing, based on his more than thirty years of experience.
\cite{targ2012reality}
#+END_QUOTE

I find Buchanan 2009 \cite{buchanan2009seventh} to be more comprehensive than McMoneagle 2000 \cite{mcmoneagle2000remote} or Targ 2012 \cite{targ2012reality}.

<2019-09-16>
I'm trying remote viewing.
I think my accuracy so far, as a total newbie, out of about 5 trials, is below 10%.

Remote viewing has been used for psychic archeology.[fn::<2019-09-13> The History of Psychic Archeology with Stephan A. Schwartz https://www.youtube.com/watch?v=KwcEyflmaxk]
Stephan A. Schwartz seems to have some strong evidence for remote viewing, with archeological flair.
It seems promising.
Project Deep Quest.[fn::<2019-09-13> Project Deep Quest with Stephan A. Schwartz https://www.youtube.com/watch?v=WH4i7Z4JwPA]

More recent, 2004, Courtney Brown, "Scientific Remote Viewing", a protocol[fn::https://farsight.org/SRV/SRVManualByCourtneyBrown.pdf]

International Remote Viewing Association[fn::https://www.irva.org/remote-viewing/howto.html].

It seems remote viewers undergo some spiritual changes.

If the issue is the bandwidth (transfer rate) between the conscious and the subconscious,
then it should be easiest to train with smell and taste first,
with the senses that evolved first.
Then, it should be easy to discern between light and dark ambience, but not the visual details.
Then, color, heat, pressure, and so on.
Sight contains lots of information.
A lot of things enter our eyes, then the brain ignores a lot of them, but there is still a lot of information at our focal point.

But my experiment is inconclusive;
I remote-viewed poorly with smell, taste, or sight;
I think relaxation is more important than choice of the senses?

Perhaps the state of relaxed focus is like Cziksenmihaly's state of flow; as a computer programmer, I am familiar with this state.
* On remote-viewing target pools
Joe McMoneagle \cite{mcmoneagle2000remote} stressed the importance of /target pools/.

What we call "target pool", machine-learning researchers call "dataset".
On <2019-09-16>, an idea comes to me:
Perhaps we can reuse machine-learning datasets for remote-viewing!
For example, the datasets for "Object detection and recognition"[fn::<2019-09-16> https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Object_detection_and_recognition]
such as Caltech 101 (101 categories, 40--800 images per category, 126 MB)[fn::<2019-09-19> http://www.vision.caltech.edu/Image_Datasets/Caltech101/]
and Caltech 256 (30607 images, 256 categories, 1.2 GB)[fn::<2019-09-19> http://www.vision.caltech.edu/Image_Datasets/Caltech256/].
But those datasets are not ideal; they have many complex images that mix several objects.

We can search and download some photos for personal use.
I go to Google Images, search some common objects, and download some images.

However, if we train with photos, wouldn't that train the visual system disproportionately and atrophy the other senses?

We need hundreds of diverse-but-isolated targets.
* On the ideal training targets for beginners
Targ 2010, chapter 3, section "Choosing target objects" \cite{targ2010limitless} recommends (emphasis mine):
#+BEGIN_QUOTE
[...]
The target object should be /bigger than a matchbox and smaller than a bread box/.
It should be visually interesting and have /describable parts/, rather than being compact.
That is, a Raggedy-Ann doll or a teacup with a handle is easier to describe than an ivory Buddha figurine or a tennis ball.
A pineapple would be easier to describe than a peach.
A hairbrush is better than a nail file.
[...]
It’s also best to /avoid using a target object that might be perceived as frightening or distasteful to the viewer/.
This is an important point, since you would not want to violate your viewer’s unconditional trust of you or the process.
#+END_QUOTE

In short, I think that the ideal image for a newbie remote viewer should
be /convenient for someone to hold with his hands/ and be /simple to sketch/.
* On the theory of remote viewing
The theory so far is that, by quieting the mind, and relaxedly focusing the attention on the target,
sometimes vague signals surface from the cosmic consciousness to the viewer's conscious mind.

"A suggested remote viewing training procedure"[fn:: https://www.cia.gov/library/readingroom/document/cia-rdp96-00789r002200070001-0] (CIA Project Stargate FOIA archive).
It contains a model (an explanatory hypothesis) of how remote viewing might work.
It is written in plain language.

Is meditation thinking or feeling?

René Warcollier's "Mind to mind"?

I think we should first learn what we know about remote viewing[fn::<2019-09-18> Targ & Ketra, "What We Know About Remote Viewing" http://www.espresearch.com/espgeneral/WhatWeKnow.shtml],
and begin with free-response remote viewing.
Free-response does not mean anything goes; there is still a /protocol/ to follow to prevent contamination.
* On indirect remote viewing
Is /reverse remote viewing/ possible?
In forward remote viewing, from an address, we perceive the object referred to by the address.
In reverse remote viewing, from a photo, we find out where the photo was taken.

But isn't reverse remote viewing just forward remote viewing whose address is the photo and whose object is the address where the photo was taken?

/Associative remote viewing/ can be used to ask multiple-choice questions about the future.

Targ et al. used /associative/ remote viewing for financial prediction,
because it is hard to remote-view anything /analytical/ such as numbers, letters, etc.
 [fn::<2019-09-16> 3:27 Precognitive Financial Forecasting with Russell Targ https://www.youtube.com/watch?v=bQK0oHP94x4]
Why is that?
Why is it hard to remote-view left-brain stuff?
Are there psychic people without right hemisphere?
What is Sperry's split-brain experiment trying to tell us?[fn::https://www.psychologytoday.com/intl/blog/consciousness-self-organization-and-neuroscience/201802/no-you-re-not-left-brained-or-right]
Why does it seem that people without corpus callosum cannot verbally describe the things in their left visual field?
Douglas Dean et al. (in "Executive ESP" book) found that CEOs of profitable companies have more precognitive abilities than the CEOs of non-profitable companies do.
Rauscher & Targ 2006 proposes a "complex Minkowski space"\cite{rauscher2006investigation},
a generalization of the Minkowski space in Einstein's general relativity theory.

But, in the same book \cite{targ2012reality}, Targ claims that Ingo could "read the code words written on the file cabinets".
Perhaps it's because it was so hidden that it became so clear in the psychic space; that is what Targ reports Pat Price said.

#+BEGIN_QUOTE
When the two CIA agents who came to investigate asked why he had so accurately described the “incorrect” location, Pat said,
“The more intent you are on hiding something, the more it shines like a beacon in psychic space.”
\cite[p. 82]{targ2012reality}
#+END_QUOTE

Psychic stock pickers, gamblers, or lottery winners?

One can use remote viewing to profit from the financial market.
 [fn::<2019-09-11> 60% success rate is not an exorbitant claim; 17-month study; brochure for a 2005 workshop http://www.espresearch.com/JAN05ARVBrochure.pdf]
 [fn::<2019-09-11> SSE Talks - Remote viewing the Stock Market - Christopher Carson Smith https://www.youtube.com/watch?v=K3x5QHD7Ewo]
However, it would be more convincing if the study lasted
/tens of years/ through several economic cycles and crises instead of only 17 months.

But what about the Efficient Market Hypothesis?
What if all financial traders are psychic with 100% accuracy?
What if all relevant future events are known and certain,
and the price takes into account all of those future events?
Will the price the constant?
If everyone knew that, exactly 123,456 days later, the biggest oil pipeline will experience an inevitable catastrophe with certain probability,
then what would the price of oil be?

There is a /genealogy/ of remote viewing methods.
 [fn::<2019-09-16> http://www.remoteviewed.com/methodshistorymap.html]
 [fn::<2019-09-16> http://www.remoteviewed.com/remote-viewing-methods/]
* Remote viewing self-training protocol?
Can you simultaneously play the role of the viewer and the monitor?

How do we distinguish conscious noise (mental noise, "interpretative overlay", now called "analytical overlay") from remote-perception signal?

The conscious mind interferes with its imagination.

Perhaps the aim of meditation is to /feel/ that we are not our conscious minds.
It is as if we were trying to look at ourselves from a third person point of view.

My hypothesis is that remote viewing experts are able to quickly relax their brains;
perhaps they are able to quickly switch into and out of "theta state"?

Information comes in as short bursts (less than 1 second) of vague signals, not as a smooth sailing experience.
Why is that?
** An imperfect protocol for remote viewing self-training using Google Maps
Open Google Maps in your browser.

Pick any city in the world.
It is better to pick cities you are not familiar with.
For example: another city in your country, or a city outside your country.

Adjust the zoom level such that you can see road names and some landmarks but not detailed buildings.

Drag the Street View guy to see roads that have Street View photos, but drop the guy back in the toolbar he came from;
don't drop the guy on any road.
While you are dragging the Street View guy,
the roads with Street View will be highlighted in blue.

Cover the bottom part that shows preview photo.

Click on any point on any road that has Street View.
Note the pair of coordinates in the search box.
The pair of coordinates is the /identifier/.
This identifier should be thought of referring to a Google Street View photo,
not the real location on Earth where the photo was taken.
We are interested in the photo itself, not in the location where it was taken.

Hide the browser window, such as by Alt+Tab-ing to another maximized window.
You can now release your hand.

Remote view the target photo at the time the Street View photo was taken.
Note that you want to remote-view the photo itself and not the actual location on Earth where the photo was taken.

Click the lower photo on the left sidebar to open Street View at that point.

Compare your remote viewing result and the Street View photo.

Repeat the exercise as many times as desired.

Note that this protocol is not perfect for training.
The data pool is somewhat predictable, and some information leaks:
You know there will be a road in the photo,
and it seems that all Street View photos are taken at noon.
But, from this, can you learn to tell apart between
the roads that come from your imagination and the roads that come from your subconscious?

It seems focusing on the photo does not work;
perhaps we should focus on the actual location.

This protocol is bad.
It is too easy to accidentally click on something,
and a photo pops up,
and it contaminates your mind.
** Self-training remote viewing using machine learning datasets?
* Bibliography

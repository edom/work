#+TITLE: Computation
#+DATE: 2017-06-29 22:40 +0700
#+PERMALINK: /compute.html
#+MATHJAX: yes
* What is computation?
Here we analyze the meaning of computation in everyday usage.
Then we formalize a computation model as a logical structure.
Then we define what it means to compute a function with respect to that model.
** What are computers, machines, automatons, robots?
In 1640, a /computer/ is a human calculator.[fn:eocomputer:https://www.etymonline.com/word/computer]
In 1897, a computer is a mechanical calculator.[fn:eocomputer]
In 1945, a computer is an electronic calculator.[fn:eocomputer]
All those computers ran approximation algorithms to generate look-up tables of values of transcendental functions.
There are also /analog computers/ made with operational amplifiers[fn::https://en.wikipedia.org/wiki/Operational_amplifier],
as opposed to /digital computers/ made with logic gates[fn::https://en.wikipedia.org/wiki/Logic_gate].
Both analog and digital computers are made with transistors,
but analog computers operate the transistors outside the saturated region,
whereas digital computers operate the transistors in the saturated region.
Analog to digital is knob to switch, that is, continuous to discrete.
Analog computers use transistors as amplifiers.
Digital computers use transistors as switches.
However, as we build stronger computers, we begin trying to simulate reality,
and we wonder whether the Universe is just an extremely powerful computer.
Some time in the 1970s, a computer is a desktop computer,
calculation gained a numerical connotation,
and a calculator is a computer specialized for numerical problems,
and thus calculation is numerical computation,
and a human calculator is a human who can mentally manipulate digits quickly and correctly.
The world progressed explosively,
despite being built on increasingly complex computer systems with ever-more undefined behaviors,
occasionally killing people.
However, modernization does not change the nature of computation:
finite, discrete, sequential, precise, algorithmic.

In 1540, a /machine/ is any structure or device.[fn:eomachine:https://www.etymonline.com/word/machine]
The word "machine" may have come from a Proto-Indo-European word that means "that which enables".[fn:eomachine]
Some machines are /programmable/.
Such machine implements several functions that can be chosen by a /program/ which is a part of the machine's input.
The program chooses which function the machine shall compute.

In 1610, an /automaton/ is a self-acting machine.[fn::https://www.etymonline.com/word/automaton]
Thus an automaton has an energy source or is connected to an energy source that enables the automaton to run with minimal human intervention.

In 1923, the English word "robot" came from the Czech word "robotnik" that means "forced worker".[fn::https://www.etymonline.com/word/robot]

Reversible computation relates erasure of information, entropy, and heat.
** What is an algorithm?
In 1690, an /algorithm/ is an Arabic system of computation.[fn::https://www.etymonline.com/word/algorithm]
It is the historically-and-interculturally mangled name of Muhammad ibn Musa al-Khwarizmi[fn::https://en.wikipedia.org/wiki/Muhammad_ibn_Musa_al-Khwarizmi] who lived in the 8th century.
An /algorithm/ is a finite description of how a computer computes something.
In the medievals, an algorithm is a numerical approximation scheme to be run by humans.
Anyone who knows basic arithmetics can mindlessly carry out an algorithm
and produce a correct answer without any understanding of why or how the algorithm works.

An algorithm restates a function as a composition of /primitives/.

Some note about ontology:
The long addition algorithm does not describe how to add two numbers \(x\) and \(y\).
It describes how to manipulate two /representations/ \(e(x)\) and \(e(y)\) in order to produce a third representation \(e(x+y)\)
that represents the sum of \(x\) and \(y\).

An approximation scheme describes a number iff the sequence of approximations converges to the number.
The approximation may never reach the number, but it always gets closer.
** What is to compute something?
*** The subjects and objects of the verb "compute"
The transitive verb "compute" takes a mathematical object.
For example, it makes sense to compute a mathematical expression, but it does not make sense to compute a dining chair.

The subject of "compute" is a physical object that has material existence.
A machine computes something.
Some animals can count[fn::http://www.bbc.com/future/story/20121128-animals-that-can-count],
and counting is a computation.
Thus some animals can compute.

An algorithm describes how to compute something,
but does not compute what is described,
because such algorithm has no material existence.

A machine simply acts according to the laws of physics, but we interpret some of such acts as a computation.
This implies that a computation is what we think a physical system does, not what the system actually does.
Thus, /a computation is a discrete sequential model of what some physical systems do/.
Computation is our way of thinking about what the machine does.
We invent the concept of computation because we are eager to see patterns everywhere even when there are none.
Our understanding of computation enables us to manipulate machines into doing what we want.

Computation is a model, and thus has no material existence.
What exist materially are machines acting according to the laws of physics.
*** Terminating and non-terminating computations
A machine "computes \(y\) from \(x\)" iff
the machine ends with a representation of \(y\) if the machine is started with a representation of \(x\).
Alas, this definition has two big problems:
- Must a computation be /started/ by something outside the computer?
- What is /representation/?

A computation may not end.
A Turing machine may compute without terminating.[fn::https://math.stackexchange.com/questions/1561293/must-an-algorithm-terminate]
 [fn::"An example of a non-terminating Turing machine program is a program that calculates sequentially each digit of the decimal representation of pi"
 http://www.alanturing.net/turing_archive/pages/reference%20articles/what%20is%20a%20turing%20machine.html]
For example, a machine may compute 2/3 (whose binary expansion 0.10... does not terminate) by repeatedly printing 10 forever.

(In this document, I always use "may" in the epistemic sense, and never in the deontic sense[fn::https://english.stackexchange.com/questions/189974/why-do-they-say-may-not-for-things-which-people-shouldnt-do].
Thus "may not" and "does not have to" have the same meaning.)
*** Computing a function
A machine "computes the function \(f:D\to C\)" iff, for each \(x\in D\), the machine computes \(f(x)\) from \(x\).
But a mathematical function may be infinite, whereas a machine is finite.
We often ignore ontology and say that a machine computes the function \(f\) to mean that the machine computes an interesting /finite subfunction/ of \(f\).
No machine can manipulate /every/ number, because there is always a number that is too big to physically represent.
It is physically impossible to manipulate extremely big natural numbers.
For example, no machine truly implements the addition of every possible two natural numbers, because it is physically impossible.
We can /describe/ an extremely large number, but we can only visually imagine five to nine things.

What is a function?
We must distinguish relations and expressions.
Which of these is a function: \(\{(0,1),(1,2),\ldots\}\) or \(x \mapsto x+1\)?
Neither.
A function \(f : D \to C\) is a /triple of sets/ \((D,C,F)\) where \(F \subseteq D \times C\),
and \(f(x)=y\) means \((x,y) \in F\),
and \(\forall x \forall y ( x = y \to f(x) = f(y) )\).

See also Rapaport 2005 \cite{rapaport2005philosophy}, section 2.3.1 ("What is a function?") and its descendants, from page 236.
*** What can be computed?
A machine "computes the set \(D\)" iff, for each \(x \in D\), the machine /can/ determine the truth of \(r(x) \in R(D)\),
where \(r\) is the computation's encoding scheme, and \(R(D) = \{ r(x) ~|~ x \in D \}\).

A machine "computes the (infinite) sequence \(x\)" iff the machine computes every finite prefix of \(x\).
That means: given ever-longer time to run, the machine computes an ever-longer prefix of the sequence.
Thus, a computation does not have to end; it may run forever.
The sequence \(x\) can be identified by the function \(f : \Nat \to A\), in the way \(x_k = f(k)\).

Turing 1937 \cite{turing1937computable} defines a computable number as a number whose digits can be generated by a machine.
Thus, to compute a number is to compute the sequence of its digits, using an algorithm (a finite description).

A machine that /generates/ a sequence computes something from /nothing/.

What does an operating system compute?

Piccinini distinguishes abstract computation and concrete computation \cite{sep-computation-physicalsystems}.

Defining computation as the execution of an algorithm raises difficult issues \cite{scheutz2006computation}.

Rapaport's very thick 2005 book \cite{rapaport2005philosophy} deals with things in the layer below the layer we work at.

Does a quantum computation consist of discrete steps?

Immerman 1999 \cite{Immerman99descriptivecomplexity}, in Definition 2.4 (page 25),
defines what it means for a Turing machine to compute a query.
** Computation, our explanation, and objective reality
A computation is our /explanation/ of what a machine does.
We invented the concept of computation so that we can exploit machines.
If machine A computes Y from X, and machine B computes Z from Y,
then the machine built from those machines computes Z from X.

However, if objective reality exists, then the machine will still compute,
regardless of whether we exist to describe what the machine does.
** Undoing chronic ontological sloppiness
First, we undo the chronic ontologically-sloppy habit of conflating a thing and a representation of the thing.
"123" is not a number, but a /representation/ of a number.
We cannot manipulate numbers physically because they do not have material existence.
We can only manipulate the physical representations of those numbers.
When we "add two numbers", we are actually manipulating the representations of those numbers in a way that corresponds to adding those numbers.
Formally, if \(e : \Nat \to \{0,1\}^*\) is an encoding scheme, then
\( e(x+y) = e(x) +_e e(y) \), where \(+\) is the operation that we think we do, and \(+_e\) is the operation that we actually do.
We think we are adding numbers, but we are actually writing symbols on paper or juggling symbols in our mind.

Then, we un-conflate a program and a machine running the program.
A program does not /compute/; it is the machine that computes.
A program cannot do anything on its own; a machine has to run it.
When we say "a program computes a function",
we actually mean that running the program on the machine causes
the machine to compute that function.

Unfortunately, the ontologically correct thing is very wordy,
so I write in conflated manner.
For example, when I write "this program adds two numbers",
what I really mean is
"running the program causes the machine to manipulate two representations in a way that corresponds to adding two numbers".
Fortunately, the only time we have to care about this ontological issue is when we are talking about the foundations of computation.
** Digressions
*** Genus-differentia definition of computation?
A computation is (what) that (what)?

Process? Activity? Mechanism?

A program describes the computation performed by a machine.
A program modulates the machine.
Manipulates computational resources to compute something.
*** Computation as information transformation
Computation is answering a question.

What is the relationship between computation and answering questions?

A computer reduces information?
Transforms information?

Computation is transformation of information?
*** Computation as model/concretion?
Computation is running a program on a machine.

It seems that the defining feature of computation is conditional and repetition.

Program is a model.
*** Diving into philosophy of computation
Ian Horswill wrote an introductory article "What is computation?"[fn::http://www.cs.northwestern.edu/~ian/What%20is%20computation.pdf].
*** Machine
A /machine/ is a tool that /computes/ what the machine is designed for.
A machine has material existence.
It is a physical implement.

Digression:
In [[file:philo.html]], I write that a machine is a tool, that is something that we use to extend our self (what we control).
*** Even more historical?
Leibniz used the term "calculation"?
Turing used "effective calculability" to mean "algorithmic"?
Computation is calculation? It's just following rules?
* What is computation theory?
Computation theory spans philosophy, physics, and mathematics.
The mathematics part[fn::https://en.wikipedia.org/wiki/Theory_of_computation] studies logical models of computation, not computation itself.
Which part of computation theory are we interested in?
This document is mostly the mathematics part, because there is a one-million-dollar prize for solving the P vs NP problem.
See Piccinini 2017 \cite{sep-computation-physicalsystems} if you are interested in the philosophy and physics parts.

1999 Immerman \cite{Immerman99descriptivecomplexity},
2009 Arora & Barak \cite{Arora2009},
2009 Marek & Remmel \cite{Marek2009},
2002 Boolos, Burgess, & Jeffrey \cite{Boolos2002},
1987 Rogers \cite{Rogers1987}.

Where are the researchers?
There is ACM Special Interest Group on Logic and Computation (SIGLOG)[fn::https://siglog.acm.org/about/].
There is also Computational Complexity Conference[fn::http://www.computationalcomplexity.org/].

We can think of computation theory as refining these hierarchies:
automaton power hierarchy[fn::https://en.wikipedia.org/wiki/Automata_theory],
problem complexity hierarchy,
logic strength hierarchy,
Chomsky language hierarchy[fn::https://en.wikipedia.org/wiki/Chomsky_hierarchy],
arithmetical hierarchy[fn::https://en.wikipedia.org/wiki/Arithmetical_hierarchy],
formal system power hierarchy[fn::https://en.wikipedia.org/wiki/Reverse_mathematics#The_big_five_subsystems_of_second-order_arithmetic],
and so on.
They are related to each other.
We want to find out which feature gives which power.

What is the difference between descriptive complexity theory and implicit complexity theory[fn::http://www.cs.unibo.it/~martini/BISS/martini-1.pdf]?
* What is computer science?
Rapaport 2005 \cite{rapaport2005philosophy} surveys various definitions and their problems.
It summarizes the discussion in page 154 (3.15.4 Conclusion).

Computer science[fn::https://en.wikipedia.org/w/index.php?title=Computer_science&oldid=875563283#Etymology]
is not science (the application of the scientific method to make falsifiable theories).

Scott Schneider defines "computer science" as "everything to do with computation, both in the abstract and in the implementation".
 [fn::http://www.scott-a-s.com/cs-is-not-math/]
Is CS a branch of math?
 [fn::https://math.stackexchange.com/questions/649408/is-computer-science-a-branch-of-mathematics]

If science is simply a synonym of "knowledge", then computer science is a synonym of "computer knowledge".
* The mathematics part
There are many computation models[fn::https://en.wikipedia.org/wiki/Model_of_computation].
All of them imply some /operating conditions/:
there are no electrical disruptions, fires, cosmic rays, and so on.
All of them also imply a sequence of operations.

We often assume that the computation model is a Turing machine.
But, ontologically, a Turing machine is a computation model, not a machine,
and thus should be called a Turing model.

A /computation model/ is a formal system that represents the relevant aspects of the internal states of a computing machine.

Now we define "to compute the function \(f : D \to C\)" with respect to the computation model \((D,C,S,d,c,t)\) where
\(d : D \to S\), and
\(c : C \to S\), and
\(t\) has arity \((S,S)\).
The computation model is a three-sorted structure.
The functions \(d\) and \(c\) together bridge two things:
(1) our high-level thought of the machine computes, and
(2) the logical system that abstracts the machine's internal state and computation.
Let \(S\) be the computation model's domain of discourse, that is, the set of each mathematical object that is a simplified representation of a machine internal state.
Let \(t\) be a relation symbol of arity 2.
The relation \(t\) represents the state transition relation.
Define the transitive closure of \(t\) as \(T(x,y) = (TC(t))(x,y) = t(x,y) \vee \exists z (t(x,z) \wedge T(z,y))\)
where \(TC\) is the transitive-closure operator.

Machine \(M\) computes function \(f : D \to C\) according to computation model \((D,C,S,d,c,t)\) iff
\[
compute(M,f) = \forall x : T(d(x), c(f(x)))
\]

We can focus on the computation model, and focus on the substructure \((S,t)\) instead.

A machine /computes/ the function \(f : D \to C\) according to the computation model \((S,c,d,t)\), iff,
for all \(x \in D\), it is true that \(T(d(x),c(f(x)))\), that is, the machine starts at state \(d(x)\) and finishes at state \(c(f(x))\).

A /computation model/ is a logical system that has a domain of discourse representing machine internal state,
and has an arity-2 relation symbol \(t\) representing the state transition relation.

TODO \cite{vardi1998computational}
** Encoding scheme
Now we define encoding.

An encoding is a representation of something.
A representation is not the represented, but a representation behaves in the way the represented does.
Formally, an /encoding scheme/ is a computable bijective function \(e : D \to A^*\) where \(A\) is an alphabet.
Thus, an encoding scheme is an /algorithm/ that describes a bijective function.

If "algorithm" and "encoding scheme" depend on each other,
then there is only one logical conclusion:
/Algorithm and encoding-scheme are the same thing./
** Computable, algorithm, finite description
Function $f$ is /computable/ by formal system $S$ iff $S$ has a /finite description/ of $f$.

An /algorithm/ solves a /problem/.
A problem can be solved by many algorithms with different resource usage characteristics.

An algorithm is a finite description of what a machine is supposed to do.
** Is computation inherently sequential? Computation as sequence of steps
In a Turing machine, a step is a state transition
that consists of reading the tape cell,
writing the tape cell,
moving the tape head,
and changing the internal state.
In $\lambda$-calculus,
a step is a $\beta$-reduction
of an expression composed from more primitive subexpressions.
These examples suggest that we can define computation as a /sequence/ of steps.

Each of those models is a special case of deciders.
** Logic, model
See [[file:logic.html]].
** Problem, formula, input, output, model, relation
"Problem" comes from Greek "problema" which means "a task, that which is proposed, a question".[fn::https://www.etymonline.com/word/problem]
Therefore, a problem /is/ a question, or, formally, a /logical formula/.

/A problem is a formula./
For example, the problem "Given an \(x\), what is \(x+x\)?" is the formula
\( x+x = y \) in first-order logic with equality and some arithmetics.
Note that some logic is embedded in English.[fn::English is at least second-order, as demonstrated by the Geach--Kaplan sentence "Some critics admire only one another" https://en.wikipedia.org/wiki/Nonfirstorderizability].

#+CAPTION: Some common problem shapes
| name             | shape          | input | output |
|------------------+----------------+-------+--------|
| decision problem | \( p(x) \)     | \(x\) |        |
| search problem   | \( p(x) \)     |       | \(x\)  |
| function problem | \( f(x) = y \) | \(x\) | \(y\)  |

A problem may have /inputs/ and /outputs/.
An /input/ of a problem is a free variable in the formula.
An /output/ of a problem is a free variable in the formula.

Another example: the problem "Is the sum of two even numbers even?" is the formula \( E(x) \wedge E(y) \to E(x+y) \).

What does it mean to solve a problem (answer a question)?
Solving a problem is answering a question.
Answering a question corresponds to /proving a formula/.
Answering a question corresponds to /finding a model/ of a formula?

A /problem/ may be /modeled/ by a /relation/ between questions and answers.
For example, the problem \( \forall x \exists y : x+x = y \)
is modeled by the relation \( \{ (0,0), (1,2), (2,4), \ldots \} \)
and is also modeled by the relation \( \{ (\epsilon,\epsilon), (1,11), (11,1111), \ldots \} \).

Do not conflate a problem and a model of it.
A problem is a formula, /not/ a relation.

Compare various definitions of "problem"
 [fn::https://en.wikipedia.org/wiki/Computational_complexity_theory]
 [fn::https://plato.stanford.edu/entries/computational-complexity/].

A problem is \cite{sep-computational-complexity}

Problem can be /composed/ as formulas can be composed.
** Complexity
The worst-case time complexity[fn::https://en.wikipedia.org/wiki/Worst-case_complexity]
of machine $m$ for input $x$ is $t(m,x)$,
the number of steps $m$ makes between the beginning and the halting.
The /worst-case time complexity/ of $m$ for input /size/ $n$ is
$T(m,n) = \left\vert \max_{|x| = n} t(m,x) \right\vert$.
We can also write asymptotic statements such as $T(m,n) \in O(f(n))$.

An algorithm implies a machine.

The complexity class of a problem is the worst-case time complexity of the most efficient algorithm solving that problem.

A /machine/ $M$ is a /transition relation/ $T$
(an /acyclic/ binary relation).
$$
T(x,y) = \text{\(M\) can state-transition from \(x\) to \(y\).}
$$

$M$ /computes/ $P$ iff
a subgraph of the shortcut of $T$ is isomorphic to $P$.
(If $T$ were cyclic, this definition would fail.)

Related:
[[https://en.wikipedia.org/wiki/Graph_isomorphism][graph isomorphism]],
[[https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem][subgraph isomorphism problem]].

/Deterministic/ machine equals /functional/ relation.

$G$ /accepts/ $v$ iff $F^\infty(\{v\}) = \emptyset$ where $F$ is the graph's fringe function.
The /language/ recognized by $G$ is the largest $L \subseteq V$ such that $F^\infty(L) = \emptyset$.

A Turing machine is $(C,I,f)$
where $C$ is countable
and $f$ is recursive.

https://en.wikipedia.org/wiki/Register_machine

Example: a state of a Turing machine is $(c,l,h,r)$
where $c$ is a configuration,
$l$ is the tape content to the left of the head,
$h$ is the tape content at the head,
and $r$ is the tape content to the right of the head.
** Problem, reduction
Sometimes we can /reduce/ a problem into another problem?
** Digressions
*** Pullback
We can model the apparent function computed by the machine as \(g : A^* \to A^*\) where \(g(e(x)) = e(f(x))\).
We then do some algebraic manipulation:
\begin{align*}
\\ g(e(x)) &= e(f(x))
\\ (g \circ e)(x) &= (e \circ f)(x)
\\ g \circ e &\equiv e \circ f
\end{align*}

An equation of the shape \(g \circ e \equiv e \circ f\) is a special case of pullbacks[fn::https://en.wikipedia.org/wiki/Pullback_(category_theory)] in category theory.
*** Cheating
"Cheating" with an unreasonable encoding is a common error in P vs NP "proofs".
** Encoding affects complexity
Encoding a natural number \(n\) in unary notation takes \(n\) symbols.
Encoding the same number in binary notation takes approximately \(\log_2(n)\) symbols.

Adding two natural numbers \(m\) and \(n\) takes \(m+n\) steps in unary notation,
but only approximately \(\log(\max(m,n))\) steps in positional notation.

Why don't encode a number as its prime factorization,
to simplify multiplication while complicating addition?

What do we formally mean by "reasonable encoding"?

Why do we assume that numbers are encoded in positional notation[fn::https://en.wikipedia.org/wiki/Positional_notation], not unary notation[fn::https://en.wikipedia.org/wiki/Unary_numeral_system]?

My guess:
What we mean by reasonable encoding is an /order-preserving homomorphism/:
\begin{align*}
a < b &\iff e(a) <_e e(b)
\\
a = b &\iff e(a) = e(b)
\end{align*}

A homomorphism preserves structure.
But which structure?

We may encode the natural numbers as the bitwise-negation of the base-2 representation: 1, 0, 11, 10, 01, 00, etc.
** What makes an encoding reasonable?
A /reasonable encoding/ is an encoding that is easy to compute and is easy to invert.

A reasonable encoding has a finite description.
** Rant: The sad state of computational complexity texts?
It is philosophically appaling that most computational complexity texts readily show what a problem is /represented/ as,
but never clearly and /formally define/ what a problem /is/.
It is appaling that they spend hundreds of pages discussing something undefined.

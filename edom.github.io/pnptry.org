#+TITLE: Trying to prove P neq. NP
#+DATE: 2018-04-28 22:30 +0700
#+PERMALINK: /pnptry.html
#+MATHJAX: yes
* Note
This is a proof /attempt/, not a proof.

Last update was 2018-04-28.
** Note: The conversion of this page from Markdown to Org Mode using Pandoc may introduce some errors, beside my errors that are already in the page before conversion.
* TODO Understand the problem
* Finding an search problem that forces a DTM to traverse the search space
Let \(
\newcommand\SetOutcome{\mathbb{F}}
\newcommand\SetBit{\mathbb{B}}
\newcommand\SetPred{\mathbb{P}}
\newcommand\FunSat{\text{sat}}
\newcommand\FunMinTime{\text{MinTime}}
\newcommand\FunLen{\text{Len}}
\mathbb{B}= { 0, 1 } \)
be the set of /bits/.

Let $\mathbb{B}^*$ be the /Kleene closure/ of $\mathbb{B}$.

Let \( \mathbb{F} = \{ \text{accept}, \text{reject} \} \) be the set of /final states/.

A /predicate/ is a function in $\mathbb{B}^* \to \mathbb{B}$.

Let $\mathbb{P}$ be the set of all /computable predicates/.

Let $p \in \mathbb{P}$ be a computable predicate.

Let $\text{Len}(x)$ be the /length/ of the string $x \in \mathbb{B}^*$.

Let the function $\text{sat}: \mathbb{P}\times \Nat \to \mathbb{F}$ be

\begin{equation*}
\text{sat}(p,n) =
\begin{cases}
    \text{accept} & \text{if \( \exists x \in \mathbb{B}^n : p(x) = 1 \);}
    \\
    \text{reject} & \text{otherwise.}
\end{cases}
\end{equation*}

Let $\text{MinTime}_M(p,x)$ be the /shortest time/ (the minimum number of steps)
required by machine $M$
to compute $p(x)$ (to compute the predicate $p$ with input $x$).

Let $N$ be an NTM (non-deterministic Turing machine).

Let $D$ be a DTM (deterministic Turing machine).

Such NTM $N$ can compute $\text{sat}(p,n)$ in $O(n + \max_{x \in \mathbb{B}^n} \text{MinTime}_N(p,x))$ steps.
This is such algorithm:

#+BEGIN_EXAMPLE
    function sat (p, n) {
        var x: array [1..n] of bit
        for i := 1 to n {
            x[i] := guess
        }
        if p(x) { accept }
        else { reject }
    }
#+END_EXAMPLE

Such DTM $D$ can compute $\text{sat}(p,n)$ in $O(\sum_{x \in \mathbb{B}^n} \text{MinTime}_D(p,x))$ steps.
This is such algorithm:

#+BEGIN_EXAMPLE
    function sat (p, n) {
        for x in B^n {
            if p(x) { accept }
        }
        reject
    }
#+END_EXAMPLE

*Conjecture:* There exists a computable predicate $p \in \mathbb{P}$ such that
1. \( \text{MinTime}_D(p,x) = \text{MinTime}_N(p,x) \),
1. $\text{MinTime}_D(p,x) \in O([\text{Len}(x)]^k)$ where $k > 1$,
1. $N$ optimally computes $\text{sat}(p,n)$ in $O(n^k)$ time, and
1. $D$ optimally computes $\text{sat}(p,n)$ in $O(2^n \cdot n^k)$ time.

If that conjecture is true, then $\TimeP \neq \TimeNP$.
** Equivalent question: Is there a problem whose optimal solution is exhaustive search?
- [[https://www.cs.cmu.edu/~ryanw/improved-algs-lbs2.pdf][2010 Ryan Williams "Improving Exhaustive Search Implies Superpolynomial Lower Bounds"]]:
  "The P vs NP problem arose from the question of whether exhaustive search is necessary for problems
  with short verifiable solutions."
* Questions
Can we apply pigeonhole principle to the computation graph?

What problems are equivalent to the P vs NP problem?
* Plan
   :PROPERTIES:
   :CUSTOM_ID: plan
   :END:

- Reading list

  - [[https://en.wikipedia.org/wiki/Natural_proof][WP: Natural proof]]
  - approaches:

    - Fagin, Immerman, ...: descriptive complexity theory
    - Mulmuley, Sohoni, ...: geometric complexity theory

      - [[https://arxiv.org/abs/0709.0746][2007 Mulmuley and Sohoni, "Geometric Complexity Theory: Introduction"]]
      - [[https://arxiv.org/abs/1305.7387][2013 Landsberg "Geometric Complexity Theory: an introduction for geometers"]]
      - [[https://arxiv.org/abs/1509.02503][2015 Landsberg "An introduction to geometric complexity theory"]]
      - [[https://www.cse.buffalo.edu//~regan/papers/pdf/Reg02MSFD.pdf][Kenneth W. Regan's "Understanding the Mulmuley-Sohoni Approach to P vs. NP"]]
      - [[https://people.mpi-inf.mpg.de/~cikenmey/teaching/summer18/firstintrotogct/index.html][Christian Ikenmeyer's 2018 course]]

  - [[http://michaelnielsen.org/polymath1/index.php?title=Deolalikar_P_vs_NP_paper][A clearing house for Deolalikar P vs NP paper]]

- Undigested

  - One-way function implies something about P vs NP?

* Meta-research
   :PROPERTIES:
   :CUSTOM_ID: meta-research
   :END:

- Where are progress tracked?

  - [[https://rjlipton.wordpress.com/2017/02/05/a-panel-on-p-vs-np/][2017 Richard J. Lipton and Kenneth W. Regan]]
  - [[http://www.win.tue.nl/~gwoegi/P-versus-NP.htm][2016 Gerhard J. Woeginger]]
  - [[http://blog.computationalcomplexity.org/2015/08/have-we-made-progress-on-p-vs-np.html][2015 Lance Fortnow and Bill Gasarch]]
  - [[https://www.reddit.com/r/math/comments/1krrkx/what_progress_has_been_made_on_the_p_vs_np/][2014 reddit]]
  - [[http://www.ncmis.cas.cn/kxcb/jclyzs/201204/W020120424627425387644.pdf][2009 Lance Fortnow "The status of the P versus NP problem"]]

- What is the P vs NP problem?

  - Official problem description: [[http://www.claymath.org/sites/default/files/pvsnp.pdf][The P versus NP problem, by Stephen Cook, for the Clay Millennium Prize Problems]]

* Another attempt?
   :PROPERTIES:
   :CUSTOM_ID: another-attempt
   :END:

- This is an older attempt.
- This should be merged to the attempt above.
- Let:

  - $f$ be a predicate
  - $k$ be a natural number
  - $Sat(f,k)$ be the problem of finding a string $x$ of length $k$ such that $f(x) = 1$

- Lemma: If $f \in \TimeP$ then $Sat(f,k) \in \TimeNP$.
  (This should be obvious and simple to prove?)
- Conjecture: There exists a predicate whose search cannot be faster than brute force.

  - Formally: There exists $f \in \TimeP$ such that $Sat(f,k) \not \in \TimeP$.

- That lemma and that conjecture, if proven true, would imply $\TimeP \subset \TimeNP$.
- We try to prove that conjecture by diagonalization/pigeonholing?
  The set \( {0,1}^k \to {0,1} \) has $2^{2^k}$ elements,
  because by combinatorics, in the truth table, there are $2^k$ rows, and each row has $2$ possibilities.
  There are $2^{2^k}$ possible $k$-letter-string predicates.
  Suppose that a deterministic machine can solve $Sat(f,k)$ for all $f$ in $O(poly(k))$ time.
  (Can we apply pigeonhole principle to the configuration graph?)
- Every predicate can be stated in disjunctive normal form.

* Other people's works that may be related
   :PROPERTIES:
   :CUSTOM_ID: other-peoples-works-that-may-be-related
   :END:

- 2017-11-22 news about NEXP and ACC https://news.mit.edu/2017/faculty-profile-ryan-williams-1122
- an explanation in English https://danielmiessler.com/study/pvsnp/
- 2011 book "Why Philosophers Should Care About Computational Complexity" https://eccc.weizmann.ac.il/report/2011/108/
* Circuit complexity
- [[https://en.wikipedia.org/wiki/Circuit_complexity][WP:Circuit complexity]]
** The shortest $n$-parameter boolean predicate equivalence class representative problem
- Let $E_n$ be the set of all /Boolean $n$-expressions/.

  - An /$n$-expression/ is an expression that has at most $n$ variables.
  - Formally, the syntax of $E_n$ is:

    - Constant expressions:

      - $0 \in E_n$.
      - $1 \in E_n$.

    - Variable expressions:

      - If $k \in \Nat$ and $0 \le k < n$, then $x_k \in E_n$.

        - The expression $x_k$ is purely symbolic.

          - The $x$ does not mean anything.

    - If $\alpha \in E_n$, then $(\neg \alpha) \in E_n$.
    - If $\alpha \in E_n$ and $\beta \in E_n$, then $(\alpha \wedge \beta) \in E_n$.
    - If $\alpha \in E_n$ and $\beta \in E_n$, then $(\alpha \vee \beta) \in E_n$.
    - Nothing else is in $E_n$.

- Let the /size/ of a formula be the number of operators in it.

  - We write $C(\phi)$ for the size of the formula $\phi$.
  - We say that $\alpha$ is /smaller/ than $\beta$ iff $C(\alpha) < C(\beta)$.
  - Formally we define $C(\phi)$ as:
    \begin{align*}
    C(\neg \alpha) &= 1 + C(\alpha),
    \\
    C(\alpha \wedge \beta) &= 1 + C(\alpha) + C(\beta),
    \\
    C(\alpha \vee \beta) &= 1 + C(\alpha) + C(\beta),
    \\
    C(\alpha) &= 0 \text{ otherwise}.
    \end{align*}

- Given a formula $\phi \in E_n$ and an /assignment/ $a : \{0,1\}^n$,
  we can /interpret/ the formula $\phi$.

  - The result of interpreting $\phi$ with assignment $a$ is written $\phi|_a$,
    and is obtained by replacing each $x_k$ with $a_k$
    and evaluating the expression to either zero or one.
  - This interpretation enables us to define /equivalence/,

    - Formally, we say that two formulas $\alpha, \beta \in E_n$ are /equivalent/, written $\alpha \equiv \beta$, iff
      for every assignment $a \in \{0,1\}^n$, it holds that $\alpha|_a = \beta|_a$.
      Then, we define the /equivalence class/ of a formula $\phi \in E_n$ as
      $[\phi] = \{ \alpha ~|~ \alpha \equiv \phi, ~ \alpha \in E_n \}$.

      - Every element of that equivalence class is called a /representative/ of that class.
        Note that equivalence is not equality: $x_0 \wedge x_0$ and $x_0$
        are equivalent but not equal.

    - Two formulas are equivalent iff they always give matching results for all assignments.
    - Two formulas are equal iff they look the same.
    - Equivalence is the comparison of meaning,
      whereas equality is the comparison of form.

- The set $E_n$ has exactly $2^{2^n}$ equivalence classes.

  - We label those classes $K(n,0), K(n,1), \ldots K(n,2^{2^n}-1)$.
  - Define $Q(n,k)$ as the shortest representative of $K(n,k)$.

    - Here are some examples of the shortest representatives
      that can be verified by hand:
      \begin{align*}
      Q(0,0) &= 0
      \\ Q(0,1) &= 1
      \\ Q(1,0) &= 0
      \\ Q(1,1) &= x_0
      \\ Q(1,2) &= \neg x_0
      \\ Q(1,3) &= 1
      \\ Q(2,1) &= x_0 \wedge x_1
      \\ Q(2,2) &= \neg x_0 \wedge x_1
      \\ Q(2,3) &= x_0
      \\ Q(2,6) &= \neg (x_0 \wedge x_1) \wedge (x_0 \vee x_1)
      \\ Q(2,7) &= x_0 \vee x_1
      \\ Q(2,9) &= (x_0 \wedge x_1) \vee \neg (x_0 \vee x_1)
      \end{align*}

- It should be apparent that $Q(n,2^{2^n}-1-k) = \neg Q(n,k)$.
  It should be apparent that $Q(2,6)$ is XOR and $Q(2,9)$ is bi-implication.
  It should be apparent that $Q(2,6)$ and $Q(2,9)$ are the longest expressions for $n = 2$,
  and both of them have size $4$.
- *Problem statement*:
  For each $n$,
  find $k$
  such that $Q(n,k)$ is the longest among all possible $k$.
- [[https://en.wikipedia.org/wiki/Parity_function][WP:Parity function]]?
  "The $n$-variable parity function and its negation are the only Boolean functions for which
  all disjunctive normal forms have the maximal number of $2^{n - 1}$ monomials of length $n$
  and all conjunctive normal forms have the maximal number of $2^{n - 1}$ clauses of length $n$.
  (Ingo Wegener, Randall J. Pruim, /Complexity Theory/, 2005, ISBN 3-540-21045-8, p. 260)"
- Relationship between $n$-expressions and $n$-cubes

  - Here we imagine what it is like to apply geometric operations to Boolean expressions.
  - Draw

    - Draw the outline of a square on a white paper.
    - Draw two lines that divide the square into four smaller subsquares.
    - Color the top right subsquare red.

      - The resulting picture represents $x_0 \wedge x_1$.

  - The result of rotating $x_0 \wedge x_1$ 90 degrees counterclockwise is $\neg x_0 \wedge x_1$.

    - Rotated once again, it becomes $\neg x_0 \wedge \neg x_1$.
    - Rotated once again, it becomes $x_0 \wedge \neg x_1$.
      _ Rotated once again, it comes back to $x_0 \wedge x_1$.

  - Define $R_2(\phi)$ as the counterclockwise-rotated $\phi$ where $\phi \in E_2$.

    - Then $R(x_0) = x_1$ and $R(x_1) = \neg x_0$.

  - Other operations:
    horizontal flip,
    vertical flip,
    negation.
  - $(R_2)^4(\phi) = \phi$.
  - On the 3-cube, there are 3 counterclockwise rotations.
  - Each $n$-expression of the form $x_k$ divides the $n$-cube into two region.

- Unnecessary

  - We define the shorthand $\alpha < \beta$ to mean that $\alpha$ is shorter than $\beta$.
    Now we can /order/ the equivalence classes in $E_n$ by their sizes.
    For every $E_n$, there exists at least one /infimum/ (greatest lower bound).
    For every $A \subseteq E_n$,
    we say that $\alpha \in \inf(A)$ iff $\alpha \le \phi$ for every $\phi \in E_n$.
  - A /bit/ is either zero or one.
  - We define the mapping $N_n : \{0,1\}^n \to \Nat$
    as a mapping from the $n$-dimensional bit vector $x = (x_0,\ldots,x_{n-1})$
    to the natural number $N_n(x) = \sum_{k=0}^{n-1} x_k 2^k$.

    - $N_n(x)$ is the number whose
      $n$-bit binary right-to-left encoding is the $n$-dimensional bit vector $x$.

  - We define the bit vector identifying the predicate as
    \begin{align*}
      B_n(\phi) = N_{2^n}( \phi(N_n^{-1}(0)), \ldots, \phi(N_n^{-1}(2^n-1)))
      \end{align*}

- Shannon 1949 proved that almost all $n$-argument boolean functions
  require circuits of size $\Theta(2^n/n)$. (citation?)
- For small numbers, we can enumerate the answers by hand.
- A formula is /canonical/ iff it cannot be shortened.

What is the longest possible canonical description length of a predicate that takes $k$ arguments?

#+BEGIN_EXAMPLE
    0000 | 0
    0001 | a \wedge b
    0010 | a \wedge \neg b
    0011 | a
    0100 | \neg a \wedge b
    0101 | b
    0110 | (a \wedge \neg b) \vee (\neg a \wedge b)
    0111 | a \vee b
    1000 | \neg (a \vee b)
    1001 | (a \wedge b) \vee \neg (a \vee b)
    1010 | \neg b
    1011 | a \vee \neg b
    1100 | \neg a
    1101 | \neg a \vee b
    1110 | \neg (a \wedge b)
    1111 | 1
#+END_EXAMPLE

Conjecture: The longest 2-argument predicate is 0110.

Conjecture: $(a \wedge \neg b) \vee (\neg a \wedge b)$ is the shortest description of 0110.

What we are asking here is Sipser 1997's /circuit-size complexity/?

- How are circuit complexity and proof complexity related?
- Simplification rewrite rules:
  \begin{align*}
  \neg (\neg \alpha) = \alpha
  \\
  \alpha \wedge \neg \alpha = 0
  \\
  \alpha \vee \neg \alpha = 1
  \\
  \alpha \vee 1 = 1
  \\
  \alpha \wedge 0 = 0
  \\
  \neg 0 = 1
  \\
  \neg 1 = 0
  \\
  \neg \alpha \wedge \neg \beta = \neg (\alpha \vee \beta)
  \\
  \neg \alpha \vee \neg \beta = \neg (\alpha \wedge \beta)
  \\
  (\alpha \wedge \beta) \vee (\alpha \wedge \gamma) = \alpha \wedge (\beta \vee \gamma)
  \end{align*}
- Is this the problem we're talking about?

  - [[https://en.wikipedia.org/wiki/Circuit_minimization_for_Boolean_functions][WP:Circuit minimization for Boolean functions]]
  - [[http://www.cs.sfu.ca/~kabanets/papers/mincircuit.pdf][Circuit Minimization Problem]], 1999, Valentine Kabanets and Jin-Yi Cai
  - [[http://www.cs.yale.edu/homes/peralta/CircuitStuff/CMT.html][Yale CS Circuit Minimization Team Work]]
  - what?

    - [[https://en.wikipedia.org/wiki/Infimum_and_supremum#Formal_definition][WP:Infimum and supremum]]
* Computational complexity
  :PROPERTIES:
  :CUSTOM_ID: computational-complexity
  :END:

- world effort

  - [[https://www.nada.kth.se/~viggo/wwwcompendium/wwwcompendium.html][A compendium of NP optimization problems]]

    - Smallest equivalent something:
      https://en.wikipedia.org/wiki/Skeleton_(category_theory)
    - Minimum equivalent graph,
      also called transitive reduction.
      https://en.wikipedia.org/wiki/Transitive_reduction
      https://www.nada.kth.se/~viggo/wwwcompendium/node49.html

  - [[https://polymathprojects.org/2013/11/04/polymath9-pnp/][2013 Polymath project: Polymath 9: Discretized Borel Determinacy]]

    - https://gowers.wordpress.com/2013/10/24/what-i-did-in-my-summer-holidays/
    - https://gowers.wordpress.com/2013/11/03/dbd1-initial-post/

  - https://cstheory.stackexchange.com/questions/4090/ways-for-a-mathematician-to-stay-informed-of-current-research-in-complexity-theo

- open access journals

  - [[https://lmcs.episciences.org/browse/latest][Logical methods in computer science]]

- recent publication trackers

  - arxiv list of recent submissions

    - [[https://arxiv.org/list/cs/recent][computer science]]
    - [[https://arxiv.org/list/cs.CC/recent][computational complexity theory]]

- NP-complete problems

  - [[https://en.wikipedia.org/wiki/List_of_NP-complete_problems][WP:List of NP-complete problems]]
  - https://mathoverflow.net/questions/72628/number-theory-and-np-complete
  - https://cstheory.stackexchange.com/questions/14124/is-there-a-natural-problem-on-the-naturals-that-is-np-complete

- descriptive complexity theory

  - Immerman and Vardi shows that FO(LFP) corresponds with P.

    - What does a FO(LFP) formula look like?
    - [[http://michaelnielsen.org/polymath1/index.php?title=Immerman-Vardi_theorem][Immerman--Vardi theorem]]
    - [[https://complexityzoo.uwaterloo.ca/Complexity_Zoo:F#folfp][FO(LFP) on Complexity Zoo]]

  - Fagin (?) proved that NP = ESO (existential second-order logic).
  - Immerman (?) proved that P = FO(LFP) (first-order logic with least fixed point).

    - Therefore, to prove that P does not equal NP,
      construct a sentence that is in ESO but not in FO(LFP).

      - Easier said than done?

        - Learn finite model theory?

          - [[https://logic.rwth-aachen.de/~graedel/yurifest.pdf][Erich Grädel and Martin Grohe, "Is polynomial time choiceless?"]].
            Choiceless polynomial time logic would imply $\TimeP \neq \TimeNP$?
          - [[http://researcher.ibm.com/researcher/files/us-fagin/tcs93.pdf][Ronald Fagin's perspective on finite model theory]]

  - https://people.cs.umass.edu/~immerman/pub/ch0_1_2.pdf
  - [[http://www.gpwu.ac.jp/~satoru/lnlg05kuroda.pdf][Descriptive Complexity and Language-Theoretic Complexity]]
    by Satoru Kuroda
  - [[https://people.cs.umass.edu/~immerman/pub/ExperimentalDC.pdf][Experimental descriptive complexity]]
    by Neil Immerman et al
  - http://arxiv.org/pdf/cs/0409039v11.pdf
    On Certain Modular Equations
    Marius Constantin Ionescu

    - is this valid?

  - http://mathworld.wolfram.com/Computation.html
  - http://mathworld.wolfram.com/PrincipleofComputationalEquivalence.html
  - http://mathworld.wolfram.com/ComputationalIrreducibility.html
  - https://en.wikipedia.org/wiki/Algebraic_logic

- http://blog.computationalcomplexity.org/2010/05/structure-or-lack-thereof-of-data.html
- Plan for the P vs NP problem?

  - Relate configuration graph and problem theory
  - Unexplored ideas:

    - Machine is not computation.
    - Machine /is/ formal system.
    - Computation /is/ repeated function application.
    - /Under what conditions does nondeterminism give extra power?/

  - Where is computation theory, computability theory, complexity theory now?

- Complexity axioms

  - Blum's?
  - Here we axiomatize machine-independent /complexity/.
  - Recall that a problem $P$ is a subset of $X \times Y$.
    We posit, without referring to any model of computation,
    that every question $x$ has a /complexity/ $m(x)$, usually a number.
    The function $m$ is a /complexity measure/ of $P$ iff it satisfies the axioms below.
  - For help, we define $S(k)$
    as the set of all questions with the same complexity $k$,
    that is $S(k) = \{ x ~|~ m(x) = k \}$.
    Then, the /complexity axioms/ are:

    - Every $S(k)$ is finite.
    - There are always more complex questions than less complex questions,
      because, for example, longer strings can encode more questions.
      Formally, if $i < j$ then $|S(i)| < |S(j)|$.

  - Note that the complexity measure is $m$, not $S$.
  - Computation graph axiom:

    - A machine can only manipulate one symbol at a time.
      Formally, if $E(a,b)$ then $|m(a) - m(b)| \le 1$.
    - The out-degree of a vertex of a nondeterministic graph may exceed 1 but cannot exceed a constant.

- Machine, algorithm, and complexity

  - The [[https://en.wikipedia.org/wiki/Worst-case_complexity#Definition][time complexity]]
    of machine $m$ for input $x$ is $t(m,x)$,
    the number of steps $m$ makes between the beginning and the halting.
    The /worst-case time complexity/ of $m$ for input /size/ $n$ is
    $T(m,n) = \left\vert \max_{|x| = n} t(m,x) \right\vert$.
    We can also write asymptotic statements such as $T(m,n) \in O(f(n))$.
  - An algorithm $a$ implies a machine $m(a)$.
  - An /algorithm/ solves a /problem/.
    A problem can be solved by many algorithms with different resource usage characteristics.
  - The what (?) time complexity class of a problem is the worst-case time complexity of the most efficient algorithm solving that problem.
  - Machine /is/ algorithm.
  - A /machine/ $M$ is a /transition relation/ $T$
    (an /acyclic/ binary relation).
    $$
    T(x,y) = \text{\(M\) can state-transition from \(x\) to \(y\).}
    $$
  - $M$ /computes/ $P$ iff
    a subgraph of the shortcut of $T$ is isomorphic to $P$.
    (If $T$ were cyclic, this definition would fail.)
  - Related:
    [[https://en.wikipedia.org/wiki/Graph_isomorphism][graph isomorphism]],
    [[https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem][subgraph isomorphism problem]].
  - /Deterministic/ machine equals /functional/ relation.
  - $G$ /accepts/ $v$ iff $F^\infty(\{v\}) = \emptyset$ where $F$ is the graph's fringe function.
    The /language/ recognized by $G$ is the largest $L \subseteq V$ such that $F^\infty(L) = \emptyset$.
  - A Turing machine is $(C,I,f)$
    where $C$ is countable
    and $f$ is recursive.
  - https://en.wikipedia.org/wiki/Register_machine
  - Example: a state of a Turing machine is $(c,l,h,r)$
    where $c$ is a configuration,
    $l$ is the tape content to the left of the head,
    $h$ is the tape content at the head,
    and $r$ is the tape content to the right of the head.
  - A problem class is a function.
  - A /problem/ is a member of $S$.
  - A /problem class/ is a subset of $S$.
  - Sometimes we can /reduce/ a problem $p : P$ into another problem $q : Q$
    by an injective reduction $r : P \to Q$.

- Space and time complexity

  - Can we deal with complexity without ever defining machine and computation
    (besides assuming they exist)?
  - \( \newcommand\ftime{\text{time}}  \newcommand\fspace{\text{space}}  \newcommand\fsize{\text{size}} \)We are interested at the number of steps
    a machine makes for an input before terminating.
    We define $\ftime~f~x$ as the /running time/
    of the machine $f$ for input (initial state) $x$.
  - We also define $\fsize~x$ as the /size/ of the state $x$.
  - (Concrete)
    Formally, $\ftime~f~x = n$ iff $n$ is the smallest natural number such that $f^{n+1}~x = f^n~x$.
  - We apply general algebraic thinking again, this time about congruences.
    Let $T~f~n = \{ x ~|~ \ftime~f~x = n \}$
    be the set of all inputs that $f$ handles in $n$ steps.
    We can also let $U~n = \{ (f,x) ~|~ \ftime~f~x = n \}$?
    [
    \lambda f . \lambda n . { x _{|} \ftime_{f}x = n }
    \
    \lambda n . { (f,x) _{|} \ftime_{f}x = n }
    \
    \lambda m . \lambda n . { (f,x) _{|} \fsize~x = m, ~ \ftime_{f}x = n }
    ]
  - We define $\fspace : M~S \to S \to \Nat$,
    where $\fspace~f~x$ is the size of the biggest state in $\{ f^n~x ~|~ n \in \Nat \}$.
  - The other option is to require that each machine $f$ have a $t : S \to \Nat$ where $t~(f~x) = 1 + t~x$.

- Complexity as an ordering of questions

  - Postulate:
    For every pair of questions, we can always decide which is more complex.
    Therefore, complexity is a /total ordering/ of questions.
    We write $x < y$ iff $x$ is less complex than $y$.
    Then the complexity axioms are:

    - For each $y$, there are finitely many $x$ such that $x \le y$.
    - For each $x$, there are infinitely many $y$ such that $x \le y$.
      (Is this required?)

  - A /reduction/ $r$ from problem $P$ to problem $Q$ is an order-preserving (but not necessarily order-reflecting) function
    that maps $P$-questions to $Q$-questions.
    Formally, for all $x, y \in P$, if $x \le y$ then $r(x) \le r(y)$,
    but the converse does not need to hold.
    (Are we sure we don't need order-reflecting?)
  - Rabin complexity axioms?
    Still with the same $m$ here.
    For help, let $L(k) = \{ x ~|~ m(x) \le k \}$
    be the set of all questions that are not more complex than $k$.
    Then the axioms are:

    - Every $L(k)$ is finite.
    - For every $i$, there exists $j > i$ such that $L(i) \subset L(j)$.
      We say that $L$ is /eventually increasing/.
    - The limit of $L(k)$ as $k$ grows unbounded is $X$, the set of all questions.
    - (That is not what Rabin says? He uses Post canonical system and Curry-Howard correspondence?)

  - Corollary:

    - $L$ is nondecreasing: If $i < j$ then $L(i) \subseteq L(j)$.

  - [[https://en.wikipedia.org/wiki/Order_theory][WP:Order theory]]

- Articles

  - [[https://en.wikipedia.org/wiki/Boolean_satisfiability_problem][WP:Boolean satisfiability problem]]
  - [[http://www.dcs.gla.ac.uk/~pat/cpM/papers/cheeseman91where.pdf][Where the really hard problems are]], Cheeseman, Kanefsky, and Taylor,

    - "Almost all k-colorable graphs are easy to color", J. S. Turner, 1988

  - Blum

    - [[https://www.researchgate.net/profile/Juris_Hartmanis/publication/242506038_On_the_Computational_Complexity_of_Algorithms/links/53fcd0a40cf2364ccc04db1d.pdf][On the computational complexity of algorithms]], J. Hartmanis and R. E. Stearns, 1965

  - [[http://www.sciencedirect.com/science/article/pii/0022000078900089][The complexity of total order structures]], Dan Moore, 1978

- Books

  - [[http://theory.cs.princeton.edu/complexity/][Computational Complexity: A Modern Approach, by Sanjeev Arora and Boaz Barak]], more than 400 pages, no finite model theory
  - [[http://cglab.ca/~michiel/TheoryOfComputation/TheoryOfComputation.pdf][Introduction to Theory of Computation, by Anil Maheshwari and Michiel Smid]], more than 200 pages

- [[http://port70.net/~nsz/articles/classic/blum_complexity_1976.pdf][Blum 1976 "a machine independent theory of the complexity of recursive functions"]], 15 pages

  - [[https://www.cs.toronto.edu/~sacook/homepage/rabin_thesis.pdf][Michael O. Rabin's 1960 technical report]]

    - [[https://cstheory.stackexchange.com/questions/34236/rabins-degree-of-difficulty-of-computing-a-function-and-a-partial-ordering-of][from cstheory stackexchange]]

- https://en.wikipedia.org/wiki/Proof_complexity
- A question related to P vs NP

  - Proving lower bound is much harder than proving upper bound.
  - Unsolved problem: How do we prove that an algorithm is the fastest solution of a problem?
    In order to prove that an algorithm is the fastest,
    it suffices us to prove that there is no faster algorithm for the same problem,
    but this is easier said than done.

    - https://cs.stackexchange.com/questions/38357/is-it-really-possible-to-prove-lower-bounds

- https://en.wikipedia.org/wiki/Time_hierarchy_theorem
- https://en.wikipedia.org/wiki/Constructible_function
- Entertainment

  - http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html
* What is a machine? What is the essence of a machine?
* Why do we use Turing machines instead of lambda calculus when discussing computational complexity?
- https://cstheory.stackexchange.com/questions/23798/p-and-np-classes-explanation-through-lambda-calculus

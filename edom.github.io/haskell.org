#+TITLE: Haskell programming language
#+DATE: 2018-07-22 02:45 +0700
#+PERMALINK: /haskell.html
#+OPTIONS: ^:nil toc:1
* Subtyping in Haskell with canonical injections
:PROPERTIES:
:CUSTOM_ID: abdullah
:END:
#+TOC: headlines 1 local
** Background
In Haskell, Just is the /only/ sound way to make a Maybe t from t.
We call such unambiguous construction a /canonical injection/.
The compiler should insert canonical injections to recover from trivial type errors.
Such recovery has these interesting benefits:
- Now we can fake non-overlapping /untagged unions/ (Haskell has tagged unions).
  This reduces the bureaucracy when composing data types following the free-monad/interpreter pattern;
  the compiler inserts the required Pure constructors.
- Now we can fake /equirecursive types/ (Haskell has isorecursive types).
  We no longer have to type "In" and "out" when using "Fix";
  the compiler inserts the required bureaucracy.
- Now we can fake /heterogeneous lists/ and heterogeneous collections.
- Now we can have /covariant/ return type and /contravariant/ return type.
  This means now we can, without breaking callers, generalize an argument or specialize a return value, as in Java.
** What is here, and how it answers your questions
This is what I am going to do in this article, in no particular order:
- [NOTATION] defines some notations.
- [DEFINE] defines canonical injections.
- [DATA] shows the rules for inferring canonical injections for inductive data types.
- [LAMBDA] shows the rules for inferring canonical injections for lambdas.
- [HICKEY] shows that Hickey's two wishes are special cases of canonical injections.
- [MONAD] shows the relationship between canonical injections and Monad instances.
- [IMPL] sketches a possible implementation, in principle.

This is how I answer your questions:
- Your first question is answered by [DEFINE], [DATA], and [LAMBDA].
- Your second question is answered by [HICKEY] and [LAMBDA].
- Extra things that may be of interest to you are [MONAD] and [IMPL].
** [NOTATION]
Notation conventions.

By "injection", I mean an injective function.

"The canonical injection from A to B" means "the only sound injection from A to B".
By "sound", I mean "not involving bottom (undefined)".
I assume total functional programming, and I say "the only possible injection" to mean "the only sound injection".
** [DEFINE] Examples of canonical injections
"Canonical" means "there is exactly one".
"Injection" means injective function.
A canonical injection from A to B is the only injection from A to B.

Examples of canonical injections:
- In the case of t -> Maybe t, Just is the canonical injection.
- In the case of a -> Either a b where a != b, Left is the canonical injection.
- In the case of a -> Either a a, each of Left and Right is an injection, so there is no canonical injection here.

Thus some constructors are canonical injections.
** [DATA] Inferring canonical injections for inductive data types
In general, the compiler infers canonical injections from a data definition using this rule:
If parameter p occurs exactly once in the right-hand side of the equal sign in "data A p = ...",
then the only constructor with p is the /canonical injection/ from p to A p.

For example, observe that, in the following definition,
in the right-hand side of the equal sign:
- Int occurs twice,
- String occurs once, and
- p occurs once.
#+BEGIN_SRC haskell
data A p = A0 Int | A1 String | A2 Int | A3 p
#+END_SRC
Therefore, from the above definition, the compiler infers that:
- A1 : String -> A p is the canonical injection from String to A p.
- A3 : p -> A p is the canonical injection from p to A p.
** [MONAD] Relationship between canonical injections and Monad instances
Let INJ be the canonical injection from p to F p.
Let F be an instance of Monad.
Then the compiler infers "return" and one case of "bind" as follows:
#+BEGIN_SRC haskell
return = INJ
(>>=) (INJ x) k = k x
#+END_SRC

Indeed I think these have to be laws:
If INJ is the canonical injection from t to F t, and F is an instance of Monad, then:
- return has to be equal to INJ,
- INJ x >>= k must be equal to k x.

I think the above laws relate this concept of "canonical injections" with your concept of monads as "conservative extensions of spaces".

There is also a law for the other way around:
the =return= function must be an injection,
although the user is responsible for ensuring that.
I think the compiler should assume that =return= /is/ a canonical injection,
and exploit such injection with this rule:
If an =x : t= is found where an =f t= is expected, and =f= is an instance of =Monad=, then replace =x : t= with =return x : f t=.

This rule also works in a nested situation.
This should typecheck:
#+BEGIN_EXAMPLE
0 :: (Monad m, Monad n) => m (Maybe (n Int))
#+END_EXAMPLE
** [HICKEY] Hickey's two wishes
Yes, my rule should work in both of Hickey's cases, because there is a canonical injection in each of those cases.
Note that Hickey's cases correspond to wanting the compiler to automatically apply these canonical injections:

#+BEGIN_SRC haskell
-- inj : today -> yesterday,
-- so that every caller doesn't have to be rewritten.

-- Making an arg optional:
-- yesterday:       X -> Y
-- today:     Maybe X -> Y
-- The canonical injection:
-- Wherever you see that a Maybe X -> Y is supplied
-- where an X -> Y is required, use this:
inj : (Maybe X -> Y) -> (X -> Y)
inj f = \ x -> f (Just x)

-- Providing a stronger return promise:
-- yesterday: X -> Maybe Y
-- today:     X -> Y
-- The canonical injection:
-- Wherever you see that an X -> Y is supplied
-- where an X -> Maybe Y is required, use this:
inj : (X -> Y) -> (X -> Maybe Y)
inj f = \ x -> Just (f x)
#+END_SRC
Note that the type of inj is "today -> yesterday", not "yesterday -> today". (Do you see why?)

Our rewriting the function changes its type from "yesterday" to "today",
but the unchanged callers still expect that the function has the type "yesterday".
** [LAMBDA] Inferring canonical injections for lambdas
Here I generalize Hickey's cases to all lambdas.

Notation convention:
I write the dependently-typed expression "inj A B" to mean the canonical injection from A to B, if such canonical injection exists.
The type of the expression "inj A B" is A -> B.

These two rules define canonical injections for all lambdas:
For all types A, B, and C:
#+BEGIN_SRC haskell
inj (A -> C) (B -> C) fac = fbc where fbc b = fac (inj B A b)
inj (C -> A) (C -> B) fca = fcb where fcb c = inj A B (fca c)
#+END_SRC

That should also work with currying and higher-order lambdas.
** [IMPL] A possible implementation, in principle
Suppose that a compiler encounters a type error.

Let s : S be the supplied (actual) expression and type (what the user actually types).

Let R be the required (expected) type.

Then, if there is the canonical injection inj : S -> R from S to R,
the compiler should behave as if the user had typed "inj s" from the beginning.

In principle, it is possible to write a Haskell interpreter in Prolog, and add our own inference rules,
such as inferring canonical injections and inserting canonical injections.
I think [DATA] and [LAMBDA] sufficiently define canonical injections for all Haskell 98 types.
** History
This originated as a letter to Abdullah on <2018-12-18>.

<2018-12-18>

- First publish date.
- First revision.

Alternative titles:
- Faking untagged unions and equirecursive types in Haskell
  - This sounds promising.
  - But this is misleading.
    This feature requires modifying the compiler, so the code is not "in Haskell".
- Inferring and inserting canonical injections in Haskell
  - This was the original working title.
- Recovering from trivial type errors in Haskell
  - Unclear about what is being sold.
- A monad is a way of conservatively extending all spaces

The concept I'm proposing already exists with the same name ("canonical injection").
https://en.wikipedia.org/wiki/Inclusion_map

<2018-12-14>

Questions leading to this article:
- Does "algebraic subtyping" mean adding the following rule to the compiler:
  "for all x, t: everywhere an x : t is found where a Maybe t is expected, replace x : t with Just x : Maybe t"?
- Does "algebraic subtyping" mean that the compiler "recovers" from certain (injective) type errors?
** Half-baked but related ideas, should be in the article
#+TOC: headlines 1 local
*** A subtyping relation arises from canonical injections
Remember:
- "A is a subtype of B" means an A can be supplied wherever a B is expected.
- The existence of a canonical injection from A to B suggests that A is a "subset of" ("is contained in") B.

We can define this subtyping relation:
A is a subtype B iff there is a canonical injection from A to B.

Subtyping by canonical injection obeys Liskov substitution principle.
*** Subtyping in Haskell?
- http://referaat.cs.utwente.nl/conference/12/paper/7000/expressing-ontologies-using-a-functional-language.pdf
  - "there are some proposals for implementing subtyping [in Haskell] [11, 12]"
    - Open ADT precludes exhaustive pattern matching.

TODO summarize:
- https://mail.haskell.org/pipermail/haskell-cafe/2007-May/026334.html
- "Polymorphic subtyping in O'Haskell" https://www.sciencedirect.com/science/article/pii/S0167642302000266
- "Subtype polymorphism in Haskell" https://stackoverflow.com/questions/12002979/subtype-polymorphism-in-haskell
*** A weak anthropocentric argument for automating canonical injections?
We should conflate =x= and =Just x=.
=Just= is there only to make the compiler happy.
For us humans, =x= and =Just x= have the same semantics.
*** Newtypes should be replaced with /proofs/.
#+BEGIN_SRC haskell
-- Replace this:
foo :: Nonneg Int -> a
-- with this, where _p is a proof that x is nonnegative:
foo {_p : x >= 0} x = ...
#+END_SRC
* Interpreting Haskell without types: a strong temptation
Suppose that we are writing a Haskell interpreter in Prolog,
but we are too lazy to check the types,
so we simply ignore all type annotations.
Let's call the language HWOT (Haskell WithOut Types), pronounced like "what".
What do we have then?
A normal-order beta-reducer/term-rewriter?
Something like the Pure language[fn::https://en.wikipedia.org/wiki/Pure_(programming_language)]?
** The temptation is strong
The temptation to ditch types is /strong/.

Untagged unions are trivial in HWOT.
We can write this in HWOT but not Haskell:
#+BEGIN_EXAMPLE
-- is_list :: a -> Bool
is_list [] = True
is_list (_:_) = True
is_list _ = False

-- size :: List a + Tree b -> Integer
size [] = 0
size (_:x) = 1 + size x
size Leaf = 0
size (Node _ lef rig) = size lef + size rig

-- my_list :: [Integer + String]
my_list = [1, 2, "three"]
#+END_EXAMPLE

Open functions (functions defined in several modules) are also trivial in HWOT.

Overloading and multimethods are trivial if constructors are namespaced.
#+BEGIN_EXAMPLE
fun ModA.Con = 0
fun ModB.Con = 1
#+END_EXAMPLE

We can make a function argument optional backward-compatibly.
We can monkey-patch our programs, although this may lead to maintenance hell.
#+BEGIN_EXAMPLE
-- We have a function f : [a] -> Int.W

f [] = 0
f _ = 1

-- Now we want to make the argument optional.

-- We simply write this somewhere else.
-- This doesn't even have to be in the same file that defines the original f.

f Nothing = 0
f (Just x) = f x
#+END_EXAMPLE

We can even write rewrite rules like GHC rewrite rules for stream fusion.
The head of a pattern does not have to be a "constructor".
#+BEGIN_EXAMPLE
map f (map g x) = map (f . g) x
#+END_EXAMPLE

Data-type-a-la-carte become much shorter.
No need for pattern synonyms.
Parsing, location, trees-that-grow, everything becomes much shorter.
#+BEGIN_EXAMPLE
eval (Add x y) = eval x + eval y

-- define in other file

eval (Neg x) = - x

-- data Loc a = MkLoc FilePath Int Int a
-- parse :: String -> Loc Exp

-- Simply add this anywhere.
eval (MkLoc _ _ _ e) = eval e
#+END_EXAMPLE

Unsolved problems: type classes.

Type classes are replaced with implicit first arguments?

Higher-order patterns may be too much to handle.
They may break confluence[fn::https://en.wikipedia.org/wiki/Confluence_(abstract_rewriting)].
#+BEGIN_EXAMPLE
\forall f x . f (Just x) = f x
#+END_EXAMPLE

=1 + "a"= is not an error; it is a /value/ that reduces to itself.

=1 / 0= is not an error; it is a /value/ that reduces to itself.

If =f= is a "partial" function and =f x= is "undefined", then =f x= is not an error; it is a /value/ that reduces to itself.

I think that type systems should be /separate/ from languages (that is, type systems should be Curry-style, not Church-style; that is, Erlang-Dialyzer-style, not Haskell-style).
Users should be able to write their own type systems.
But even an interpreter has an implicit type system.
** Compiling HWOT to Haskell?
1. Write "crazy" programs in HWOT.
1. Translate it to Haskell.
1. ???
1. PROFIT
* A set-theoretic programming language?
(A mess. Do not see.)

Titles?
- Lambda-calculus with functors and monads
- Lambda-calculus with built-in functors and monads
- Restricted set theory instead of type theory?

To-do:
- How is this language better than Haskell?
- How is this language worse than Haskell?
- Proof-of-concept implementation (interpreter from the semantic equations)

The key idea is to involve functors and monads in the denotational semantics of the language.

The type theory is a restricted set theory whose membership-check is practical.

We define a programming language.
The idea seems very similar to SETL[fn::https://en.wikipedia.org/wiki/SETL][fn::https://en.wikipedia.org/wiki/Set_theoretic_programming].

We begin with lambda calculus, and we add strings, sets, sequences, and builtins.

TODO switch to logical structure formalism \((D,I,f_1^{m_1},\ldots,R_1^{n_1},\ldots)\)?
** The universe of values, the domain of discourse
The universe (the domain of discourse) is \(D\).
- If \(x\) is a string, then \(x \in D\).
- If \(x\) is a set, then \(x \in D\).
- If \(x\) is a sequence, then \(x \in D\).

A relation is a sequence (domain,codomain,subset) of length three.
A lambda abstraction expression is an expression, not a function.

Some axioms:
\begin{align*}
\forall A \quad D \cup A = D
\end{align*}

\(
\newcommand\semantics[1]{\langle #1 \rangle}
\newcommand\bigsemantics[1]{S\left(#1\right)}
\newcommand\universe{\Omega}
\)
** The abstract syntax and semantics
*** Summary of the semantics of the programming language's abstract syntax
Notations:
\begin{align*}
F(X,Y) &= (F(X))(Y) & \text{currying}
\\ A \to B \to C &= A \to (B \to C)
\\ [D,C,F]x &= y \text{ such that } (x,y) \in F & \text{function application}
\\ B[P := X] &= \text{\(B\) with each free \(P\) replaced with \(X\)} & \text{substitution}
\end{align*}

Laws:
\begin{align*}
\\ (A \cup B) \cup C &= A \cup (B \cup C) & \text{associativity of set union}
\\ (A \times B) \times C &= A \times (B \times C) & \text{associativity of Cartesian product}
\\ \universe \to \universe &\subset \universe
\end{align*}

The trivial stuffs:
\begin{align*}
\semantics{\{\}} &= \{\} & \text{empty set}
\\ \semantics{\universe} &= \universe & \text{universe}
\\ \semantics{\{A\}} &= \{ \semantics{A} \} & \text{singleton set}
\\ \semantics{A \cup B} &= \semantics{A} \cup \semantics{B} & \text{set union}
\\ \semantics{A \times B} &= \semantics{A} \times \semantics{B} & \text{Cartesian product}
\\ \semantics{[]} &= [] & \text{empty sequence}
\\ \semantics{[A]} &= [\semantics{A}] & \text{singleton sequence}
\\ \semantics{cons(A,B)} &= cons(\semantics{A},\semantics{B}) & \text{sequence construction}
\\ \semantics{uncons(F,G,L)} &= uncons(\semantics{F},\semantics{G},\semantics{L}) & \text{sequence deconstruction}
\\ \semantics{concat(A,B)} &= concat(\semantics{A},\semantics{B}) & \text{sequence concatenation}
\\ \semantics{N} &= parsenumeral(N) & \text{numeral (numeric literal)}
\end{align*}

Lambda-calculus semantics:
\begin{align*}
\semantics{P \mapsto B} &= [\universe,\universe,\{(x,\semantics{B[P:=x]}) ~|~ x \in \universe \}] & \text{lambda abstraction}
\\ \semantics{F(X)} &= (\semantics{F})(\semantics{X}) & \text{function application}
\end{align*}

Function spaces:
\begin{align*}
\semantics{A \to B} &= \{ [\semantics{A},\semantics{B},F] ~|~ F \subseteq \semantics{A} \times \semantics{B}, ~ F \text{ is functional} \}
\\ F \text{ is functional} &\equiv \forall x \forall y \forall z (F(x,y) \wedge F(x,z) \to y=z)
\end{align*}

We extend the notion of "application" from functions to also include functors, in the type level.
If \(f : A \to B\), \(x : F(A)\), and \(F = functor(M,m)\), then \(x : M(A)\) and \( \semantics{f(x)} = \semantics{m(f,x)} \).

The expression \(x:T\) is the same as \(x\) but also asserts \(x \in T\) to the domain-checker.

A /triple/ is \((D,C,S)\).
Such triple can be thought as a relaxed/generalized/improper /relation/.
If \(S\) is functional, then the triple is a function.
Such function is /partial/ iff \(\exists x \exists y : D(x) \wedge \neg S(x,y)\).
Such function is /deceptive/ iff \(\exists x \exists y : \neg C(y) \wedge S(x,y)\).
\begin{align*}
\exists x \in D (\neg \exists y S(x,y)) && \text{partial}
\\ \exists y \not \in C (\exists x S(x,y)) && \text{deceptive}
\\ \exists x \not \in D (\exists y S(x,y)) && \text{superfluous}
\end{align*}
A superfluous function has unnecessary mapping.

If each of \(D,C,S\) is finite, it is straightforward to check a function application.

#+BEGIN_EXAMPLE
extend [D, Maybe C, F] = [
    Maybe D,
    Maybe C,
    F \union { [Nothing, Nothing] }
]

extend [D, Risky E C, F] = [
    Risky E D,
    Risky E C,
    F \union { [Left, e] | e \in E }
]
#+END_EXAMPLE

We replace subtyping with subsetting.

Because \(A \subseteq Maybe(A)\), each element of \(A\) can be passed to a function whose domain is \(Maybe(A)\).

Superfluous functions are harmless if we do domain check at each function application.

In this programming language, every functor is an endofunctor of Set.
Such functor is \((F,m)\) where \(F : Set \to Set\) and \(m : \forall A \forall B . (A \to B) \to (FA \to FB)\) such that
\(m(id) = id\) and \(m(f \circ g) = m(f) \circ m(g)\).[fn::https://en.wikipedia.org/wiki/Functor]

In this programming language, two endofunctors \(F\) and \(G\) are /adjoint/ iff
there is an isomorphism (bijection) between \(FY \to X\) and \(Y \to GX\), for all two sets \(X,Y\).
It seems that adjunctions don't work with endofunctors:
we would have to find mutually inverse functions
\(p : \forall X \forall Y . FY \to X\) and \(q : \forall X \forall Y . Y \to GX\).

A /natural transformation from endofunctor \(F\) to endofunctor \(G\)/ is a function \(\eta : \Pi \alpha . F(\alpha) \to G(\alpha)\) such that
\(\eta(Y) \circ \mu_F(f) = \mu_G(f) \circ \eta(X)\) for every \(f : A \to B\).
An example is \( \eta(a) : risky(e,a) \to maybe(a) \).
What?[fn::https://en.wikipedia.org/wiki/Natural_transformation]

#+BEGIN_EXAMPLE
class (Functor f, Functor g) => NaturalTransformation f g where
    eta :: f a -> g a -- where eta . fmap f = fmap f . eta

class NatTrans f g where
    eta :: f -> g

instance NaturalTransformation Identity Maybe where
    eta (Identity x) = Just x

instance NaturalTransformation (Either e) Maybe where
    eta (Left _) = Nothing
    eta (Right x) = Just x

instance (Monoid e) => NaturalTransformation Maybe (Either e) where
    eta (Just x) = Right x
    eta Nothing = mempty
#+END_EXAMPLE

A monad is \((F,m)\) where \(FFX = FX\).
An example monad is \(F(X) = 2^X\) (power set-ing).
*** What?
We write \(M(A)\) or \(MA\) to mean "the meaning of \(A\)".
\(M\) is not a function; it is just a notation.
The meaning depends on context.
The context contains name bindings.
*** Literal expressions
The /universe literal expression/ ~\universe~ means \(D\).

A /string literal expression/ ~\string what~ means =what= itself.
*** Lambda expressions
A /lambda abstraction expression/ ~\lambda a b~ means a subset of \(D \times D\) according to beta-reduction.
Thus, if \(L\) is such expression, then \(M(L)\) is not a function, but \((A,B,M(L))\) is a function if it domain-checks.

An /application expression/ =\app f x= means \((Mf)(Mx)\).
Every application expression is /domain-checked/.
\(Mf\) has to be a function (a triple).

A /substituting expression/ =\subst name= means the meaning of that name as bound by the nearest lambda abstraction that bounds that name.
*** Set expressions
A /set expression/ =\set a b c ...= means the set \(\{M(a),M(b),M(c),\ldots\}\).

A /set union expression/ =\union A B ...= means \(M(A) \cup M(B) \cup \ldots\).

A /Cartesian product expression/ =\times A B ...= means \(M(A) \times M(B) \times \ldots\).
*** Sequence expressions
A /sequence expression/ =\seq a b c ...= means \([M(a),M(b),M(c),\ldots]\).

A /sequence concatenation expression/ =\concat a b c ...= means \(M(a)+M(b)+M(c)+\ldots\) where \(+\) is sequence concatenation.

A /sequence projection expression/ =\project n s= means \(\pi_n M(s)\) (the \(n\)th component of \(M(s)\)) where \(n\) starts from one.
*** Logical expressions
=\member=

=\and=

=\or=
*** Builtins
=\println= for testing purposes only.

=\procedural= executes sequentially.

#+BEGIN_EXAMPLE
(\procedural
  (\println 1)
  (\println [2 3 4])
  (\println {5 6 7})
)
#+END_EXAMPLE
** The concrete syntax
Convenience concrete syntax:
- ~\let name = what in exp~ means ~(\ name -> exp) what~
- =\with= means chained =\let=
** Motivation: Monads in set-theoretic lambda-calculus?
We want \(Maybe(A) = A \cup \{Nothing\}\) for each set \(A\).
It follows from that definition that:
\begin{align*}
A &\subseteq Maybe(A)
\\ Maybe(Maybe(A)) &= Maybe(A)
\end{align*}

We want \(Risky(A,B) = \{ (Fail,a) ~|~ a \in A \} \cup B\) for each set \(A\) and each set \(B\).
It follows from that definition that:
\begin{align*}
B &\subseteq Risky(A,B)
\\ Risky(A,Risky(A,B)) &= Risky(A,B)
\end{align*}

Thus \(Maybe : D \to D\) and \(Risky : D \to D \to D\).

Risky is similar to Haskell Either, but the name "Risky" makes it clear that the parameters are not interchangeable.

#+BEGIN_EXAMPLE
(\with
  ( A {0 1}
    B {0 1}
    Maybe [\universe \universe (\ a (\union $a {Nothing}))]
    F [$A $B {[0 1] [1 0]}]
    G [($Maybe $A)
      (\union $B {none})
      (\union (\mapping $F) {[Nothing none]})]
  )
  (\and ($F 0 1) ($F 1 0))
)
#+END_EXAMPLE

A /relation/ is a triple \((A,B,R)\) where \(R \subseteq A \times B\).
We write \(R(x,y)\) to mean \((x,y) \in R\).

\((A,B,R)\) is a /subrelation/ of \((A',B',R')\) iff \(A \subseteq A'\), \(B \subseteq B'\), \(R \subseteq R'\), and \(R' \subseteq A' \times B'\).

A /monad/ (in the category of sets) is \((M,r,j)\) where
\(M : \Omega \to \Omega\),
\(r : \forall A . A \to M(A)\),
\(\forall X : M(M(X)) = M(X)\).

A monad maps each relation \((A,B,R)\) to \((MA,MB,LR)\) where
\(A \subseteq MA\), \(R \subseteq LR\), \(p : A \to MA\), \(j : MMA \to MA\).

If a hole expects an element of \(A\), then it accepts an element of \(A' \subseteq A\).

Abdullah's law of continuity:
#+BEGIN_EXAMPLE
extend return = id

extend : (a -> m b) -> (m a -> m b)
return :          a -> m a
id     :        m a -> m a
#+END_EXAMPLE
* A mess; do not see
** Open ADTs (algebraic data types)
   :PROPERTIES:
   :CUSTOM_ID: open-adts-algebraic-data-types
   :END:

- "Closed" means "defined in one place".
- Open ADTs don't mix with exhaustive case analysis (function totality).

  - https://stackoverflow.com/questions/870919/why-are-haskell-algebraic-data-types-closed
  - But what if functions are "open" too?

    - https://www.andres-loeh.de/OpenDatatypes.pdf

- If =f : a -> b=, then the compiler should infer =lift f : (Monad m) => m a -> m b=.

** Can we extend Haskell to "auto-fmap"?
   :PROPERTIES:
   :CUSTOM_ID: can-we-extend-haskell-to-auto-fmap
   :END:

- Possibilities:

  - Add rewrite rules so that the compiler "recovers" from some type "errors".
  - Extend the syntax and semantics of function application.

- Related

  - 1989, article, Wadler, "Theorems for free!"
  - The Haskell Djinn can, given a type T, infer/construct a term having type T.

- Recovering from some type errors

  - Idea

    - Extend Haskell with "implicit injections".
    - The compiler should try in-scope injections automatically when there is a typing error, before quitting with a type error.

      - Isn't this similar to Scala implicits and implicit conversion?

        - I forgot who, but I think somebody on the Internet said that Scala implicits are a way for the compiler to recover from type errors.

    - Can we do this on GHC?

      - https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/TypeChecker

        - GHC typechecker works on Haskell before it's transformed to Core.

      - Write a plugin for GHC?

        - Can a GHC modify the syntax tree on type error?

      - Use GHC as library?
      - We can't use GHC rewrite rules because they are only applied when optimization is enabled.

  - Define the concept of "expected type".
  - Let =e= be an expression.
  - Let =f : a -> b=.
  - Let =m= be an instance of Monad.
  - If =e= has type =a=, but the compiler expects =e= to have type =m a=, then the compiler shall rewrite =e= to =return e=.
  - If =e= has type =m a=, then the compiler rewrites =f e= to =map f e=.

- If =x= is a Monad, then these are two /different/ things: =x : a= and =return x=, but they are related, in the sense that they are equivalent, in the sense that one is trivially computable/derivable from the other.
- Can Strathclyde Haskell Enhancement (SHE) do this?

  - It has idiom brackets.
    It translates =(| f a1 ... an |)= to =pure f <*> a1 <*> ... <*> an=.

    - https://personal.cis.strath.ac.uk/conor.mcbride/pub/she/idiom.html

  - Enhancement to SHE https://github.com/bezirg/she

    - http://blog.bezirg.net/posts/2013-08-03-enhancement-to-the-strathclyde-haskell-enhancement.html

- https://en.wikipedia.org/wiki/Bidirectional_transformation

  - https://www.cis.upenn.edu/~bcpierce/papers/lenses-etapsslides.pdf

** Auto-lifting (and therefore sequencing) of function application involving Monad instances
   :PROPERTIES:
   :CUSTOM_ID: auto-lifting-and-therefore-sequencing-of-function-application-involving-monad-instances
   :END:

- The standard rule is:

  - If =x : a= and =f : a -> b=, then =f x : b=.

- Suppose that =m= has a Monad instance.

  - If =x : m a= and =f : a -> b=, then should the compiler silently translate =f x= to =x >>= return . f=?

    - Isn't it the only desirable way of putting together =f= and =x=?

      - Monad class requires that =x >>= return . f= be equivalent to =fmap f x=.

        - So there is really only one way to do it, isn't it?

      - Examples of non-desirable ways: =unsafeCoerce=, =undefined=.

  - Should the compiler also appropriately translate =f x= for all these combinations?

    - Possibilities for the type of =x=:

      - =a=
      - =m a=

    - Possibilities for the type of =f=:

      - =a -> b=
      - =a -> m b=
      - =m (a -> b)=
      - =m a -> m b=
      - =m a -> b=

- At first glance it seems convenient, but what are the consequences?

  - Some I can think of

    - Confusing error message

      - Suppose:

        - The programmer makes a typing mistake.
        - The compiler infers the wrong type.
        - The compiler performs translation based on the wrongly inferred type.
        - The compiler produces a confusing error message.

** Equirecursive types?
   :PROPERTIES:
   :CUSTOM_ID: equirecursive-types
   :END:

Haskell has isorecursive types.
Can we make it use equirecursive types?

- Can we make it automatically insert roll-unroll/fold-unfold/In-out?
- How do we compose monads seamlessly?

  - Isorecursive types?
  - True sum types (untagged unions)?

- "System F-omega with Equirecursive Types for Datatype-Generic Programming"?
** <2018-12-15> Bootstrap GHC?
https://twitter.com/ErikDominikus/status/1073726987338842112

How about writing a Haskell interpreter with Prolog?
I guess Haskell type checker takes ~100 lines of Prolog, and parser takes ~200 lines.
It may be doable in a month.
I have ~20 lines of Prolog type-checking Haskell AST but without type classes.

Add ~500 more lines of Prolog metaprogram for translating lists to arrays,
~2000 more lines for translating Prolog to optimized x86_64 native code (if not reinventing LLVM), 1 more month, and ... we may beat GHC at its own game? :)

\chapter{Wonderings}

\section{Reading list}

Statistical learning

Deep learning \cite{DeepLearning}

Inverse problem theory \cite{tarantola2005inverse}

? \cite{DeepArch}

? \cite{RepLearn}

? \cite{SuttonBartoRein}

? \cite{SepLogicAi}

Wiener cybernetics book? \cite{WienerCyber}

approximation theory? \cite{ApproxThePrac}

Semi-supervised learning?

\section{Adversarial random process}

\(P\) tries to predict \(G\).
\(G\) tries to make \(P\) wrong.

\section{What is rational?}

\section{Moravec's paradox}

\section{Neural networks}

Neural networks is one architecture that makes machine trainable.
Neural network is not necessarily the best architecture for intelligence.
Evolution is a greedy optimization algorithm.

\section{What is a fractional iterate? (unrelated)}

We generalize \(f^p\) for real \(p\).
\begin{align*}
    f^2 &= f \circ f
    \\
    f^{1/2} \circ f^{1/2} &= f
\end{align*}

If \(f~x = x \uparrow a\) then \(f~(f~x) = (x \uparrow a) \uparrow a\).

What is a \(g\) that satisfies \(g~(g~x) = x^a\)?

What does \(d~(p \to f^p)\) even mean?
The \(d\) is differential operator.

% http://math.stackexchange.com/questions/676229/fractional-composite-of-functions

% https://en.wikipedia.org/wiki/Iterated_function#Fractional_iterates_and_flows.2C_and_negative_iterates

Topologically, a neural network layer is a continuous map.
It transforms the input space into a more separable space.
Consider the set of points that satisfy the classifier.
This set is a manifold.
A neural network layer stretches, rotates, manipulates that manifold.
The output wants to be box-shaped.
But isn't this just the idea of Kohonen's self-organizing maps?

\chapter{Other handy stuffs}

DeepMind is transfer learning:
let an AI learn in virtual environment,
then move it into the real world.

\section{Corpuses, datasets, training sets}

MNIST handwritten digit dataset.

%OpenCog
%http://opencog.org/about/

\chapter{Making machines work}

There are several ways to make machines work:
program them, train them, or make them learn.
Programming and training produce inflexible machines
that cannot do things that they are not programmed or trained for.

\section{Programming}

\section{Training}

\section{Learning}

\section{Delayed signal thought experiment}

Imagine that you install something in your brain that delays the signal to your left hand by one hand,
so your left hand does what you want it to do, but one second after when you want it to do that.
Would you still think your left hand is a part of your self?

If a machine does not have any way of sensing touch, even indirectly,
then it will never experience touch.

\section{Signs of intelligence}

Imitation and survival?

Imitation implies intelligence?
For \(a\) to be able to imitate \(b\),
\(a\) has to have a model of \(b\).

If the only goal is to survive, then wouldn't the best strategy be
make as many copies as many as possible?

Make copies, as fast as possible, as many as possible.

Arrange for the species to maximize the number of copies that live at the same time.

Make an organism as fit as possible.
Make an organism survives as many environments as possible,
including the environments it did not originally evolve from.
A sign of intelligence is that the organism can
perform well in environments it had never encountered before.

\section{Related concepts}

intelligence, learning, self, consciousness, sentience, life, perception,
adaptivity, adaptability, adaptation, control, language, thought, feeling, reasoning, discovery,
recursion, feedback, computation, computability.

\section{Interesting idea}

Strategy 1:
Given two nouns \(a\) and \(b\), find a verb \(v\) such that the sentence \(a~v~b\) makes sense.
Strategy 2:
Given two nouns \(a\) and \(b\), pick which of these two sentences make sense:
``\(a\) requires \(b\),'' or ``\(a\) does not require \(b\).''

An early `intelligence' is chemotaxis.
Chemotaxis is random walk that is biased by the gradient. (Cite?)
The deterministic version of that is gradient following algorithm.
The goal is to minimize the concentration of the chemical at the location of the cell.

Control system. Homeostasis.

Deduction: Given premises, infer conclusion.
Induction: Given a few premises and a conclusion, infer a rule.

Probabilistic logic.
Generalize boolean \(\{0,1\}\) to probability, real unit interval, \([0,1]\).
Boolean logic is a special case of probabilistic logic.
\(p~(x \wedge y) = \min~(p~x)~(p~y)\).
Fuzzy logic?

``To organize is to create capabilities by intentionally imposing order and structure.'' \cite{Organ}

\section{Cybernetics}

How can we apply systems theory to management? \cite{SystemManage}

Ashby's optical mobile homeostat
\cite{BattleHom}
\cite{BattleThree}

Braintenberg vehicles

A G\"odel machine improves itself.
It proves that the improvement it makes indeed makes it better.
\cite{GodelMachImpl}

% http://people.idsia.ch/~juergen/goedelmachine.html
% http://people.idsia.ch/~juergen/selfreflection.pdf
% http://people.idsia.ch/~juergen/metalearner.html

Steinberg and Salter (1982)
wrote that intelligence is ``goal-directed adaptive behavior''.
This suggests that an intelligent system is purposeful and adaptive,
in the sense we defined above.
%https://en.wikipedia.org/wiki/Intelligence#Definitions

% Intelligence maximizes future freedom?
% https://www.ted.com/talks/alex_wissner_gross_a_new_equation_for_intelligence/transcript?language=en#t-121478

\cite{PickeringCyber}
\cite{GoertzelAgi}
\cite{SlomanTuringIrrelevance}

Algorithmic information theory
\cite{AlgoInfTh}

Giulio Tononi, integrated information theory
(not to be confused with information integration theory)

Nils J. Nilsson modeled a world and an agent as finite-state machines \cite{NilsLogicAi}.
He used explicit sense type, action type, and memory type.
William Ross Ashby used the phase space of a continuous dynamical system,
where time is a real number,
to describe an agent's behavior \cite{AshbyBrain}.

\section{Supervised classification problems}

AI shines in supervised classification problems.
Machine vision.

Digit recognition is classification problem.

\section{Classification involving sequence or time}

\chapter{Fields of study related to intelligence}

AI is about making something
that is as intelligent as a human brain
without caring about how human brain works.
Cognitive neuroscience is about how a human brain works.

\section{Connectionism}

\section{Brain is a vector function}

\section{Machine learning}

Machine learning makes machine do things from examples.

\section{Connectionism}

\section{Computational neuroscience}

\section{Cognitive neuroscience}

Cognitive neuroscience tries to understand how brains work.
The organism with central nervous system with the fewest neurons is \species{Caenorhabditis elegans}.
You can create your own virtual \species{Caenorhabditis elegans} online at \cite{openworm}.

In rats, neuron firing rate encodes posterior probability (expected value)?
(Cite?)

Neural coding tries to find out how neurons encode information.
Are neurons digital, analog, or both?
Spike train?

Digit-recognizing neural network performs generalization/induction.

Decoding mental states from brain activity in humans \cite{haynes2006decoding}

\section{Imagination is as real as perception}

Imagining a thing excites the same neurons as perceiving that thing.
Therefore if we have a very good mental model,
we should be able to perform experiments in our imagination
and translate the results to the real world.

Imagine that an intelligent machine existed,
and then work our way back.
Invent a story about how we would get there.

\section{Materials looking for a place to belong}

Logic has \emph{syntax} (form) and \emph{semantics} (meaning).
Grammar determines the \emph{well-formed formulas}.
Semantics maps a well-formed formulas to an \emph{interpretation}.
(What are the terms? Mathematical logic lecture notes or book?)

\index{extension of a predicate}%
The \emph{extension} of a predicate \(p\) is \(\{x~|~p(x)\}\).

\index{normal form!Skolem}%
\index{Skolem normal form}%
\index{Skolemization}%
\index{Skolemized formula}%
A formula in first-order logic is \emph{Skolemized} or is in \emph{Skolem normal form}
iff it has the form \(\forall x_1 \ldots \forall x_n ~ M\)
where \(M\) is a quantifier-free formula in conjunctive normal form.
A formula is in \emph{conjunctive normal form} iff ...
% http://mathworld.wolfram.com/SkolemizedForm.html
\index{Herbrand universe}%
A \emph{Herbrand universe} is ...
\index{interpretation}%
An \emph{interpretation} is ...
A \emph{formal system} is ...
A \emph{formal language} is ...

\index{Curry-Howard correspondence}%
\emph{Curry-Howard correspondence} relates logic and type.
A value \(x : T\) is a proof the logic formula isomorphic to \(T\).

\section{Genetic algorithm}

\newcommand\fit{\fun{fit}}
\newcommand\mate{\fun{mate}}
\newcommand\pop{\fun{pop}}
\newcommand\sur{\fun{sur}}
\newcommand\Pop{\fun{Pop}}

A \emph{genetic algorithm} is an iterated randomized mixing filtering optimization.
Generalized genetic algorithm:
Let \(\Pop\) be the population type.
Let \(t : \Nat\) be time.
Let \(\pop~t : \Pop\) be the population at time \(t\).
Let \(\fit : \Pop \to \Pop\) be the fitness filter a.k.a. selection function a.k.a. selection pressure function.
Let \(\mate : \Pop \to \Pop \to \Pop\) be the next-population function,
including mutation, birth, death, mating.
Let \(\sur~(t+1) = \fit~(\pop~t)\) be the survivor set at time \(t+1\).
The algorithm is the equation \(\forall t \in \Nat : \pop~(t+1) = \sur~(t+1) + \mate~(\pop~t)\).
Observe the sequence of populations \(\pop~0, \ldots, \pop~t\).
A genetic algorithm, an iterated search algorithm, is a mono-unary algebra.
Genetic algorithm is like tree search.
The mating function is the fringe function.
A genetic algorithm is a stochastic process.
A genetic algorithm takes a filtering and mating algorithm and produces a search algorithm.

Simulated annealing.

Randomized search algorithm.

\section{Draft}

Is a company, which consists of undoubtedly intelligent people, intelligent?

Alan Turing proposed the Turing test.

Intelligence is what intelligence tests measure.

I think we use the word `intelligence' to refer to a stabilizing behavior
that is complex enough to elude a simple explanation.

I think we agree that we are intelligent.

We cannot know if something is intrinsically intelligent.
We can only determine intelligence from what we can observe.

\section{How do we determine how intelligent something is?}

An intelligent being may elude detection by pretending to be unintelligent.

\section{The brain at a time is a big array function.}

Can we formulate it in a way that does not depend on linear time?

\section{Control needs feedback.}

There is also open-loop or feed-forward control,
but complex control needs feedback.

\section{Consciousness}

Consciousness needs sensory input.

Consciousness needs feedback.

Self concept needs feedback.

If there is not a feedback, a system cannot distinguish itself from its environment.
The self concept will never arise.

If a brain can immediately control a thing,
then that thing is part of the brain's self concept.
If the brain can't, it's not.

If a brain often gets certain input shortly after it produces certain output,
it will associate the output with its self concept.

The self is the thing under conscious control.

\section{Intelligence is a spectrum.}

Is a human intelligent?

Is a rock intelligent?

A human is more intelligent than a rock.

Is a human pretending to be a rock intelligent?

Can an intelligent system look non-intelligent (hide its intelligence)?

We can measure intelligence as numbers.

Intelligence needs learning.

Adapting needs learning.

We say X adapts to Y iff Y surprises X less as time goes by. (Whose idea is this?)

Intelligence needs state.

State needs time.

\section{Intelligence is control.}

An intelligent system is a special case of control system.

\section{Intelligence is relative.}

Intelligence relative to something is a real number.

\section{Intelligence needs the ability to adapt.}

\section{Every software system is a state machine.}

\section{Curry's Y combinator makes a fixed point equation}

\section{What are the limits of intelligence?}

\section{Phase-space learning?}

There is a boundary: the agent, and the environment.
How many functions do we need to model it?

One function that is an endofunction of phase space.
The agent state is a subspace of that phase space.
The environment state is another subspace of that phase space.

The idea is to represent the how the phase space changes in a small time.
The number of variables should equal to the degree of freedom of the system.

\section{What are the ways of describing a system?}

\begin{itemize}
    \item function from time to state
    \item endofunction of phase space
\end{itemize}

State space and phase space are the same.
State space is for discrete systems.
Phase space is for continuous systems.

\section{What fields does this book depend on?}

Topology \cite{Topology}

Functional analysis

Dynamical system

Control theory

Fixed point theory

Neurophysiology

Computer science

Cybernetics

% https://en.wikipedia.org/wiki/Connectionism
% https://en.wikipedia.org/wiki/Cybernetics

Biological neuron model
% https://en.wikipedia.org/wiki/Biological_neuron_model

An introduction to mathematical physiology
% https://people.maths.ox.ac.uk/fowler/courses/physiol/physiolnotes.pdf

Learning and Transfer of Learning with No Feedback: An Experimental Test Across Games
% http://repository.cmu.edu/cgi/viewcontent.cgi?article=1040&context=sds

Perceptual learning without feedback in non-stationary contexts: Data and model
% http://socsci-dev.ss.uci.edu/maplab/webdocs/petrovdosherlu06.pdf

Neural coding
% https://en.wikipedia.org/wiki/Neural_coding

Pulse-frequency modulation in brain neurons

Reward system

\section{R2 = R}

There is a bijection between \(\Real^2\) and \(\Real\).
We do this by interleaving the digits.
\[
    (x, y) \leftrightarrow \ldots X_2 Y_2 X_1 Y_1 X_0 Y_0 . x_1 y_1 x_2 y_2 x_3 y_3 \ldots
\]

\section{Supervised to unsupervised}

Can a supervised learning algorithm always be made into an unsupervised learning algorithm?

\section{Approximation to optimization}

Can an approximation scheme always be made into an optimization scheme?

\section{Optimal clustering}

Given a set of points, what is the optimal clustering/partition?

\section{Optimal approximation}

Given a set of points
\(\{(x_1,y_1),\ldots,(x_n,y_n)\}\)
(samples of a function),
what is the function that optimally approximates those samples?
The approximation error is \(\sum_k y_k - f~x_k \).
Let \(F\) be the set of all integrable real-to-real functions.
Define \(M~f = \int_{-\infty}^\infty f~x~dx\) as the infinite integral of \(f\).
Define the complexity of \(f\)
as \(C~f = \sum_{k=1}^\infty M~(D_k~f)\)
where \(D\) is the derivative operator.

\section{Meta-approximation}

Given set of points
\(D = \{(x_1,y_1),\ldots,(x_n,y_n)\}\),
find \(g\) that finds \(f\) that approximates \(D\).

Let \(F\) be the set of all real-to-real functions.
Can we craft a measure on \(F\)?
Can we craft a probability measure on \(F\)?
Can we craft a universal prior for \(F\) like Solomonoff did for bitstrings?

What is the best way to update the approximator using the approximation error?

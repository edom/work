\chapter{Opinion}

\section{Immortality}

If we want to be immortal,
we should invest in AI so we can create a machine scientist
and let it find out a biological way of making us immortal.

\section{AI vs Semantic Web}

Semantic Web puts the burden on humans to structure data in machine-friendly format.
Every other AI researcher is trying to make machines understand unstructured data.

\section{Finding out if we are in a simulation}

To find out if we are a simulation,
look for numerical errors in the Universe.
\cite{UniNumError}

\section{Trust in early development}

Can we spend 20 years to raise an AI the way we raised a human child?

Children trust everything they are told.
Young AI must also.
If a child is brought up with lies, taught the wrong thing,
it will need to unlearn when it is adult.

We cannot know a human is intelligent before we test
that human in the environment we are interested in.

\section{Consciousness}

My consciousness is tied to my body.
When I sleep, my consciousness pauses.

Imagine something.

Imagine that you are imagining something.

Imagine that the imagined you are in turn imagining something else.
Is this even possible?

To manipulate your consciousness,
you must consciously intend to manipulate your consciousness.
Can you consciously manipulate your consciousness?

\section{Problem theory}

Everything can be stated as problem solving.

A problem has solutions.
A solution removes the problem.

Write a program for each problem,
or write a program that is general enough to solve all problems.

We can measure the intelligence of a system by what it does to vast data.

Let us have many brains with the same inputs.
Which brain is more intelligent than which?

If intelligence is goal-directed behavior, what is the goal of a human?

The goal of chemotaxis is survival.

The goal of living beings is survival.
But this is false. Otherwise there will not be suicide.

How do we explain self-destructive organisms such as smokers and drug abusers?
What are their goal?

The goal is to minimize the concentration of certain substance in the brain in the long term.

\section{Automated reasoning}

% http://math.stackexchange.com/questions/116827/how-to-start-with-automated-theorem-proving
% https://en.wikipedia.org/wiki/Mizar_system
% https://proofwiki.org/wiki/Main_Page

A \emph{prover} or an \emph{automated theorem prover} takes a logical statement
and proves it.
Example: ACL2, Prover9.

A \emph{proof assistant}
or an \emph{interactive theorem prover}.
takes a logical statement and a partially completed proof,
and interacts with a human to complete the proof.
Example: Isabelle, Coq, Idris.

A \emph{checker} or a \emph{automatic proof checker} takes a proof and indicates whether it is correct.

\section{Goal of human}

The goal of human is to understand reality, to model reality, to predict the future, or to invent the future.

\section{Alpha-normalized lambda calculus}

The syntax for an expression is \(E ::= V ~|~ EE ~|~ (\lambda N . E) \)
where \(N\) is a natural number.
Two variables refer to the same thing if and only if their natural number is the same.

This algorithm alpha-normalizes a lambda calculus expression:
Find a lambda abstraction.
Replace all occurrence of that bound variable with a fresh number.
Repeat until there is no unreplaced lambda.

\begin{align*}
    v : V &\vdash \normalize~n~v = v
    \\
    &\vdash \normalize~n~(\lambda x.y) = \lambda n. ~ \normalize~(n+1)~(y[x := \Var~n])
\end{align*}
The expression \(y[x := a]\) means \(y\)
with all free occurrences of \(x\) replaced with \(a\).

This reduces:

Let \(c\) be context.
Let \(c[k := x]\) mean \(c\) but with element at index \(k\) replaced with \(x\).
Let \(y = \beta~c~x\) means that \(x\) reduces to \(y\) under context \(C\).
\begin{align*}
    v : V \vdash \beta~c~v = v
    \\
    \beta~c~(\Var~n) = \beta~c[n := \beta~c~c[n]]~c[n]
    \\
    \beta~c~((\lambda n. b)~a) = \beta~c[n := a]~b
\end{align*}

\emph{Every variable is reduced at most once.}

Is there a stronger: Every (sub)expression is reduced at most once?

\section{Intelligence}

In a biological organism, the goal is to survive.

The brain learns the concept of self by using feedback
to determine what it can directly control
and what it cannot directly control.
What it can directly control becomes a part of its self.
What it cannot directly control becomes a part of non-self.
According to this theory, a person driving a car
should act as if the car were a part of that person's self.
If machines have a direct brain interface,
we should be able to extend or shrink what a person thinks that person's self is.

If a child is born without any senses at all,
the brain does not have feedback.
The brain will not develop a self concept.

Pedro Domingos said
"AI is the automation of discovery." (?)
in his 2015 Google Talk about his book ``The master algorithm''.
He writes about the five tribes of AI.
Those five tribes are Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers.
% https://www.slideshare.net/SessionsEvents/pedro-domingos-professor-university-of-washington-at-mlconf-atl-91815

Clark Glymour gave several examples of what I call `machine scientists'.
\cite{GlyAutoDisc}

\section{Chunk}

Learning:
Given sample, infer something about the population.

Evolution must hardwire procreation to feel good;
otherwise the species will avoid procreation,
and it will go extinct.

Machine constructs mental model of the world through its senses,
and then revise its model.
It can predict the result of activating certain actuators.
Language is part of the mental model.
A sufficiently advanced machine may internally form a language.

Ancient humans knew that fire is hot.
They just didn't have words to express that fact.
A modern human who have never experienced a fire
wouldn't know that fire is hot,
even though he can read the text ``fire is hot'',
but all he would know is that fire is a thing, and hot is an adjective.

We can only know something in relation to other things.
We understand that fire is hot because we understand the consequences:
fire is bright, heat cooks food.

There is no way to solve a Rubik's cube quickly with just intuition.
The only way to do that is to follow an algorithm.
You must think abstractly.
You must translate the problem into mathematics,
and then translate the mathematics back into the problem.

An advanced machine would invent mathematics.
An advanced machine would invent a priori knowledge.

A human can learn from just some samples;
see a similar thing three times and someone would guess that there's a pattern.
Sometimes this worked too well: people see patterns when there aren't any;
pareidolia.
It's just a consequence of the architecture of the brain.
The brain is hardwired to recognize patterns.

Statistics can suggest whether a signal is analog or digital.
This has been applied to brain signals. \cite{mochizuki2014analog}

\chapter{Wonderings}

\section{Reading list}

Statistical learning

Deep learning \cite{DeepLearning}

Inverse problem theory \cite{tarantola2005inverse}

? \cite{DeepArch}

? \cite{RepLearn}

? \cite{SuttonBartoRein}

? \cite{SepLogicAi}

Wiener cybernetics book? \cite{WienerCyber}

approximation theory? \cite{ApproxThePrac}

\section{Adversarial random process}

\(P\) tries to predict \(G\).
\(G\) tries to make \(P\) wrong.

\section{Immortality}

If we want to be immortal,
we should invest in AI so we can create a machine scientist
and let it find out a biological way of making us immortal.

\section{AI vs Semantic Web}

Semantic Web puts the burden on humans to structure data in machine-friendly format.
Every other AI researcher is trying to make machines understand unstructured data.

\section{What is rational?}

\section{Moravec's paradox}

\section{Finding out if we are in a simulation}

To find out if we are a simulation,
look for numerical errors in the Universe.
\cite{UniNumError}

\section{Trust in early development}

Can we spend 20 years to raise an AI the way we raised a human child?

Children trust everything they are told.
Young AI must also.
If a child is brought up with lies, taught the wrong thing,
it will need to unlearn when it is adult.

We cannot know a human is intelligent before we test
that human in the environment we are interested in.

\section{Consciousness}

My consciousness is tied to my body.
When I sleep, my consciousness pauses.

Imagine something.

Imagine that you are imagining something.

Imagine that the imagined you are in turn imagining something else.
Is this even possible?

To manipulate your consciousness,
you must consciously intend to manipulate your consciousness.
Can you consciously manipulate your consciousness?

\section{Problem theory}

Everything can be stated as problem solving.

A problem has solutions.
A solution removes the problem.

Write a program for each problem,
or write a program that is general enough to solve all problems.

We can measure the intelligence of a system by what it does to vast data.

Let us have many brains with the same inputs.
Which brain is more intelligent than which?

If intelligence is goal-directed behavior, what is the goal of a human?

The goal of chemotaxis is survival.

The goal of living beings is survival.
But this is false. Otherwise there will not be suicide.

How do we explain self-destructive organisms such as smokers and drug abusers?
What are their goal?

The goal is to minimize the concentration of certain substance in the brain in the long term.

\section{Automated reasoning}

% http://math.stackexchange.com/questions/116827/how-to-start-with-automated-theorem-proving
% https://en.wikipedia.org/wiki/Mizar_system
% https://proofwiki.org/wiki/Main_Page

A \emph{prover} or an \emph{automated theorem prover} takes a logical statement
and proves it.
Example: ACL2, Prover9.

A \emph{proof assistant}
or an \emph{interactive theorem prover}.
takes a logical statement and a partially completed proof,
and interacts with a human to complete the proof.
Example: Isabelle, Coq, Idris.

A \emph{checker} or a \emph{automatic proof checker} takes a proof and indicates whether it is correct.

\section{Goal of human}

The goal of human is to understand reality, to model reality, to predict the future, or to invent the future.

\section{Alpha-normalized lambda calculus}

The syntax for an expression is \(E ::= V ~|~ EE ~|~ (\lambda N . E) \)
where \(N\) is a natural number.
Two variables refer to the same thing if and only if their natural number is the same.

This algorithm alpha-normalizes a lambda calculus expression:
Find a lambda abstraction.
Replace all occurrence of that bound variable with a fresh number.
Repeat until there is no unreplaced lambda.

\begin{align*}
    v : V &\vdash \normalize~n~v = v
    \\
    &\vdash \normalize~n~(\lambda x.y) = \lambda n. ~ \normalize~(n+1)~(y[x := \Var~n])
\end{align*}
The expression \(y[x := a]\) means \(y\)
with all free occurrences of \(x\) replaced with \(a\).

This reduces:

Let \(c\) be context.
Let \(c[k := x]\) mean \(c\) but with element at index \(k\) replaced with \(x\).
Let \(y = \beta~c~x\) means that \(x\) reduces to \(y\) under context \(C\).
\begin{align*}
    v : V \vdash \beta~c~v = v
    \\
    \beta~c~(\Var~n) = \beta~c[n := \beta~c~c[n]]~c[n]
    \\
    \beta~c~((\lambda n. b)~a) = \beta~c[n := a]~b
\end{align*}

\emph{Every variable is reduced at most once.}

Is there a stronger: Every (sub)expression is reduced at most once?

\section{Intelligence}

In a biological organism, the goal is to survive.

The brain learns the concept of self by using feedback
to determine what it can directly control
and what it cannot directly control.
What it can directly control becomes a part of its self.
What it cannot directly control becomes a part of non-self.
According to this theory, a person driving a car
should act as if the car were a part of that person's self.
If machines have a direct brain interface,
we should be able to extend or shrink what a person thinks that person's self is.

If a child is born without any senses at all,
the brain does not have feedback.
The brain will not develop a self concept.

Pedro Domingos said
"AI is the automation of discovery." (?)
in his 2015 Google Talk about his book ``The master algorithm''.
He writes about the five tribes of AI.
Those five tribes are Symbolists, Connectionists, Evolutionaries, Bayesians, and Analogizers.
% https://www.slideshare.net/SessionsEvents/pedro-domingos-professor-university-of-washington-at-mlconf-atl-91815

Clark Glymour gave several examples of what I call `machine scientists'.
\cite{GlyAutoDisc}

\section{Neural networks}

Neural networks is one architecture that makes machine trainable.
Neural network is not necessarily the best architecture for intelligence.
Evolution is a greedy optimization algorithm.

\chapter{A brain at a given time is an array function.}

A brain at a given time is an array function
having type \(\Real^\infty \to \Real^\infty\).
Each component of the input array is a signal from a sensor.
Each component of the output array goes to an actuator.

Since the brain is finite,
there must be infinitely many zeros in the input and output arrays.

\section{An array iself is also a function.}

An \(E\)-array is a function having type \(\Nat \to E\).
The input is an index.
The output is the value of the component at that index.
Subscripting denotes function application.

\section{Each brain has a maximand.}

Such maximand is a hidden function.
The brain always tries to maximize the maximand.

A differential change in brain tries to increase the maximand.
The brain follows gradient.

\section{Consider functions of length-one arrays.}

Let \(h\) be a differential change in brain.

\section{Draft}

The only way to know whether the system has learning something
is by testing it with samples the system has never seen.

Practically all machine learning cases deal with functions
that is continuous enough to form a Hilbert space.

Every classification problem in the real world can be written as \(f : I^n \to I\) for an \(n : \Nat\).
Usually \(I\) is discrete.

Consider the case where \(I = [0,1]\).
Continuous map from \(I^n\) to \(I\).
Continuous map from a hyperplane to a line.

\section{How do we relate vector functions and intelligence?}

\section{How does feedback happen in the brain?}

Feedback is due to environment and the physical laws.
When we move our hand, we see it, because the light
reflected by our hand now reaches our eyes.

The next input depends on the previous input.
\begin{align*}
    y_k &= b~x_k
    \\
    x_{k+1} &= f~x_k~y_k
\end{align*}

\section{What is a fractional iterate? (unrelated)}

We generalize \(f^p\) for real \(p\).
\begin{align*}
    f^2 &= f \circ f
    \\
    f^{1/2} \circ f^{1/2} &= f
\end{align*}

If \(f~x = x \uparrow a\) then \(f~(f~x) = (x \uparrow a) \uparrow a\).

What is a \(g\) that satisfies \(g~(g~x) = x^a\)?

What does \(d~(p \to f^p)\) even mean?
The \(d\) is differential operator.

% http://math.stackexchange.com/questions/676229/fractional-composite-of-functions

% https://en.wikipedia.org/wiki/Iterated_function#Fractional_iterates_and_flows.2C_and_negative_iterates

Topologically, a neural network layer is a continuous map.
It transforms the input space into a more separable space.
Consider the set of points that satisfy the classifier.
This set is a manifold.
A neural network layer stretches, rotates, manipulates that manifold.
The output wants to be box-shaped.
But isn't this just the idea of Kohonen's self-organizing maps?

\section{The brain is a recurrence relation.}

This pictures the brain as a parallel dataflow computer
with clock period of a few microseconds.

% https://en.wikipedia.org/wiki/Dataflow_architecture

Let \(m\) be memory, \(x\) be senses, and \(y\) be actuators.
\begin{align*}
    m_{t+1} &= f~x_t~m_t
    \\
    y_{t+1} &= g~x_t~m_t
\end{align*}

There is also a version with implicit time.
\begin{align*}
    m' &= f~x~m
    \\
    y' &= g~x~m
\end{align*}

There is also a continuous version.
\begin{align*}
    m_{t+h} &= h \cdot f~x_t~m_t
    \\
    y_{t+h} &= h \cdot g~x_t~m_t
\end{align*}

\section{The brain evolved from simpler nervous systems.}

Nervous systems are control systems.

Nervous systems must have provided some evolutionary benefit;
otherwise natural selection would have phased them out.

Bacterial chemotaxis detects chemical concentration difference.

Nematode.
Caenorhabditis elegans.

\chapter{Other handy stuffs}

DeepMind is transfer learning:
let an AI learn in virtual environment,
then move it into the real world.

\section{Corpuses, datasets, training sets}

MNIST handwritten digit dataset.

%OpenCog
%http://opencog.org/about/

\chapter{Solomonoff theory}

Why was Raymond J. Solomonoff \cite{SolAlpProb2011, GacsVitanyiSolomonoff}
interested in predicting sequences of bits?

Marcus Hutter approached intelligence from \emph{algorithmic} complexity theory (Solomonoff induction)
\cite{DefineMachIntel}.
Warren D. Smith approached intelligence from \emph{computational} complexity theory
(NP-completeness)
\cite{WdsIntel, WdsIntelSlide}

\section{Generalization of Solomonoff theory}

\newcommand\Bit{\fun{Bit}}
\newcommand\Bits{\fun{Bits}}

Let \(\Bit = \{0,1\}\).
Let \(\Bits = \Bit^*\) where \(*\) is the Kleene star.
Let \(f : \Bits \to \Bits\).
Let \(p : \Bits \to [0,1]\) be the input distribution.
Define \(q~y\) as the probability of finding an input \(x\) such that \(f~x = y\).
Solomonoff used a universal Turing machine for \(f\),
but I'm interested on the consequences of relaxing this constraint.

Bijection allows us to use \(\Nat\) or any other countable set instead of \(\Bits\).
Let \(f : \Nat \to \Nat\) be a function.
We say that \emph{\(x\) \(f\)-explains \(y\)} iff \(f~x = y\).
Let \(p : \Nat \to [0,1]\) be the input distribution.
Define \(q~y\) as the probability of finding an \(x\) such that \(f~x = y\).
We call an input such as \(x\) a \emph{hypothesis}.

\newcommand\preimage{\fun{preimage}}

Let \(f\) be a binary relation.
We define \(\preimage~f~y = \{ x ~|~ f~x~y \}\).

\section{Generalizing Kolmogorov complexity}

Schmidh\"uber generalized Kolmogorov complexity to super Turing machines \cite{SchmidhuberKolmogorov}.

The Kolmogorov complexity of a string
is the length of the shortest program that generates that string.
This complexity depends on the machine.
Formally, we define \(\kolmogorov~f~y\),
the Kolmogorov complexity of \(y\) with respect to \(f\),
as the length of the shortest \(x\) that satisfies \(f~x = y\).

We can relax the constraint of \(f\) so that \(f\)
now only needs to be a surjective relation.
We can relax it further so that it is a relation.
However, if \(f\) is not surjective,
the Kolmogorov complexity will be partial
(undefined for some inputs).
That seems to be as general as logic allows.

We can relax the measure \(m : A \to \Real\) into a function \(m : A \to B\)
and an ordering \(c\).

\[
    \kolmogorov~c~m~f = \minimumBy~c \circ \map~m \circ \preimage~f
\]

Note the notation:
If \(f\) is a binary relation,
we overload the notation \(f\)
to also mean the binary predicate
that is the indicator function of the relation \(f\).
We conflate a predicate and its extension.
We write \(f~x~y\) to mean \((x,y) \in f\).
The type of the expression \(f~x~y\) is \(\Bool\).

We can generalize Kolmogorov complexity.
Instead of a space of strings and the length of strings,
we can use a measure space.
Furthermore, we can generalize the function into relation.
Let \(m : A \to \Real\) be a measure on \(A\).
Let \(f \subseteq A \times A\) be a binary relation.
Formally,
\[
    \kolmogorov~m~f~y = \minimum~(\map~m~(\preimage~f~y))
\]
or, more pointfreely,
\begin{equation}
    \kolmogorov~m~f = \minimum \circ \map~m \circ \preimage~f
\end{equation}

We define \(\kolmogorov~m~f~y\) as the measure of an \(x\)
that both minimizes \(m\) and satisfies \(f~x~y\).
Therefore \(\kolmogorov\) is a constrained optimization problem.
The classical Kolmogorov complexity is a special case of \(\kolmogorov\)
where \(m\) computes the length of a bitstring
and \(f\) is a universal Turing machine.

The Kolmogorov complexity is incomputable due to the halting problem.
It does not even have a brute-force algorithm.
However, Levin search allows us to approximate it.

\chapter{Making machines work}

There are several ways to make machines work:
program them, train them, or make them learn.
Programming and training produce inflexible machines
that cannot do things that they are not programmed or trained for.

\section{Programming}

\section{Training}

\section{Learning}

\chapter{Designing a humanoid}

A humanoid is a human-shaped robot.

There are several choices:
Make a machine that resembles human,
Make a cyborg (a human-machine hybrid with more human part),
or Mind upload.

\section{Power plant}

It needs power plant with high power-to-mass and power-to-volume ratio
for long-time low-power and short-time burst scenario.
High-density sugar biobattery \cite{zhu2014high}.
A microbial fuel cell capable of converting glucose to
electricity at high rate and efficiency \cite{rabaey2003microbial}.
Sugar beats lithium ion.

Distributed processing, distributed energy generation.

Citric acid cycle.
Oxidative phosphorylation.

Biomachine hybrid.
A mixture of microbes and machine.

\section{Sensors}

Billions of sensors.
Light, sound, heat, itch, touch, gravity.

A strong enough brain.

How will it sustain itself?

How will it sense the world?

How will it manipulate the world?

\chapter{AI hardware design}

\section{Architecture}

Most computers in 2017 have the von Neumann architecture,
which suffers from the von Neumann bottleneck
(the limited transfer rate between CPU and RAM).
This architecture fits programming,
but it fits training less,
and it does not fit learning.
This architecture does not suit machines with billions of sensors.
This architecture does not preclude intelligence
but the bottleneck incurs a great penalty.

\section{An array of FitzHugh-Nagumo cells}

A FitzHugh-Nagumo cell is an electrical circuit implementing the FitzHugh-Nagumo model.
FHN cells can be implemented in Field-programmable Analog Array (FPAA) \cite{CircuitFitzHughNagumo}.

\section{Delayed signal thought experiment}

Imagine that you install something in your brain that delays the signal to your left hand by one hand,
so your left hand does what you want it to do, but one second after when you want it to do that.
Would you still think your left hand is a part of your self?

If a machine does not have any way of sensing touch, even indirectly,
then it will never experience touch.

\section{Artificial life}

\chapter{Definition of intelligence}

We try to infer the meaning of intelligence
from the way we use that word in everyday situation.

Scoring high on the IQ test.
Knowing lots of things.
Winning at chess.
???

Dictionary defines intelligence as the ability to tell apart.

Intelligence is curiosity plus analogizing with respect to prior knowledge.
Imagine a trap shaped exactly like a rose in the middle of the road but it will explode upon picked.
A human who does not know about rose-shaped exploding traps will pick it up and explode.

Intelligence is the ability to control the environment.

Intelligence is the ability to manipulate the environment.

Intelligence transforms data into knowledge.
Intelligence uses knowledge.

Knowledge is compressed representation of data.

\section{Mathematical definition of intelligence}

``Intelligence measures an agent's ability to achieve goals in a wide range
of environments.''
\cite{LeggPhd,LeggHutterFormal}

If we have a predicate \(\fun{achieve}~a~g~e\) that states whether the agent \(a\) achieves the goal \(g\) in environment \(e\),
we define the intelligence.

\section{Universal intelligence}

TODO Shane Legg's PhD thesis titled ``Machine super intelligence'' \cite{LeggPhd}

TODO Negnevitsky AI book \cite{negnevitsky2005artificial}

\chapter{Signs of intelligence}

\section{Imitation}

Imitation implies intelligence?
For \(a\) to be able to imitate \(b\),
\(a\) has to have a model of \(b\).

\section{Survival}

If the only goal is to survive, then wouldn't the best strategy be
make as many copies as many as possible?

Make copies, as fast as possible, as many as possible.

Arrange for the species to maximize the number of copies that live at the same time.

Make an organism as fit as possible.
Make an organism survives as many environments as possible,
including the environments it did not originally evolve from.
A sign of intelligence is that the organism can
perform well in environments it had never encountered before.

\section{Related concepts}

intelligence, learning, self, consciousness, sentience, life, perception,
adaptivity, adaptability, adaptation, control, language, thought, feeling, reasoning, discovery,
recursion, feedback, computation, computability.

\section{Interesting idea}

Strategy 1:
Given two nouns \(a\) and \(b\), find a verb \(v\) such that the sentence \(a~v~b\) makes sense.
Strategy 2:
Given two nouns \(a\) and \(b\), pick which of these two sentences make sense:
``\(a\) requires \(b\),'' or ``\(a\) does not require \(b\).''

An early `intelligence', if you will, is chemotaxis.
Chemotaxis is random walk that is biased by the gradient. (Cite?)
The deterministic version of that is gradient following algorithm.
The goal is to minimize the concentration of the chemical at the location of the cell.

Control system. Homeostasis.

Deduction: Given premises, infer conclusion.
Induction: Given a few premises and a conclusion, infer a rule.

Probabilistic logic.
Generalize boolean \(\{0,1\}\) to probability, real unit interval, \([0,1]\).
Boolean logic is a special case of probabilistic logic.
\(p~(x \wedge y) = \min~(p~x)~(p~y)\).
Fuzzy logic?

``To organize is to create capabilities by intentionally imposing order and structure.'' \cite{Organ}

\section{Cybernetics}

How can we apply systems theory to management? \cite{SystemManage}

Ashby's optical mobile homeostat
\cite{BattleHom}
\cite{BattleThree}

Braintenberg vehicles

A G\"odel machine improves itself.
It proves that the improvement it makes indeed makes it better.
\cite{GodelMachImpl}

% http://people.idsia.ch/~juergen/goedelmachine.html
% http://people.idsia.ch/~juergen/selfreflection.pdf
% http://people.idsia.ch/~juergen/metalearner.html

Steinberg and Salter (1982)
wrote that intelligence is ``goal-directed adaptive behavior''.
This suggests that an intelligent system is purposeful and adaptive,
in the sense we defined above.
%https://en.wikipedia.org/wiki/Intelligence#Definitions

% Intelligence maximizes future freedom?
% https://www.ted.com/talks/alex_wissner_gross_a_new_equation_for_intelligence/transcript?language=en#t-121478

\cite{PickeringCyber}
\cite{GoertzelAgi}
\cite{SlomanTuringIrrelevance}

Algorithmic information theory
\cite{AlgoInfTh}

Giulio Tononi, integrated information theory
(not to be confused with information integration theory)

Nils J. Nilsson modeled a world and an agent as finite-state machines \cite{NilsLogicAi}.
He used explicit sense type, action type, and memory type.
William Ross Ashby used the phase space of a continuous dynamical system,
where time is a real number,
to describe an agent's behavior \cite{AshbyBrain}.

\section{Supervised classification problems}

AI shines in supervised classification problems.
Machine vision.

Digit recognition is classification problem.

\section{Classification involving sequence or time}

\chapter{Attempts at defining intelligence}

\section{Sequence and goal function}

Let there be a goal function \(g : A^\infty \to [0,\infty)\)
where \(A^\infty\) is the set of all infinite sequences whose each element is of type \(A\).
We say that a sequence \(x\) is more intelligent than a sequence \(y\) iff \(g~x < g~y\).

\section{An intelligent function}

Let \(f\) be a function.
We define the \emph{\(j\)-converger} of \(f\)
as the set \( \{ x ~|~ j~(f^\infty~x) = 0 \} \).
We define the \emph{\(j\)-intelligence} of \(f\)
as the size of the \(j\)-converger of \(f\).

\chapter{Fields of study related to intelligence}

AI is about making something
that is as intelligent as a human brain
without caring about how human brain works.
Cognitive neuroscience is about how a human brain works.

\section{Connectionism}

\section{Brain is a vector function}

\section{Machine learning}

Machine learning makes machine do things from examples.

\section{Connectionism}

\section{Computational neuroscience}

\section{Cognitive neuroscience}

Cognitive neuroscience tries to understand how brains work.
The organism with central nervous system with the fewest neurons is \species{Caenorhabditis elegans}.
You can create your own virtual \species{Caenorhabditis elegans} online at \cite{openworm}.

In rats, neuron firing rate encodes posterior probability (expected value)?
(Cite?)

Neural coding tries to find out how neurons encode information.
Are neurons digital, analog, or both?
Spike train?

Digit-recognizing neural network performs generalization/induction.

Decoding mental states from brain activity in humans \cite{haynes2006decoding}

\section{Imagination is as real as perception}

Imagining a thing excites the same neurons as perceiving that thing.
Therefore if we have a very good mental model,
we should be able to perform experiments in our imagination
and translate the results to the real world.

Imagine that an intelligent machine existed,
and then work our way back.
Invent a story about how we would get there.

\section{Materials looking for a place to belong}

\index{coprime numbers}%
\index{number!coprime}%
Two numbers are \emph{coprime} iff their only common divisor is 1.
\index{prime number}%
\index{number!prime}%
A \emph{prime number} is divisible by 1 and itself only, except 1.

Logic has \emph{syntax} (form) and \emph{semantics} (meaning).
Grammar determines the \emph{well-formed formulas}.
Semantics maps a well-formed formulas to an \emph{interpretation}.
(What are the terms? Mathematical logic lecture notes or book?)

\index{extension of a predicate}%
The \emph{extension} of a predicate \(p\) is \(\{x~|~p(x)\}\).

\index{normal form!Skolem}%
\index{Skolem normal form}%
\index{Skolemization}%
\index{Skolemized formula}%
A formula in first-order logic is \emph{Skolemized} or is in \emph{Skolem normal form}
iff it has the form \(\forall x_1 \ldots \forall x_n ~ M\)
where \(M\) is a quantifier-free formula in conjunctive normal form.
A formula is in \emph{conjunctive normal form} iff ...
% http://mathworld.wolfram.com/SkolemizedForm.html
\index{Herbrand universe}%
A \emph{Herbrand universe} is ...
\index{interpretation}%
An \emph{interpretation} is ...
A \emph{formal system} is ...
A \emph{formal language} is ...

\index{Curry-Howard correspondence}%
\emph{Curry-Howard correspondence} relates logic and type.
A value \(x : T\) is a proof the logic formula isomorphic to \(T\).

\section{Group, ring}

\index{binary operation}%
The type of a \emph{binary operation} is \(a \to b \to c\).
\index{binary operation!closed}%
\index{closed binary operation}%
The type of a \emph{closed binary operation} is \(a \to a \to a\).
A binary operation \(\cdot\) is \emph{associative} iff \(x\cdot(y\cdot z) = (x\cdot y)\cdot z\).

\index{magma}%
A \emph{magma} is a set and a closed binary operation.
\index{semigroup}%
A \emph{semigroup} is an associative magma (a magma whose operation is associative).
\index{monoid}%
A \emph{monoid} is a semigroup with an identity element.
\index{group}%
A \emph{group} is a monoid whose each element has an inverse.
A \emph{ring} is \((S,+,\cdot)\) where
\((S,+)\) is an commutative group,
\((S,\cdot)\) is a monoid,
and multiplication distributes addition:
\(x \cdot (y+z) = (x \cdot y) + (x \cdot z)\)
and \((x+y) \cdot z = (x \cdot z) + (y \cdot z)\).

\section{Genetic algorithm}

\newcommand\fit{\fun{fit}}
\newcommand\mate{\fun{mate}}
\newcommand\pop{\fun{pop}}
\newcommand\sur{\fun{sur}}
\newcommand\Pop{\fun{Pop}}

A \emph{genetic algorithm} is an iterated randomized mixing filtering optimization.
Generalized genetic algorithm:
Let \(\Pop\) be the population type.
Let \(t : \Nat\) be time.
Let \(\pop~t : \Pop\) be the population at time \(t\).
Let \(\fit : \Pop \to \Pop\) be the fitness filter a.k.a. selection function a.k.a. selection pressure function.
Let \(\mate : \Pop \to \Pop \to \Pop\) be the next-population function,
including mutation, birth, death, mating.
Let \(\sur~(t+1) = \fit~(\pop~t)\) be the survivor set at time \(t+1\).
The algorithm is the equation \(\forall t \in \Nat : \pop~(t+1) = \sur~(t+1) + \mate~(\pop~t)\).
Observe the sequence of populations \(\pop~0, \ldots, \pop~t\).
A genetic algorithm, an iterated search algorithm, is a mono-unary algebra.
Genetic algorithm is like tree search.
The mating function is the fringe function.
A genetic algorithm is a stochastic process.
A genetic algorithm takes a filtering and mating algorithm and produces a search algorithm.

Simulated annealing.

Randomized search algorithm.

\section{Draft}

Is a company, which consists of undoubtedly intelligent people, intelligent?

Alan Turing proposed the Turing test.

Intelligence is what intelligence tests measure.

I think we use the word `intelligence' to refer to a stabilizing behavior
that is complex enough to elude a simple explanation.

I think we agree that we are intelligent.

We cannot know if something is intrinsically intelligent.
We can only determine intelligence from what we can observe.

\section{How do we determine how intelligent something is?}

An intelligent being may elude detection by pretending to be unintelligent.

\section{The brain at a time is a big array function.}

Can we formulate it in a way that does not depend on linear time?

\section{Control needs feedback.}

There is also open-loop or feed-forward control,
but complex control needs feedback.

\section{Consciousness}

Consciousness needs sensory input.

Consciousness needs feedback.

Self concept needs feedback.

If there is not a feedback, a system cannot distinguish itself from its environment.
The self concept will never arise.

If a brain can immediately control a thing,
then that thing is part of the brain's self concept.
If the brain can't, it's not.

If a brain often gets certain input shortly after it produces certain output,
it will associate the output with its self concept.

The self is the thing under conscious control.

\section{Intelligence is a spectrum.}

Is a human intelligent?

Is a rock intelligent?

A human is more intelligent than a rock.

Is a human pretending to be a rock intelligent?

Can an intelligent system look non-intelligent (hide its intelligence)?

We can measure intelligence as numbers.

Intelligence needs learning.

Adapting needs learning.

We say X adapts to Y iff Y surprises X less as time goes by. (Whose idea is this?)

Intelligence needs state.

State needs time.

\section{Intelligence is control.}

An intelligent system is a special case of control system.

\section{Intelligence is relative.}

Intelligence relative to something is a real number.

\section{Intelligence needs the ability to adapt.}

\section{Every software system is a state machine.}

\section{Curry's Y combinator makes a fixed point equation}

\section{What are the limits of intelligence?}

\section{Phase-space learning?}

There is a boundary: the agent, and the environment.
How many functions do we need to model it?

One function that is an endofunction of phase space.
The agent state is a subspace of that phase space.
The environment state is another subspace of that phase space.

The idea is to represent the how the phase space changes in a small time.
The number of variables should equal to the degree of freedom of the system.

\section{What are the ways of describing a system?}

\begin{itemize}
    \item function from time to state
    \item endofunction of phase space
\end{itemize}

State space and phase space are the same.
State space is for discrete systems.
Phase space is for continuous systems.

\section{What fields does this book depend on?}

Topology \cite{Topology}

Functional analysis

Dynamical system

Control theory

Fixed point theory

Neurophysiology

Computer science

Cybernetics

% https://en.wikipedia.org/wiki/Connectionism
% https://en.wikipedia.org/wiki/Cybernetics

Biological neuron model
% https://en.wikipedia.org/wiki/Biological_neuron_model

An introduction to mathematical physiology
% https://people.maths.ox.ac.uk/fowler/courses/physiol/physiolnotes.pdf

Learning and Transfer of Learning with No Feedback: An Experimental Test Across Games
% http://repository.cmu.edu/cgi/viewcontent.cgi?article=1040&context=sds

Perceptual learning without feedback in non-stationary contexts: Data and model
% http://socsci-dev.ss.uci.edu/maplab/webdocs/petrovdosherlu06.pdf

Neural coding
% https://en.wikipedia.org/wiki/Neural_coding

Pulse-frequency modulation in brain neurons

Reward system

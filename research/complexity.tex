\chapter{Computational complexity}

There are two computational resources we concern ourselves with:
time and space.
The unit of time is arbitrary.
Number of steps. Each step takes the same amount of time.
Each configuration transition uses the same amount of time.

The time used by that computation is the length of the corresponding path.
Formally the time required by the machine
to move from configuration $a$ to $b$ is
the smallest natural number $n$ such that $\beta^n a = b$.
By definition, the machine \emph{moves in one unit time} from configuration $x$ to $y$ iff $\beta x = y$
so $\beta$ depends on the set of primitive operations we equip the machine with.

The \emph{time-to-termination} of a configuration $x$,
written $\TC \beta x$,
is the smallest natural number $n$ such that $\beta^n x$ is terminal.
The time-to-termination of $x$ is the length of the shortest path from $x$ to a terminal configuration.

The maximum space usage of a computation is
the maximum of the space usages of the vertexes of the corresponding path.
Now suppose that we write $s x$ as the \emph{space usage} of configuration $x$.
The space usage of an initial configuration is the size of the input.
We define $\SC \beta x$,
the \emph{maximum-space-to-termination} of a computation from $x$
as follows:
\begin{equation}
    \SC \beta x = \max_{c \in C \beta x} s c
\end{equation}
where we define
$C \beta x = \{ \beta^k x \,|\, k \in \mathbb N \}$
as the set of all configurations
that can be reached from $x$ by following $\beta$.

\section{Time class}

What can a machine compute in a given number of steps?
Given more time, does a machine compute more?

What is the relationship between the size of the input and the running time?
What is the relation between the size of
an initial configuration and its time-to-termination?
How fast does the time-to-termination grow?

We are talking about a special kind of problems
whose time usage depends only on the length of the input.

A \emph{time class} is a set of all initial configurations that have the same time-to-termination.
Define the \emph{time class $n$ of machine $D$},
written $\Teq D n$ (or just $\Teq n$ when the machine is clear in the context),
as the set of every initial $D$-configuration
whose time-to-termination equals $n$.
Then define $\Teqsum n$, the \emph{max-time class $n$},
as the set of every initial configuration whose time-to-termination is less than $n$:
\begin{equation}
    \Teqsum n = \bigcup_{k = 0}^{n - 1} \Teq k
\end{equation}

For example, if the machine ignores its input and runs in constant time,
$\Teqsum 1 = I$.

\newcommand{\Cset}{\mathbf{C}}
Define $\Cset n$ as the set of every initial configuration whose size is less than $n$.
The \emph{time simplicity function of the machine} is
\begin{equation}
    K n = \frac{\mu(\Teqsum n)}{\mu(\Cset n)}
\end{equation}
(Find a better name?)
Higher $K n$ means faster computation.
The \emph{space simplicity function} of the machine is defined analogously:
\begin{equation}
    J n = \frac{\mu(\mathbf S n)}{\mu(\Cset n)}
\end{equation}

If the alphabet used is the binary alphabet $\{ 0, 1 \}$
and the input is a natural number encoded using the usual binary positional encoding,
then $\mu (C n) = 2^n$ and thus $\mu (\Cset n) = 2^{n + 1} - 1$.

If every instance $x$ of size $\mu x$ is solved by machine
(if the time-to-termination of each initial configuration $x$ of size $\mu x$ is less than $f(\mu x)$)
then we say that the problem is size-bounded by $f$.

Is there an $m$ such that for all $n > m$, we have $\Teq n = \varnothing$?
Only if the machine does not read all its input?

Now we examine the relation between the size of the initial configuration
and the time to termination of that configuration.
Intuitively, when the problem is non-trivial, as the initial configuration grows larger,
the machine should require more time to arrive at the related terminal configuration.
If the problem is non-trivial then a bigger initial configuration
should imply a higher time to termination of that configuration.

The minimum time-to-termination of every initial configuration of size $n$.

The maximum size of every initial configuration with time-to-termination of $n$.

The sets of functions computable by deterministic and nondeterministic machines are the same?

$\Teq n$ may be empty?

$\Teq n$ and the length of.

Define space equivalence class $n$ as $\Seq n$ as the set of
every configuration that has a maximum-space-to-termination of $n$.

Both $\TC$ and $\SC$ are functions.
Are they computable?
$C \beta$ is also a function.

Every configuration following $x_0$ is fully determined by $x_0$.
The computation is fully determined by its first configuration.
A machine is deterministic in the sense that given a configuration,
the computation that proceeds from that configuration is always the same.
What can graph theory say about computation?
What result in graph theory helps us discover something in computation theory?
Weighted graph can model computation with nonuniform transition time.
But for what?
Modeling modern machines with speculative execution?

We say that an algorithm $a$ is in $\TIME(O(f n))$ where $n$ is the length of the input iff
for infinitely many (but not necessarily every) $i$ in each initial configuration
$x \equiv (a,i)$ that eventually terminates, we have $\TC x \in O(f(s x))$.

Determining if a number is divisible by $m$ is a constant-time operation in a machine with alphabet of size $m$,
but is it also constant-time operation in a machine with another base that is coprime to $m$?

\section{Fair coding scheme}

How to code almost anything into a bit string?

How to code members of type $t$ into bits?

How do we constrain the coding function so that meticulous mathematicians
cannot cheat by shifting the computation into the coding function?

Let $\mu t : t \to \Nat$ be the \emph{canonical measure} of an element of the countable type $t$.

Let $c t : t \to \Bits$ be the coding function.
This coding function must be measure-preserving, size-preserving.
Formally the coding function must satisfy
\[
    \mu t x \le \mu t y \iff \mu \Bits (c t x) \le \mu \Bits (c t y)
\]
for each $x : t$ and $y : t$.

\section{Terminology and notation}

A \emph{list} $x$ of $X$ of length $n$ is $[x_0,x_1,\ldots,x_{n-1}]$
where each $x_k$ has the type $X$.
The list $x$ has type $X^*$ (the Kleene closure of $X$).
The empty list is written $[]$.
Lists are also known as \emph{strings}.

An \emph{instance} is a string.
A \emph{problem} is a set of instances.
A problem is also called a \emph{language}.

A \emph{complexity class} is a set of problems.

We write $\TC_M e$ to mean the number of time units required by machine $M$
to evaluate expression $e$.
Sometimes $M$ is omitted so we write only $\TC e$
such as when the machine is not too relevant
or is clear in the context.

To evaluate an expression is to reduce it until it becomes a value.
A value is an expression that reduces to itself.

An \emph{$X$-decider} is an implementation of a function having the type $X \to \mathbb B$.
We say that the decider \emph{accepts} the input $x$ iff $fx$ is true.
The \emph{language} recognized by the decider is the set
\begin{align*}
    \langset f = \{ x ~|~ x : X, ~ fx \}
\end{align*}

We say that $b$ is a time usage lower bound of decider $f$ iff $fx \in \Omega b$.
We say that $b$ is the time usage infimum of that decider iff
for all $c$ that is a time usage lower bound of $f$,
$b$ is a time usage lower bound of $f$ and $b \in \Omega c$.

The \emph{decider set} of a language \(L\) is \(\decset L = \decset L = \{ f ~|~ \langset f = L \}\).
It is the set of all deciders whose language is \(L\).
We say $f \leTC g$ iff $\forall x \in X^* ~ \TC(fx) \in O(\TC(gx))$.

$f$ is a \emph{minimum-time decider} of $L$ iff for each $g \in \decset L$,
it holds that $\forall x \in X^* ~ \TC(fx) \in O(\TC(gx))$.
In other words, such $f$ is an infimum of $\decset L$ according to $\leTC$.

\begin{msco}[nonexistence of time usage supremum]
    $\decset L$ has no supremum according to $\leTC$.
    For each decider $f \in \decset L$, there exists an asymptotically slower $g \in \decset L$.
    \begin{align}
        \forall f \in \decset L ~ \exists g \in \decset L ~ \forall x \in X^* ~ \TC(fx) \in o(gx)
    \end{align}
\end{msco}

\begin{mcor}[decider set equivalence class]
    We can define two deciders as $f$ and $g$
    as equivalent iff for all input $x$,
    their time usage is asymptotically similar.
    \begin{align}
        \mathcal E m p L = \{ f ~|~ \langset f = \decset L, ~ \forall x \in X^* ~ \TC_m(fx) \in \Theta(\TC_m(px)) \}
    \end{align}
\end{mcor}

\begin{msco}[NTIME upper bound]
    Let $N$ be a nondeterministic machine.
    The number of time units required by $N$
    to evaluate $\SDP fx$ is bounded above as follows
    where $n$ is the length of $x$:
    \begin{align}
        \TC_N(\SDP fx) \in O\left(n + \max_{s \sqsubseteq x} (\TC(fs))\right)
    \end{align}
\end{msco}

\begin{msco}[DTIME upper bound]
    Let $D$ be a deterministic machine.
    The number of time units required by $D$
    to evaluate $\SDP fx$ is bounded above as follows
    where $n$ is the length of $x$:
    \begin{align}
        \TC_D(\SDP fx) \in O \left( \sum_{s \sqsubseteq x} \TC(fs) \right)
    \end{align}
\end{msco}

A \emph{$g$-transformer} of a decider $f$ is a function $g : X^* \to X^*$
such that $fx = f(gx)$ for all $x : X^*$.
If $\TC(fx) \in o(\TC(f(gx)))$ then
we call the $g$-transformer a \emph{$g$-speedup}.
On the other hand if $\TC(fx) \in \omega(\TC(f(gx)))$ then
we call the $g$-transformer a \emph{$g$-slowdown}.

\begin{mcon}[DTIME lower bound]
    For each deterministic machine $D$,
    $\TC_D(\SDP fx) \in \Omega(m^n)$ for all $f : X^* \to \mathbb B$
    and $x : X^*$
    where $|X| = m$
    and $|x| = n$.
\end{mcon}

\begin{mcon}[existence of a certain decider]
There exists an alphabet $X$
and an $X^*$-decider $f$ such that
for each list $x : X^*$ of length $n$,
the following two statements hold
\begin{align}
    \TC_D(\SDP fx) &\in \Omega 2^n
    \\
    \TC_N(\SDP fx) &\in O n
\end{align}
where $D$ and $N$ are the deterministic machine
and the nondeterministic machine from the two previous conjectures.
If such $f$ exists, then $\PTIME \neq \NPTIME$.
\end{mcon}

\begin{mcon}
    If $f = f \circ g$ for all $f$ then $g = \id$.
\end{mcon}

\begin{mcon}[existence of a PNP decider]
Such decider cannot have overlapping subproblem
and cannot have optimal substructure.
There is no mathematical identity that allows decider to be computed faster.
If
\begin{align}
    \neg\exists p ~ \forall x \in \{ a | a \in X^*, p a \} ~ \exists y ~ fx = fy
\end{align}
then $f$ exists.
\end{mcon}

Proof by contradiction:
suppose that for every decider,
there exists a mathematical identity that allows it to be computed faster.
\begin{align}
    \forall f ~ \exists p ~ \forall x \in \{ a | a \in X^*, p a \} ~ \exists y ~ fx = fy
\end{align}
Then what?

\section{Machines}

\begin{mdef}[standard machine]
    The standard machine with alphabet $X$
    has the following primitive operation set:

    Every constant of type $X$.

    Every unary operation of type $X \to X$.

    Every binary operation of type $X \to X \to X$.

    Every ternary operation of type $X \to X \to X \to X$.
    One of these ternary operations is the three-way branch operation:
    $pctf$ is $t$ iff $c \neq 0$; $f$ otherwise.

    Function application.

    Function composition.

    Some list operations: $\fnull : X^* \to X$,
    $\fhead : X^* \to X$,
    $\ftail : X^* \to X^*$,
    and $\fcons : X \to X^* \to X^*$.

    A fixed-point combinator $y : \forall a ~ (\alpha \to \alpha) \to \alpha$ satisfying $yf = f(yf)$
    such that the expression $yf$ reduces to $f(yf)$ in one time unit.
\end{mdef}

\section{Recursion}

\begin{mlem}
    The type of the Y-combinator is $\forall a ~ (\alpha \to \alpha) \to \alpha$.
    \begin{proof}
        The definition is $yf = f(yf)$.
        \begin{align}
            f &: \alpha
            \\
            r &: \alpha \to \beta
            \\
            yf &: \beta
            \\
            f &: \beta \to \gamma
            \\
            f(yf) &: \gamma
            \\
            yf : \beta, \ f(yf) : \gamma, \ yf = f(yf) &\implies \beta = \gamma
            \\
            f : \alpha, \ yf : \beta, \ f(yf) : \gamma &\implies f : \beta \to \gamma, \ \alpha = \beta \to \gamma
        \end{align}
    \end{proof}
\end{mlem}

Recursive has to do with fixpoints.

\section{Nondeterminism}

In a nondeterministic machine, $\ambc x y$
has the same effect as reducing $x$ and $y$ in parallel in one unit time.
Let the accepting computation be $z$ where $z$ is either $x$ or $y$.
\begin{align}
    \TC(\ambc xy) &= \TC z
\end{align}

\section{Notation}

$a : A$ or $a \in A$ means the type of $a$ is $A$,
or $a$ is in $A$,
or $a$ is an element of $A$.

$A \to B$ is the type of every function
that takes any $a \in A$ and returns any $b \in B$.

Concatenation means function application:
$fx$ means $f(x)$ in standard mathematical notation.
$fxy$ means $f(x,y)$ in standard mathematical notation,
but the former one is with currying.
$f0$ can mean $f(0,y)$ which is a function of $y$ only.

If $f : A\to B$ and $x:A$, then $fx : B$.

If $f : A\to B\to C$, $x:A$, and $y:B$, then $fxy : C$.





\begin{mcor}[number of deciders]
    Let $|X| = m$.
    The number of total mappings of type $X^n \to \mathbb B$ is
    \begin{align}
        2^{m^n}
    \end{align}
    The number of total mappings of type $(X^0 \cup X^1 \cup \ldots \cup X^n) \to \mathbb B$ is:
    \begin{align}
        \sum_{n=0}^{\infty} 2^{m^n}
    \end{align}
    There are $m^n$ boxes and each box can contain either $\syes$ or $\sno$.
\end{mcor}





\begin{mdef}[Ambiguous operator]
    The \emph{ambiguous operator} $\amb : A^* \to A$
    takes a list and returns an element of that list
    such that the decider containing the amb-expression is led to $\syes$.
\end{mdef}

    The following is a nondeterministic algorithm:
    \begin{align}
        \SDP fx &= gfx[] & \text{where}
        \\
        gfxy &= \fite{\fnull x}{fy}{gf(\ftail x)(\amb[y, \ftail y])}
    \end{align}






\begin{mlem}[existence of decider bounded below by LIN]
There exists a decider that cannot be computed
in less than linear time
by the standard machine.
Formally there exists an $X^*$-decider $f$ such that
for each list $x : X^*$ of length $n$,
$\TC(fx) \in \Theta n$.
\begin{proof}
    Consider the decider that decides whether zero
    is the modulo-$m$ sum of all elements in the input list of $X$s
    where $X$ is a finite subset of $\mathbb N$ of size $m$.

    $f x = [\sum_{k=0}^{n-1} x_k = 0]$
\end{proof}
\end{mlem}

    \begin{align}
        \ambc y &= \fite{\fnull y}{y}{\amb[\fhead y :: \ambc (\ftail y), \ambc (\ftail y)]}
    \end{align}

\begin{mcon}
Corollary:
If $\TC_D(\SDP fx) \in \Omega(2^n \cdot n)$ and $\TC_N(\SDP fx) \in O n$,
there exists a problem that is in NP but not in P;
therefore $P \subset NP$.
\end{mcon}

Prove that the only $g$ that satisfies $fx = f(gx)$ is $\text{id}$.

To prove that $\TC (fx) \in O(gn)$,
write an algorithm that is in that time complexity class.

To prove that $\TC (fx) \in \Omega(gn)$, ...


Function Constancy Check Problem/Function Constancy Decider.

Given an almost constant $X^n$-decider, find the only $x$ that differ.

An $X$-decider is almost constant iff $f^{-1}\syes = \{\}$.

This will also prove P neq NP:
Find $f$ and $g$ such that $\forall x \in X^* ~ fx = gx$ but $\TC_D(fx) \subset \TC_N(gx)$









\section{Computational complexity}

A set is \emph{computable} iff there is an algorithm (a finite description)
for its indicator function.

\section{Lax monoidal functors}

A category $C$ is defined by $\ob C : \Set\alpha$ and $\hom C : \Set(\alpha, \alpha))$ such that
associative and preserve identity
\begin{enumerate}
    \item $(f \circ g) \circ h = f \circ (g \circ h)$ for all $f,g,h : \hom C$.
    \item $1_C \circ f = f \circ 1_C = f$ for all $f : \hom C$.
\end{enumerate}

Functor is $F$:
\begin{enumerate}
    \item $f : (A \to B) \to (FA \to FB)$.
\end{enumerate}

Also known as `monad' in Haskell.

A lax monoidal functor $F$ takes a set.
\begin{enumerate}
    \item Zero element $F_0 : FA$.
    \item Lifting morphism $F_1 : A \to FA$.
    \item Internal operation on Kleisli category $f : FA \to (A \to FB) \to FB$.
\end{enumerate}

\section{Monads}

Let there be the following type functions:
\begin{align}
    \mM A &= \{ \mM_0 \} \cup \{ \mM_1 a ~|~ a \in A \}
 \\ \mL A &= \{ \mL_0 \} \cup \{ \mL_1 h t ~|~ h \in A, ~ t \in \mL A \}
 \\ \mP A &= \{ \mP X ~|~ X \subseteq A \}
\\ \mE AB &= \{ \mE_0 a ~|~ a \in A \} \cup \{ \mE_1 b ~|~ b \in B \}
\end{align}
In Haskell, $\mM$, $\mM_0$, and $\mM_1$ are known as Maybe, Nothing, and Just;
and $\mL$, $\mL_0$, and $\mL_1$ are known as list type function ([]), the empty list ([]), and the list constructor (:).

\begin{align}
    \sigma_M &: MA \to (A \to MB) \to MB
\end{align}

For \mM, $\sigma$ is defined as
\begin{align}
    \sigma \mM_0 f &= \mM_0
    \\ \sigma (\mM_1 a) f &= fa
\end{align}

For \mL, $\sigma$ is defined as
\begin{align}
    \sigma \mL_0 f &= \mL_0
    \\ \sigma (\mL_1 h t) f &= [\amb (fh \cdot \sigma tf)]
\end{align}
where $\amb : \mL A \to A$ is McCarthy's ambiguous operator
and $\cdot$ is list concatenation.
The operator $\amb$ picks an element leading to accepting path
in zero time without computing the other elements.

For \mP, $\sigma$ is defined as
\begin{align}
    \sigma (\mP S) f &= \{ \amb \{ f x ~|~ x \in S \} \}
\end{align}

\section{\mM-extended string}

\begin{align*}
    x_n' &= \begin{cases}
 \mM_1 x_n &: n \text{ is a valid index into input string}
  \\ \mM_0 &: \text{otherwise}
\end{cases}
\end{align*}

\section{Definition of computation via expression reduction}

The grammar for expression:
\begin{align}
    Exp &::= X
      \\ &| -Exp
      \\ &| (Exp)
      \\ &| Exp + Exp
      \\ &| Exp \cdot Exp
\end{align}

A finite countable set $X$.

There are $n^{n \cdot n}$ possible binary operations on a set of $n$ elements.
We assume using space-time-tradeoff that some of them can be performed in constant time.

A \emph{primitive expression} is an expression whose time cost is one unit.
We assume that these are the \emph{only} primitive operations:
\begin{enumerate}
    \item modulo-$m$ arithmetic operations:
            negation ($-a$),
            addition ($a + b$),
            subtraction ($a - b$),
            and multiplication ($a \cdot b$).
    \item every unary operation in $N_m$ and every binary operation in $N_m$
    \item every unary operation in $\mathbb B = \{0,1\}$ and every binary operation in $\mathbb B$
    \item comparison: comparing equality $(=) : X \to X \to \mathbb B$
        and (unsigned) ordering $(<) : X \to X \to \mathbb B$,
        and three-way conditional ($Cctf$: if $c$ then $t$ else $f$ where $t,f:\alpha$ and $c:\mathbb B$).
    \item primitive list operations:
        \begin{enumerate}
            \item \fnull: determining whether a list is empty
            \item \fhead: taking the first element (partial function)
            \item \ftail: taking all but the first element (partial function)
            \item constructing a list by prepending one element to a list (::)
        \end{enumerate}
\end{enumerate}
For each constant expression $e$, $\tau e = 0$.

A \emph{primitive value} is a value whose space cost is one unit.
\begin{align}
    \forall x \in X \quad \sigma x &= 1
    \\ \forall x \in (A,B) \quad \sigma x &= \sigma a + \sigma b
     \\ \forall fx \in \{L a | a \in A\} \cup \{R b | b \in B\} \quad \sigma (fx) &= 1 + \sigma x
\end{align}
Example:
\begin{align}
    \sigma[1,2,3] &= \sigma(1::2::3::[])
               \\ &= \sigma (L1(L2(L3L_0)))
               \\ &= 1 + \sigma 1 + \sigma (L2(L3L_0))
               \\ &= 1 + 1 + 1 + \sigma 2 + \sigma (L3L_0)
               \\ &= 3 + 1 + 1 + \sigma 3 + \sigma L_0
               \\ &= 5 + 1 + 1
               \\ &= 7
\end{align}

For example, the following $f$ performs modulo-$m$ summation:
\begin{align}
     fx &= C (\fnull x) 0 (\fhead x + f(\ftail x))
\end{align}

The space and time cost for reducing an expression is $\sigma E$ and $\tau E$ respectively.

\section{Definitions}

A \emph{problem} is a set of its instances.
An instance is a pair of question and answer.
The question is a string of the input alphabet.
The answer is a string of the output alphabet.
A question may have more than one answer.
Each question must have at least one answer.

An \emph{$\alpha$-machine} has a \emph{transition function}
$t : (S,\mM X) \to \alpha S$
where $S$ is the \emph{state type},
$X$ is the \emph{input alphabet},
and $\alpha$ determines the way the machine performs computation.
$X$ must be finite and countable.
$S$ must be countable.
$S$ may contain a special elements:
the accepting state \syes.
Formally, a \emph{machine} is a 4-tuple $(\alpha,X,S,t)$ where
\begin{align}
    X &: \Fin
 \\ S &: \Set
 \\ t &: (S,\mM X) \to \alpha S
\end{align}

Once something is accepted or rejected, it is final:
\begin{align}
    \forall x \quad t (\syes,x) &= \pi \syes
  \\ \forall x \quad t (\sno,x) &= \pi \sno
\end{align}
where $\pi : S \to \alpha S$ is the $\alpha$-lifting function.

The transition function must be total
and it must be an semi-algorithm;
it must be able to be described
in a finite number of (what?) elementary operations.
It must go into an infinite loop when the answer is no.

A \emph{path} of that machine for input $x = [x_0,\ldots] \in X^*$ is $s = [s_0,\ldots] \in S^*$.
The computation performed by that machine is a repeated application of the transition function:
\begin{align*}
    s_n &= \sigma (t (s_{n-1}, x_n'))
\end{align*}
where $\sigma$ is defined according to $\alpha$
and $x'$ is \mM-extended $x$.
The initial state is $s_0 \in S$.
The path is an \emph{accepting path} iff $\syes$ is in that path.
The machine \emph{accepts} an input iff the path for that input is an accepting path.

The \emph{running time} for that input is the length of the corresponding path.

The \emph{maximum space usage} is: (maximum or supremum?)
\begin{align}
    \max_{x \in s} (\mu x)
\end{align}

Deterministic transition function type is $(S,\mM X) \to S$.
Nondeterministic transition function type is $(S,\mM X) \to \mP S$.

Nondeterministic machine can \emph{look into the future}
to \emph{guess an accepting path};
deterministic machine cannot.
Given the same input, a deterministic machine
will always go through the same path of computation.
Given the same input, a nondeterministic machine
might go through another path of computation.


We say that a language is in $\aTIME f$ iff
there exists a constant $k$ and an $\alpha$-machine
such that the length of the shortest path of that machine
for each acceptable input $x$ is in $O(f(\mu x))$.

\begin{align}
    \DTIME &= \idTIME
 \\ \NTIME &= \mPTIME
\end{align}

\section{Example machines}

This machine accepts all inputs:
\begin{align*}
    S &= \{ \syes \}
    \\ s_0 &= \syes
 \\ t(s,x) &= \pi s
\end{align*}
This machine does not accept any input:
\begin{align*}
    S &= \{ \sno \}
    \\ s_0 &= \sno
 \\ t(s,x) &= \pi s
\end{align*}
This machine accepts the language $\{1\}^*$:
\begin{align*}
    S &= \{ s_0, \syes, \sno \}
    \\ t(s,x) &= \text{case $(s,x)$ of} \begin{cases}
      (s_0, \mM_1 1) &\pi s_0
        \\ (s_0, \mM_0) &\pi \syes
 \\ \text{otherwise} &\pi \sno
\end{cases}
\end{align*}

Assume that $X = \{0,1\}$.
\begin{enumerate}
    \item How many languages can an $\alpha$-machine with $n$ states accept?
    \item How many states are needed for an $\alpha$-machine to recognize a given language?
    \item How many transition functions are possible for a machine with $n$ state?
\end{enumerate}

\section{Languages accepted by a machine}

Let $\mu X = \mu Y = 2$.

Types are measurable:
\begin{align}
    \mu(A\to B) &= \mu A \cdot \mu B
    \\ \mu(A,B) &= \mu A \cdot \mu B
    \\ \mu(\mM A) &= 1 + \mu A
    \\ \mu(\mL A) &= 1 + \mu A \cdot \mu(\mL A)
    \\ \mu(\mP A) &= \mu(2^A) & \text{if $A$ is countable}
\end{align}
Hypernatural measures:
\begin{align}
    \mu A = \omega &\implies \mu(\mM A) = \omega
    \\ \mu A > 0 &\implies \mu(\mL A) = \omega
    \\ \mu A < \omega &\implies \mu(\mP A) = 2^{\mu A}
\end{align}

How many transition functions does a \mM-machine have?

How many languages can be accepted by \mM-machine with $\mu S = 2$?

Suppose that a problem is in NP.
Then there exists a constant $k$ such that
the length of the shortest nondeterministic path
for valid input whose size is in $O(n)$ is in $O(n^k)$.

The time complexity measure of a computation is
the length of the path of that computation.

The set of regular languages is $\DSPACE(O(n)) \cap \DTIME(O(n))$.

\section{Speedup theorem?}

Alphabet size can be exchanged with state size.
Space can be traded for time?

\section{Example: modulo-$m$ subset-sum problem}

$X = \{0,1,2,3,\ldots,m-1\}$.
$\syes$ iff there exists $N \subseteq \mathbb N$ such that
\begin{align}
    \sum_{k \in N} x_k &= 0
\end{align}
where addition is done modulo-$m$.

The modulo-$m$ subset-sum problem is in $\NTIME(O(n))$ and is in $\NSPACE(O(m))$
where $n$ is the length of the input.

\begin{align}
    S &= \{ S_0 \} \cup \{ S_1 n ~|~ n \in X \}
    \\ s_0 &= S_0
\end{align}
$t$:
\begin{align}
    (S_1 0, x) &\to \{ \syes \}
    \\ (S_1 s, \mM_1 x) &\to \{ S_1 s, S_1 (s+x) \}
    \\ (S_0, \mM_1 x) &\to \{ S_0, S_1 x \}
\end{align}

\section{Some Haskell code}

\begin{verbatim}
type Tr s x y = (s, Maybe x) -> (Maybe s, Maybe y)

run :: Tr s x y -> s -> [x] -> [y]
run tr state input =
    let
        run' s xs =
            let
                (mx,xs') = case xs of
                    [] -> (Nothing, [])
                    x : t -> (Just x, t)
                (ms',my) = tr (s,mx)
                ys = case ms' of
                    Just s' -> run' s' xs'
                    Nothing -> []
            in
                maybe id (:) my ys
    in
        run' state input
\end{verbatim}

\section{Example: 3-SAT in NP}

Encode a boolean expression.

$X = \{ T, F, A, 0, 1, 2, N, C, D \}$

The grammar for the input is \verb@inp@:
\begin{verbatim}
inp     ::=     asgs A exp
asgs    ::=     empty | asg asgs
asg     ::=     T | F
exp     ::=     0 | 1 | 2
        |       N exp
        |       C exp exp
        |       D exp exp
\end{verbatim}

$A$ separates the assignment and the expression.

The state type is a tuple of three boolean values.

For example, the expression $v_0 \wedge v_1 \vee \neg v_2$ with truth assignment $(v_0,v_1,v_2) = (T,F,F)$ is encoded as TFFDC01N2.

There are $n$ variables.

SAT is in NP iff SAT is verifiable in P.

Constant space. Linear time.

\section{Is there a bijection?}

\begin{align}
    \mathbb N &\iff 2^\mathbb N
    \\ 0 &\iff \{\}
    \\ 1 &\iff \{0\}
    \\ 2 &\iff \{1\}
    \\ 3 &\iff \{0,1\}
    \\ 4 &\iff \{2\}
    \\ 5 &\iff \{0,2\}
    \\ 6 &\iff \{1,2\}
    \\ 7 &\iff \{0,1,2\}
\end{align}
will enumerate all of $2^\mathbb N$?

But Cantor's theorem.

We can construct $x \in 2^\mathbb N$ that has no counterpart in the above bijection.
Counterintuition of infinity.

Binary numbering of $2^\mathbb N$.

\chapter{Old computation book draft}

\theoremstyle{definition}
\newcounter{thmctr}
\newtheorem{mdef}[thmctr]{Definition}
\newtheorem{mque}[thmctr]{Question}
\newtheorem{mcon}[thmctr]{Conjecture}
\newtheorem{msco}[thmctr]{Strong Conjecture}
\newtheorem{mcor}[thmctr]{Corollary}
\newtheorem{mlem}[thmctr]{Lemma}
\newtheorem{mthm}[thmctr]{Theorem}
\newcommand\sno{\ensuremath{\mathcal N}}
\newcommand\syes{\ensuremath{\mathcal Y}}
\newcommand\Fin{\ensuremath{\operatorname{Fin}}}
\newcommand\powerset{\ensuremath{\mathcal{P}}}
\newcommand\fa[1]{\forall#1\,}
\newcommand\Fa[1]{\forall#1~}
\newcommand\FA[1]{\forall#1~~}
\newcommand\sfT{\mathsf{T}}
\newcommand\Typ{\mathsf{Typ}}
\newcommand\Either[2]{\mathsf{Either}~#1~#2}
\newcommand\Left[1]{\mathsf{Left}~#1}
\newcommand\Right[1]{\mathsf{Right}~#1}
\newcommand\Void{\mathsf{Void}}
\newcommand\Pair[2]{\mathsf{Pair}~#1~#2}
\newcommand\UDMach[1]{\mathsf{UDMach}~#1}
\newcommand\DMach[1]{\mathsf{DMach}~#1}
\newcommand\NMach[1]{\mathsf{NMach}~#1}
\newcommand\Mach[2]{\mathsf{Mach}~#1~#2}
\newcommand\Macha[1]{\mathsf{Mach}~#1}
\newcommand\RecRel{\mathsf{RecRel}}
\newcommand\Kleene[1]{\mathsf{Kleene}~#1}
\newcommand\RecFun{\mathsf{RecFun}}
\newcommand\DTM{\mathsf{DTM}}
\newcommand\NTM{\mathsf{NTM}}
\newcommand\sfDMach{\mathsf{DMach}}
\newcommand\sfNMach{\mathsf{NMach}}
\newcommand\sfFun{\mathsf{Fun}}
\newcommand\sfSet{\mathsf{Set}}
\newcommand\sfRel{\mathsf{Rel}}
\newcommand\sfVec{\mathsf{Vec}}
\newcommand\Vect[2]{\sfVec~#1~#2}
\newcommand\Relab[2]{\sfRel~#1~#2}
\newcommand\Fun[2]{\sfFun~#1~#2}
\newcommand\sfPred{\mathsf{Pred}}
\newcommand\Pred[1]{\sfPred~#1}
\newcommand\setB{\mathbb B}
\newcommand\decset{\mathcal D}
\newcommand\langset{\mathcal L}
% time complexity
\newcommand\TC{\mathcal{T}}
\newcommand\leTC{\ensuremath{\le_\TC}}
% time equivalence class
\newcommand\Teq{\mathbb{T}}
\newcommand\Teqsum{\mathbf{T}}
% space equivalence class
\newcommand\Seq{\mathbb{S}}
\newcommand\Seqsum{\mathbf{S}}
\newcommand\SC{\mathcal{S}}
% \newcommand\hom{\operatorname{hom}}
\newcommand\fite[3]{\text{if}~#1~\text{then}~#2~\text{else}~#3}
\newcommand\id{\ensuremath{\operatorname{id}}}
\newcommand\mE{\ensuremath{\mathcal E}}
\newcommand\mP{\ensuremath{\mathcal P}}
\newcommand\mM{\ensuremath{\mathcal M}}
\newcommand\mL{\ensuremath{\mathcal L}}
\newcommand\bB{\ensuremath{\mathbb B}}
\newcommand\amb{\operatorname{amb}}
\newcommand\ambc{\operatorname{ambc}}
\newcommand\fhead{\ensuremath{\operatorname{head}}}
\newcommand\ftail{\ensuremath{\operatorname{tail}}}
\newcommand\fcons{\ensuremath{\operatorname{cons}}}
\newcommand\aTIME{\operatorname{\alpha-TIME}}
\newcommand\idTIME{\operatorname{id-TIME}}
\newcommand\mPTIME{\operatorname{\mP-TIME}}
\newcommand\TIME{\operatorname{\mathsf{TIME}}}
\newcommand\DTIME{\operatorname{\mathsf{DTIME}}}
\newcommand\NTIME{\operatorname{\mathsf{NTIME}}}
\newcommand\EXPTIME{\ensuremath{\mathsf{EXP}}}
\newcommand\PTIME{\ensuremath{\mathsf{P}}}
\newcommand\NPTIME{\ensuremath{\mathsf{NP}}}
\newcommand\NSPACE{\operatorname{NSPACE}}
\newcommand\DSPACE{\operatorname{DSPACE}}
\newcommand\SDP{\ensuremath{\operatorname{SD}}}

\section{TODO}

cite CMI problem description;
understand Baker-Gill-Solovay (?) theorem and relativization;
read Rogers \cite{Rogers1987};
read Arora and Barak \cite{Arora2009};
read Marek and Remmel \cite{Marek2009};
read Boolos, Burgess, and Jeffrey \cite{Boolos2002}

\section{Diary}

In this document, I use the term \emph{predicate} to always mean
a total function that takes a bit string and gives a bit.
Furthermore, if $f$ is a predicate, then
I may write ``$x$ \emph{satisfies} $f$'' to mean $f(x) = 1$, and
I may write ``$f$ is \emph{satisfiable}'' to mean
that there exists $x$ that satisfies $f$.

\newcommand\encoding[1]{\langle#1\rangle}

I write $\encoding{x}$ to mean a binary encoding of $x$.
I write $\encoding{x,y}$ to mean a binary encoding of $x$
concatenated with a binary encoding of $y$.

The ATMB problem is ``Given a machine $m$, a string $x$,
and a number $n$,
does $m$ accept $x$ in $n$ steps or less?''
This problem is exptime-complete with respect to the length of
$\encoding{m,x,n}$. (cite?)

The bounded halting problem is:
``Given a machine $m$ and a number $n$,
does $m$ accept any string that is at most $n$ bits long?''
This is np-complete? (cite?)
% http://www.ics.uci.edu/~eppstein/161/960312.html
% sat-t-icalp.ps

\begin{enumerate}
\item Show that it is in exptime.
\item Show that it is in exptime-hard.
(This implies that it is not in p.
Show that it is polynomial-time many-one reducible to ATMB?
Use diagonalization perhaps?)
\item Show that it is in np.
\item Congratulations.
\end{enumerate}

\section{Defining computation}

Post-Turing machine is simpler than Turing machine.
Wang B-machine is even simpler.

A computation is a repeated application of a function $f$
until the output does not change anymore.
The computation begins with the input $x$ already in place.
Such computation produces the output $y$
in $n$ steps iff $n$ is the smallest number such that $f^{n+1}(x) = f^n(x) = y$
where $f^n(x)$ means $n$ times applying $f$ to $x$.
This function can be thought a transition function that describes
how the entire system (machine state and tape content) changes.
A machine can be seen as a function.

This is a special case of fractal? Chaotic function?

The zero function $f(x) = 0$ corresponds to a machine
that always accepts its input.

The function $f(x) = 2 \cdot x$ corresponds to a machine
that appends a zero bit to the memory, one by one.

What is the essence of computation?
Is it recursion?

This has to do with time-constructibility?

\section{Finding the problem}

Now I try to craft a problem that nondeterministic machines
can solve exponentially faster than deterministic machines can best do.
I am looking for a problem whose best deterministic solution
is an exhaustive search.
Formally, I am looking for a problem that is dexptime-hard but also in np.

``Find a string that satisfies a given satisfiable ptime-predicate,''
where \emph{ptime-predicate} means that
a machine can compute the predicate in an amount of time
that is a polynomial of the number of bits in the input string.

However, there is also an exptime-complete problem:
given a machine and a number $k$, determine if the machine
halts in at most $k$ steps.

What if I combine those problems into this problem:
``Given a ptime-predicate $p$ and a natural number $n$,
determine whether there is an $n$-bit string satisfying $p$?''
Showing that this problem is bounded below by dexptime
and bounded above by np would prove that p and np are not equal.

The input is $(p,n)$.
The output is a bit.

If the problem is to be in ptime,
the length of the string representation of $p$
must be a polynomial of $n$.

Suppose there exists $k$ such that the length of the input is in $\Theta(n^k)$.

Let the input be $(k,p,n)$?

The following question is a generalization of the p vs np problem:
Given the same amount of resources (space and time),
what is the maximum ratio of the number of functions that NTMs can compute
to the number of functions than DTMs can compute?
Informally, what is the maximum speedup
that nondeterminism can give a TM?
The answer of this question will answer the p vs np question.

How do I prove that a problem doesn't have better algorithm than brute force?
I have to see the paper that proves something is dexptime-complete.
Pebble game problem? Kolaitis and Panttaja?
Does that a problem can only be brute-forced at best
depend on the model of computation?
Show that the existence of faster algorithm raises a contradiction?

Should I switch from DTM and NTM to ATM (alternating Turing machine)?
Should I abandon TMs and use pebble games instead?
How about Boolean circuits?

The following is a nondeterminstic algorithm that
builds the string that will satisfy such predicate.
\begin{enumerate}
\item Let the current string be empty.
\item Either skip this step,
or pick a bit and append it to the current string.
\item If the current string satisfies the predicate, halt.
\item Otherwise go to step 2.
\end{enumerate}
The running time of that algorithm is a function of the length
of the shortest string that satisfies the predicate.
Let $s~p$ be the length of the shortest string that satisfies the predicate $p$.
We have just shown that the problem is in $\NTIME(O(s(p)))$.

Now, if we can show that for that problem
there is no better deterministic algorithm than the exhaustive search
(that is if the problem is exptime-hard),
then we prove that P and NP are not equal.

The size of the search space of all deterministic algorithms
that run in $n$ steps is smaller than...
$\DTIME(2^{s(p)})$.

Can the algorithm use any information from
the string representation of the predicate?

Suppose that there is a deterministic algorithm that can
always find an answer in polynomial time.

How many satisfiable predicates are there?
Let $c(n)$ be the number of predicates that can be satisfied
by an input that is not longer than $n$ bits.
\begin{align}
    c(0) &= 2^{2^0} - 1 = 1
    \\
    c(1) &= 2^{2^0 + 2^1} - 1 = 7
    \\
    c(2) &= 2^{2^0 + 2^1 + 2^2} - 1 = 127
    \\
    c(3) &= 2^{2^0 + 2^1 + 2^2 + 2^3} - 1 = 32,767
    \\
    c(n) &= 2^{2^{n+1}-1} - 1
\end{align}

I use the term \emph{$n$-least predicate} to mean that the predicate
can be satisfied by a string that is no longer than $n$ bits.

There exists an $n$-least predicate.

If two predicates differ, then their encodings will also differ.

A predicate can be encoded as a base-2 representation real number
between 0 inclusive and 1 exclusive.
The uncountability of real number implies that there is no algorithm
for determining whether any arbitrary predicate is satisfiable.

However, a predicate can also be encoded as a natural number
(by G\"odel numbering for example).
Natural numbers are countable.

\section{Introduction}

Roughly speaking, we say that a function is \emph{computable} or \emph{recursive}
if and only if it can be stated as a finite arrangement
of certain primitive operations we allow.

For example, if we only allow the constant function,
then the machine will either accept all input or reject all input.

\section{First attempt}

A \emph{recursive predicate} is a function having type $\mathbb N \to \{0,1\}$.
There is a bijection between $\{0,1\}^*$ and $\mathbb N$
so every function having type $\{0,1\}^* \to \{0,1\}$ can also be considPred{a} recursive predicate.
We say that $x$ \emph{satisfies} $p$ iff $px = 1$.
We say that $p$ is \emph{satisfiable} iff there exists $x$ that satisfies $p$.

The \emph{$p$-satisfaction problem}
and asks for the smallest $x$ that satisfies a given predicate $p$.
A related decision problem is the \emph{$p$-satisfiability problem} that
asks whether a given predicate $p$ is satisfiable.
This satisfiability problem allows us to show that $\PTIME \neq \NPTIME$
by constructing a satisfiable recursive predicate
$p$ in $\DTIME(\Theta n)$ such that
the corresponding $p$-satisfiability is in both $\NTIME(On)$ and $\DTIME(\Omega 2^n)$
where $n$ is the length of the shortest string that satisfies $p$.

An \emph{alphabet} is a finite countable non-empty set.

Many things can be \emph{recursive} or \emph{computable}: sets, functions, languages.

Blum \cite{Blum1967} defined a machine-independent complexity measure?
Blum speedup theorem implies $\EXPTIME = \PTIME$?

Rabin \cite{Rabin1977}?

Chow \cite{Chow1976} introduces the theory concisely.

Who? shows that partial computable functions are isomorphic to natural numbers.
This allows category theory to be used on computability theory.
An algorithm is a natural number.
An algorithm for simulating an algorithm: $\mathbb N \to \mathbb N$.
G\"odel numbering of partial recursive functions.
Formal systems.
Relates completeness, consistency, computability, decidability.

We use typed lambda calculus as our model of computation.

Informally, we construct a function $f$ such that $f$ is easy but $\SDP f$ is hard
such that there is no faster deterministic algorithm
than trying every possible subsequence.
A list of length $n$ has at most $2^n$ subsequences.

There is a bijection between $X^*$ and $\mathbb N$.
the empty string, 0, 1, 00, 01, 10, 11, 000, 001, 010, 011, 100, 101, 110, 111
\begin{align}
    \varphi [] &= 0
  \\ \varphi x &= \sum_{k=0}^{\mu x - 1} 2^k + \sum_{k=0}^{\mu x - 1} x_k \cdot 2^k
            \\ &= 2^{\mu x} - 1 + \sum_{k=0}^{\mu x - 1} x_k \cdot 2^k
\end{align}

Time hierarchy theorem?

The deterministic algorithm can use iterative deepening depth-first search:
\begin{align}
    sf &= \text{any $($map $f$ $\xi)$}
    \\
    \xi &= \text{fix} n []
    \\
    nx &= \text{map} (0:) x ++ \text{map} (1:) x
    \\
\end{align}
The nondeterministic algorithm:
\begin{align}
    sf &= gf[]
    \\
    gfx &= fx \vee \ambc (gf(0:x)) (gf(1:x))
\end{align}

\section{Graph theory}

We can see the tuple $(C,f)$ as a \emph{directed graph}
where each configuration is a vertex in the graph
and there is an edge from $x$ to $y$ if and only if $f(x) = y$.
An \emph{initial configuration} is a possible configuration from which the machine starts computing.
An initial configuration contains an input for the algorithm running on the machine.
A deterministic machine always starts computing from an initial configuration
and always either goes into infinite cycle or ends at terminal configuration.

\paragraph{Termination}
A configuration $x$ is \emph{terminal} iff
there is no $y$ such that $(x,y) \in f$.
A vertex is terminal iff its out-degree is zero.

A configuration $x$ \emph{eventually terminates}
iff there exists $n$ such that $f^n(x)$ is terminal.
Such configuration $x$ eventually terminates iff repeated application of $f$ to $x$
eventually produces a terminal configuration.
In the graph, such configuration $x$ eventually terminates iff
there is a path from $x$ to a terminal configuration.

\paragraph{Computation}
A \emph{computation} is a path in the graph.
More precisely, a computation from $x_0$ to $x_{n-1}$
is a path $[x_0, x_1, \ldots, x_{n-1}]$
such that $x_{k+1} = \beta x_k$ for each natural number $k$ from $0$ to $n-1$.
We can see by induction that $x_k = \beta^k x_0$ for each natural number $k$ from $0$ to $n-1$.

A \emph{complete computation} is a computation that begins at an initial configuration
and ends at a terminal configuration.
Subcomputation is to computation as subpath is to path.
The graph can be seen as a set of complete computations.

We say that the deterministic machine $D = (I,\beta)$ \emph{computes} a function
$f : A \to B$
that is isomorphic to
$f_N : \mathbb{N} \to \mathbb{N}$
that is in turn also isomorphic to
$f_D : I \to T$
where $T$ is the set of all terminal configurations of the machine
where $f_D$ is defined as the following function:
\begin{equation}
    f_D = \{ (x,y) \,|\, x \in C \,\wedge\, x \text{ eventually terminates at } y \}
\end{equation}
Formally we say $f_D x = y$ iff there exists
a natural number $n$ such that $\beta^n x = y$ and $y$ is terminal.
The functions $p$ and $q$ are the \emph{input encoding} function
and the \emph{output encoding} function.
If we ignore the time used by the machine,
we can see the machine as a function from $I$ to $T$.
$q \circ f = f_D \circ p$.

State every natural number $n$ as the sum of $p$ and $q$
where $p$ is the biggest prime less than $n$.

The encoding and decoding functions allow us to make
a distinction between a natural number
and the binary representation of natural number.

\section{A universal machine to simulate other machines?}

\[
    \UDMach{c} = \DMach{(\Pair{(\Fun{c}{c})}{c})}
\]

Machine or algorithm can be encoded as string.
\emph{Universal machines} simulate every machine.
A program corresponds to a \emph{partial computable function}.
Partial is not total.
Total function is a function defined for each element in its domain.
Partial function is a function that can be undefined for any number of elements in its domain.

The \emph{$c$-universal machine} of type $\UDMach{c}$ can compute every inhabitant of $\DMach{c}$.
The configuration type of the universal machine is $\Pair{(\Fun{c}{c})}{c}$.
\[
    I_u = \{ (\beta,x) \,|\, (I,\beta) : \DMach c \,\wedge\, x \in I \}
\]
Can a universal machine simulate all universal machines?
Let $t = (\Fun{c}{c},c)$.
Is $|t| = |(\Fun{t}{t},t)|$?
If and only if yes, then a universal machine can simulate all universal machines.

A universal deterministic machine is $U = (C_u, I_u, \beta_u)$
where the universal configuration set is $C_u = (C \to C, C)$.
A configuration of that universal machine is a tuple $(\beta, x)$.
This machine can compute everything every other machine can compute.
The universal machine transitions from $(\beta, x)$ to $(\beta, y)$
if and only if the simulated machine transitions from $x$ to $y$.
Let $u$ be the pairing function, that is $uab = (a,b)$.
Then
\begin{equation}
    u \beta \circ \beta = \beta_u \circ u \beta
\end{equation}
The universal transition function $\beta_u$ can be seen as a set:
\begin{equation}
    \beta_u = \{ ((\beta,x), (\beta,y)) \,|\, (x,y) \in \beta \}
\end{equation}
The inverse of the partially applied pairing function $u a$ is $r$
where $r (a,b) = b$.

\section{Recursive Function over Bitstrings}

Every inhabitant of $\Bit \to \Bit$ is recursive.

Every inhabitant of $\Bit \to \Bit \to \Bit$ is recursive.

For all $a$, the \emph{head} function $f [x 0, x 1, \ldots] = x 0$,
where $f : \List{a} \to a$, is recursive.

For all $a$, the \emph{tail} function $f [x 0, x 1, \ldots] = [x 1, \ldots]$,
where $f : \List{a} \to \List{a}$, is recursive.

Every well-formed well-typed lambda expression
that involves only recursive functions is recursive?

\section{Nondeterminism from two deterministic machines}

The author got the idea of defining a nondeterministic machine
using two deterministic transition functions
from Arora and Barak \cite[p.~40]{Arora2009}.
We can form a nondeterministic machine $N$
from two deterministic machines $D_0 = (C,I,\beta_0)$ and $D_1 = (C,I,\beta_1)$
(both machines must have the same configuration set and the same initial configuration set)
as follows:
\begin{enumerate}
    \item The sets of initial configurations are the same.
    \item If $x$ is a configuration of $D_0$ then $(0,x)$ is also a configuration of $N$.
    \item If $x$ is a configuration of $D_1$ then $(1,x)$ is also a configuration of $N$.
    \item Nothing else is a configuration of $N$.
    \item $\beta = P 0 \beta_0 \cup P 1 \beta_1$ where $P c X = \{ (c,x) \,|\, x \in X \}$.
    \item $x$ is $\beta$-terminal iff $x$ is $\beta_0$-terminal or $\beta_1$-terminal or both.
    \item Nothing else is $\beta$-terminal.
\end{enumerate}

Sum types: $\Either{a}{b} = \Left a | \Right b$.
Iff $x : a$ then $\Left x : \Either{a}{b}$.
Iff $y : b$ then $\Right y : \Either{a}{b}$.
The configuration type is $\Either{c_0}{c_1}$.
\[
    I =
    \{ \Left x \,|\, x \in I_0 \}
    \cup
    \{ \Right x \,|\, x \in I_1 \}
\]
\begin{align*}
    (\Left x, \Left y) \in \beta \iff (x,y) \in \beta_0
    \\
    (\Right x, \Right y) \in \beta \iff (x,y) \in \beta_1
\end{align*}

$\NMach c$.
$\beta : \Relab{c}{c}$.
Does $\Fun{c}{c} < \Relab{c}{c}$ strictly?

We can also form a deterministic machine $D$ from a nondeterministic machine $N$.

A machine computes a function $f : X \to Y$ as follows:
For each $x$ such that $f x$ is defined, the string $\hat x$ (the string encoding of $x$)
is an initial configuration of the machine.
For each $y = fx$, the configuration $\hat y$ (the configuration encoding of $y$)
is a terminal configuration of the machine.
There is a path from $\hat x$ to $\hat y$.
There is a machine that computes this $f$ in unit time: the oracle of $f$.
Then there is another machine that computes it asymptotically slower.
Then there is another machine that computes it even slower asymptotically.
This goes on and on.
We can always invent a slower machine.

\begin{enumerate}
    \item
        Every configuration of $N$ can branch to \emph{at most two} configurations.
        Formally for each configuration set $X$, it holds that $\mu(B X) \le 2 \cdot \mu X$
        where $\mu X$ is the size of $X$.
\end{enumerate}

$\NMach c$.

\section{Nondeterminism}

$N = (I,\beta) : \NMach c$
where $I : \Set{c}$ and $\beta : \Relab{c}{c}$.

Let $N$ be a nondeterministic machine $(C,I,\beta)$ where
Let $\beta \subseteq C \times C$ is the transition relation of $N$.
The tuple $(C,\beta)$ forms a graph.
There is an edge from $x$ to $y$ iff $(x,y)$ is in $\beta$.
with the following properties:
\begin{align}
    B^n X &= \{ (x,y) \,|\, x \in X \wedge (x,y) \in \beta^n \}
\end{align}
where $B X$ means $B^1 X$.

The relation $\beta$ can also be seen as an equivalent function $B : \powerset C \to \powerset C$
where $\powerset C$ is the power set of $C$.
Thus for every nondeterministic machine $(C, I, \beta)$
there is a deterministic machine $(\powerset C, \powerset I, B)$
that computes the same function at the same time.
But this deterministic machine is not countable.
Contradiction.
So nondeterminism bestows some power that deterministic machines cannot have.
There exists nondeterministic machine that cannot be simulated in equal time by deterministic machine.
(Is this a jump in logic? This seems wrong.)

But every deterministic machine can simulate
every nondeterministic machine by using breadth-first search.
So nondeterminism does not add any power?

Every deterministic machine is trivially a
nondeterministic machine since every transition function is a transition relation.

Is the set of functions computable by the nondeterministic machines
the same as that of deterministic machines?
Does it add any power?

\section{Uncomputable functions}

Each machine has infinitely many functions that it \emph{cannot compute}.
We prove this by diagonalization.
Suppose that the set of functions computable by a machine is $F = \{ f_0, f_1, f_2, \ldots \}$.
Suppose also that there is no function outside that set.
Alas, we can define a function $f$
such that $f0 \neq f_0 0$, $f1 \neq f_1 1$, $f2 \neq f_2 2$, and so on
such that $fn \neq f_n n$ for each natural number $n$.
This $f$ is not equal to any function in $F$ so it cannot be in that set.
Contradiction.

Nondeterministic machine is a $\sigma$-algebra of deterministic machine?
Can we relate nondeterminism to topology?

We can make it a topological space?
Nondeterministic reversible computation?
Remember that a configuration of a nondeterministic machine is a set.
Allow the no-computation: for each configuration $x$, make $x \in N x$.
Then make it reversible:
if $y \in N x$ then $x \in N y$.
Then make each subset of $B x$ to be in $N x$.
We can $(C,N)$ where $C$ is the set of all configurations of the machine
and $N : C \to 2^C$ is the neighborhood function.

Ullman? Sipser? defines NTM as DTM with transition relation instead of transition function.

We define $\beta^n$ as a composition of $n$ instances of $\beta$:
$\beta^0 = \text{id}$ and $\beta^1 = \beta$ and $\beta^n = \beta \circ \beta^{n-1}$.
The time complexity of a computation $x$
is the smallest $n$ such that $\beta^{n+1} x = \beta^n x$.

\section{Major theme in computability theory}

The idea is to encode almost \emph{everything}
(machines, algorithms, configurations, computations, numbers, graphs, you name it)
as a \emph{string} and then establish a bijection between strings and natural numbers.

Time-limited simulation of another machine:
simulate the machine as long as the number of steps do not exceed $f n$.
If the number of step exceeds $f n$ and the machine still does not terminate,
output $0$.
Truncated language?

A particular kind of machine called the \emph{recursive machines}
is equivalent to Turing machines with polynomial-time speedup/slowdown.

For each machine with transition function $t$ there exists another machine
with transition function $t' = t^p$
providing polynomial speedup.
Space usage of configuration $x$.
Length of program plus length of input.

\section{Differential topology and computation?}

A configuration is a point.

The transition function.

Unit step is in differential time?

What are we trying to say?

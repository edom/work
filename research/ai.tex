\chapter{Artificial intelligence}

(Summarize \cite{LiangCs221}. Shuffle around later.)

A
\index{model}%
\emph{model} is a constrained optimization problem:
Given \(C\),
compute \(\min_{x \in C} f(x)\) or \(\argmin_{x \in C} f(x)\).
If \(C\) is discrete, use dynamic programming.
If \(C\) is continuous, use gradient descent.

Let \(a\) be the input type, \(b\) be the output type, and \(g : a \to b\).
A
\index{predictor}%
\emph{predictor} is a function.
Iff \(b\) is finite, then \(f\) is a
\index{classifier}%
\emph{classifier}.
A
\index{feature}%
\emph{feature} inhabits \(a \to \Real\).
A
\index{data}%
\emph{data} or an
\index{example}%
\emph{example}
is a tuple \((x,y) : (a,b)\).

A
\index{linear predictor}%
\index{predictor!linear}%
\emph{linear predictor} is \(y = w \cdot f(x)\) where \(w\) is the weight vector,
\(f(x) = (f_1(x),\ldots,f_n(x))\) is the feature vector of \(x\),
\(f_k(x)\) is the \(k\)th feature,
\(x\) is the input,
and \(y\) is the predicted output.

A
\index{learner}%
\emph{learner} inhabits \([(a,b)] \to (a \to b)\).

A
\index{loss function}%
\emph{loss function} inhabits \((a,b,\Real^\infty) \to \Real\).

The
\index{training loss}%
\emph{training loss} of \(g(x) = w \cdot f(x)\) with respect to \(D\)
is \(\frac{1}{|D|} \sum_{(x,y) \in D} L(x,y,w)\)
where \(L\) is the loss function.

Learning is finding \(w\) that minimizes the training loss.

Let \(y \in \{-1,+1\}\).
The
\index{score}%
\emph{score} of \(f\) for \((x,y)\) is \(f(x)\).
The
\index{margin}%
\emph{margin} of \(f\) for \((x,y)\) is \(f(x) \cdot y\).

Binarization of \(f\) is \(\sgn \circ f\).

Least-squares linear regression

Minimize training loss

Gradient descent training with initial weight \(w_1\), iteration count \(T\), and step size \(\eta\):
Let \(K : \Real^n \to \Real\) be the training loss function.
Let \(\nabla K\) be the gradient of \(K\).
The weight update equation is \(w_{t+1} = w_t - \eta \cdot (\nabla K)(w_t)\)
where \(w_1\) may be random.
The training result is \(w_T\).

Stochastic gradient descent (SGD) training:
\(w_{t+1} = w_t - \eta \cdot (\nabla(L~x_t~y_t))(w_t)\).
Note the usage of the loss function \(L\)
instead of the training loss function \(K\).

SGD is \emph{online} or \emph{incremental} training.

\chapter{Computation}

\section{Unary algebra}

\index{unary algebra}%
A \emph{unary algebra} is \((S,f)\) where \(f : S \to S\).

% https://en.wikipedia.org/wiki/Distance_(graph_theory)

The natural graph of a unary algebra \((V,f)\) is \((V,E)\)
where \((a,b) \in E\) iff \(f(a) = b\).

The natural metric space of a connected undirected graph \((V,E)\) is \((V,d)\) where
\(d(a,b)\) is the length of the shortest path from \(a\) to \(b\).

\section{Fixed point}

Iff \(x = f(x)\) then \(x\) is a \emph{fixed point} of \(f\).

Let \(F\) be a set of some functions.
Let \(G(F)\) be the set of all functions that can be made by combining the functions in \(F\).

A recursive equation has the form \(f(x) = g(f,x)\).
For example, iff \(x^2 = x^4 + 1\) and \(f(x) = x^2\), then \(g(f,x) = x^4 + 1 = [f(x)]^2 + 1 = f(x^2) + 1 = x^4 + f(1)\)
and many more.

The \(y\)-combinator satisfies \(y(f) = f(y(f))\).

\section{String}

\index{language}%
A \emph{language} is a set of strings.

Two
\index{string}%
\emph{strings}
\(x\) and \(y\) can be
\index{string concatenation}%
\index{concatenation!string}%
\emph{concatenated} to \(xy\).

Two languages \(A\) and \(B\) can be
\index{language concatenation}%
\index{concatenation!of languages}%
\emph{concatenated} to
\(AB = \{ ab ~|~ a \in A, ~ b \in B \}\).

\index{alphabet}%
An \emph{alphabet} is a finite set where each element is a string of length one.

\paragraph{Kleene closure}
Let \(A\) be a language.
The
\index{Kleene closure}%
\index{Kleene operator}%
\index{Kleene star}%
\emph{Kleene closure}
of \(A\) is \(A^* = A^0 \cup AA^*\).
Another nonrecursive definition is
\( A^* = \bigcup_{n \in \Nat} A^n \)
where \( A^0 = \{\emptystr\} \),
\( A^{n+1} = A A^n \),
and \(\epsilon\) is the
\index{empty string}%
\index{string!empty}%
empty string.

\(A^*\) is the smallest superset of \(A\)
closed under string concatenation.

\section{Finite automaton}

% https://en.wikipedia.org/wiki/Automata_theory#Formal_definition

A
\index{finite automaton}%
\emph{finite automaton} is \(M = (Q,A,t,i,F)\) where
\(A\) is the alphabet,
\(t \subseteq Q \times A \times Q\) is the transition relation,
\(i \in Q\) is the initial state,
and \(F \subseteq Q\) is the set of accepting states.
Another name of finite automaton is
\index{state machine}%
\emph{state machine}.

\paragraph{Final-state function}
The \emph{final-state function} of \(M\) is \(f(w)\)
where \(f(pc) = t(f(p), c)\) and \(f(\emptystr)=i\).
Call \(f\) the \emph{final-state function} of \(M\).
The \emph{final state} of \(M\) for input \(w\) is \(f(w)\).
There is a bijection between DFAs and their final-state functions.

\(M\) \emph{accepts} \(w\) iff \(f(w) \in F\).

The \emph{language recognized by \(M\)} is \(\{ w ~|~ f(w) \in F \}\).

\section{Machine}

A \emph{machine} is \((S,f)\)
where \(S\) is the \emph{state set},
and \(f \subseteq S \times S\) is the \emph{transition relation}.
Iff \(f\) is a function, then the machine is \emph{deterministic}.
\(I = \{ a ~|~ a \in S, ~ (a,b) \not\in f \}\) is the \emph{initial state set}.

Such machine is also graph \((V,E)\) where \(V=S\), \(E = f\),
and \(I\) is the set of all \emph{source} vertices.
A source vertex is a vertex with zero indegree.
A sink vertex is a vertex with zero outdegree.

A machine \emph{is} a graph.

The \emph{fringe} of \(A\) is \(F(A) = \{ b ~|~ a \in A, ~ (a,b) \in E \}\).
Define: \(F^{n+1}(A) = F(F^n(A))\).
Property: \(F(\emptyset) = \emptyset\).
Property: \(F(A \cup B) = F(A) \cup F(B)\).
\(G\) \emph{accepts} \(v\) iff \(F^\infty(\{v\}) = \emptyset\).
The \emph{language} recognized by \(G\) is the largest \(L \subseteq V\) such that \(F^\infty(L) = \emptyset\).

A Turing machine is \((C,I,f)\)
where \(C\) is countable
and \(f\) is recursive.

Example: a state of a Turing machine is \((c,l,h,r)\)
where \(c\) is a configuration,
\(l\) is the tape content to the left of the head,
\(h\) is the tape content at the head,
and \(r\) is the tape content to the right of the head.

\section{Primitive by metric}

Iff \(d\) is a metric,
then \(f\) is \emph{\(d\)-primitive} iff \(d(x,f(x)) \le 1\).

Let \(P\) be a set of some \(d\)-primitive functions.
Let \(P^*\) be the set of all finite compositions of the functions in \(P\).

\paragraph{Example}
Let \(S\) be the set of all infinite \(\Nat\)-indexed \(E\)-arrays.
Let \(x,y \in S\).
The \emph{Hamming distance between \(x\) and \(y\)} is
\(d(x,y) = \sum_{k\in\Nat} [x_k \neq y_k]\).
The function \(f(x_0,x_1,\ldots) = f(0,x_1,\ldots)\) is \(d\)-primitive,
which in English means that this \(f\) does not change more than one element.

\section{Primitive by fiat}

Let \(AB = \{ ab ~|~ a \in A, ~ b \in B \}\)
where \(ab\) is string concatenation.

Let the \emph{instruction set} \(I\) be a finite set of atoms.

The set of all \(I\)-programs is \(I^*\).

Let the \emph{state set} be \(S\).
Let the \emph{primitive set} \(P\) be a finite set of \(S\)-endofunctions.
The set of all \emph{\(P\)-computable} functions is \(P^*\).
The set \(P^*\) contains every program that can be made from a finite composition of the functions in \(P\):
the function \(f\) is \(P\)-computable iff it is equal to a finite composition of functions in \(P^*\).

Let the \emph{execution function} \(f : I^* \to P^*\)
where
\(f(\emptystr) = id\),
\(f(ab) = f(a) \circ f(b)\),
and that \(x \in I\) implies \(f(x) \in P\).
The set of all \emph{\(I\)-describable} functions are \(\{ f(x) ~|~ x \in I^* \}\).

Let \(S = \Nat^\infty\).
Example:
Infinite-stack machine:
\begin{align*}
    swap(a,b,c,\ldots) = (b,a,c,\ldots)
    \\
    dup(a,b,\ldots) = (a,a,b,\ldots)
    \\
    push(a,b,\ldots) = (0,a,b,\ldots)
    \\
    pop(a,b,c,\ldots) = (b,c,\ldots)
    \\
    read(k,x_0,x_1,\ldots) = (x_k,x_0,x_1,\ldots)
    \\
    write(k,v,x_0,x_1,\ldots) = (k,v,x_0,x_1,\ldots,x_{k-1},v,x_{k+1},\ldots)
    \\
    if(0,f,t,a,\ldots) = (f,a,\ldots)
    \\
    if(1,f,t,a,\ldots) = (t,a,\ldots)
    \\
    inc(a,b,\ldots) = (a+1,b,\ldots)
    \\
    dec(a,b,\ldots) = (a-1,b,\ldots)
    \\
    add(a,b,c,\ldots) = (a+b,c,\ldots)
\end{align*}

\section{Machine (old)}

A machine that can only change one cell at a time.
A machine is
\((P, f)\)
where \(P = (S,A^\infty)\)
and
\(d(x,f(x)) \le 1\)
for all \(x : P\).
The state set \(S\) is finite.
The alphabet \(A\) is finite.
Define the distance between two phases as
\begin{align}
    d~(s,x)~(t,y) = \sum_{k : \Nat} ~ [x_k \neq y_k].
\end{align}
It ignores the state.
It only cares about the memory.

But unlike Turing machines, this machine cannot approach an infinite number of 1s...

The machine is free to change its state as long as it only changes at most one cell at a time.
If we remove the restriction, we get a nondeterministic machine,
or even an oracle.

If \(S\) has exactly \(n\) elements,
we can encode \(f : S \to A\) as \(g : A^n\)
where \(f~s_k = g_k\) where \(g = (f~s_1, \ldots, f~s_n)\).

\section{Machine (older)}

The transition function depends on the set of primitive operations of the machine.
Seen the other way around, this transition function
determines the set of primitive operations of the machine.

A machine is an embodiment of an algorithm.

A machine performs computation by repeatedly
making a transition from its current configuration
according to its transition function
until it reaches a terminal configuration.

A \emph{primitive operation} maps a configuration to a configuration.
Every primitive operation represents a computation that the machine can do in one unit time.
An \emph{architecture} is a set of primitive operations
and a set of rules for evaluating expressions built using those primitive operations.
A \emph{machine} is an architecture and a configuration representing its current state.

\section{Turing machine}

A \emph{Turing machine} is a finite-state machine with read-write memory.
How do we model finite-state machine?
How do we model read-write memory?

Let \(m\) be a Turing machine.

Let \(A\) be the alphabet.
It is finite.

Let \(S\) be the state type.
It is finite.

Let \(P = (S,T)\) be the phase type.

Let \(T = (A^\infty,A,A^\infty)\) be the tape type.

Define the \emph{phase} of \(m\) as \((s,t)\)
where \(s\) is the \emph{state} and \(t\) is the \emph{tape}.

A tape is \((L,h,R) : (A^\infty,A,A^\infty)\).

Define the transition function \(\after : P \to P\).

The pluggable parts of the machine are
the alphabet type \(A\),
the state type \(S\),
the next-state function \(\jump : (S,A) \to S\),
the output-symbol function \(\fwrite : (S,A) \to A\),
and the direction function \(\dir : (S,A) \to \{0,1\}\).
The \(\jump\) computes the next state.
The \(\fwrite\) function computes the symbol to write.
The \(\dir\) function computes where the head should move after writing that symbol.

The tape is \((L,h,R)\).
The string \(L\) is the \emph{reverse} of the string on the left of the head.
The symbol \(h\) is the symbol at the head.
The string \(R\) is the string on the right of the head.

Here comes an equational description of a Turing machine.
For readability, we don't use the minimum number of equations.

\section{The fixed parts}

A Turing machine must satisfy all of these.
These are the parts we cannot change.

The types.
\begin{align}
    P &= (S,T)
    \\
    T &= (\InfList~A, ~ A, ~ \InfList~A)
    \\
    \after &: P \to P
\end{align}

The logical constraints.
\begin{align}
    S &\text{ is finite}
    \\
    A &\text{ is finite}
\end{align}

The value definitions:
\begin{align}
    \after~(s,t) &= (s',t')
    \\
    t &= (L,h,R)
    \\
    s' &= \jump~i
    \\
    t' &= \dir~\stay~\fleft~\fright~i~(L,w,R)
    \\
    i &= (s,h)
    \\
    w &= \foutput~i
    \\
    \stay~(L,h,R) &= (L,h,R)
    \\
    \fleft~(cL,h,R) &= (L,c,hR)
    \\
    \fright~(L,h,cR) &= (hL,c,R)
\end{align}

We try to avoid pattern matching:
\begin{align}
    t' &= (L',h',R')
    \\
    w &= \foutput~i
    \\
    L' &= \dir~\stay_0~\fleft_0~\fright_0~L
    \\
    h' &= \dir~\stay_1~\fleft_1~\fright_1~L~w~R
    \\
    R' &= \dir~\stay_2~\fleft_2~\fright_2~R
    \\
    \stay~(L,h,R) &= (L,h,R)
    \\
    \fleft~(L,h,R) &= (\tail~L, \head~L, \cons~h~R)
    \\
    \fright~(L,h,R) &= (\cons~h~L, \head~R, \tail~R)
    \\
    \stay_0~L &= L
    \\
    \fleft_0~L &= \tail~L
    \\
    \fright_0~L &= \cons~L
    \\
    \stay_1~h &= h
    \\
    \fleft_1~L &= \head~L
    \\
    \fright_1~R &= \head~R
    \\
    \stay_2~R &= R
    \\
    \fleft_2~R &= \cons~R
    \\
    \fright_2~R &= \tail~R
    \\
    \stay_0 &= \stay_2
    \\
    \fleft_0 &= \fright_2
    \\
    \fright_0 &= \fleft_2
    \\
    \fleft_1 &= \fright_1
\end{align}

Some note about the notations:
We write \(A^\infty\) for the set of all infinite strings of \(A\).

\section{The pluggable parts}

There are the parts we can change.
\begin{align}
    s_0 &= \text{the initial state}
    \\
    S &= \text{the set of states}
    \\
    A &= \text{the set of symbols}
    \\
    \jump &= \text{a function of type \((S,A) \to S\)}
    \\
    \foutput &= \text{a function of type \((S,A) \to A\)}
    \\
    \dir &= \text{a function of type \(\forall a ~.~ a \to a \to a \to (S,A) \to a\)}
\end{align}

If you have the pluggable parts,
the equations will give you a Turing machine.

\section{Some definitions}

The input is the initial phase.

Let \(x = (s,t)\).
We say that \(x\) is an \emph{initial} phase iff \(s = s_0\).
We say that \(x\) is a \emph{halting} phase iff \(\after~x = x\).

The \emph{phase graph} is defined as follows.
Its vertex set is the set of all phases.
An edge \((x,y)\) is in the graph iff \(\after~x = y\).

We say that \(x\) \emph{eventually leads} to \(y\) iff
there is a path from \(x\) to \(y\) in the phase graph.

We say that the machine \emph{halts for input \(t\)} iff
\((s_0,t)\) eventually leads to a halting phase.

Let the alphabet be \(A = \{b,0,1\}\) where \(b\) is the blank symbol.
Let \(B = \ldots bbb \ldots\) be an infinite string of blank symbols.
We say that the machine \emph{accepts the input \(t\)} iff
the phase \((s_0,t)\) eventually leads to the phase \((s, (B,1,B))\)
where \(s\) can be any state.

\section{Turing machine as constrained unary algebra}

A Turing machine is a unary algebra with a limited transition function.
It can only read and write at the head.

We can encode an infinite stream of \(a\)
as the infinite type \(S~a = (a \to b) \to (S~a \to b) \to b\).

\emph{A Turing machine is a finite state machine with memory.}

A finite state machine has input, but no memory.

We can encode memory as infinite feedforward.

A finite state machine step function is a function \((S,I) \to (S,O)\).

\section{Logical formulation of Turing machine}

We can encode a function \(f : A \to B\) as a predicate \(f' : A \to B \to Bool\) such that \(f'~a~b\) iff \(f~a = b\).

If you have the predicates \(\jump\), \(\fwrite\), \(\stay\), \(\fleft\), and \(\fright\),
and an initial state and initial tape,
then the Turing machine generator will give you the following inference rules.
You can rewrite the rules in Prolog.
Prolog will then simulate that Turing machine.
\begin{align}
    \inferrule
    {\fwrite~s~h~w \\ \stay~s~h}
    {\tape~s~(L,h,R)~(L,w,R)}
    \\
    \inferrule
    {\cons~h'~L'~L \\ \cons~w~R~R' \\ \fwrite~s~h~w \\ \fleft~s~h}
    {\tape~s~(L,h,R)~(L',h',R')}
    \\
    \inferrule
    {\cons~w~L~L' \\ \cons~h'~R'~R \\ \fwrite~s~h~w \\ \fright~s~h}
    {\tape~s~(L,h,R)~(L',h',R')}
    \\
    \inferrule
    {\jump~s~h~s' \\ \tape~s~(L,h,R)~(L',h',R')}
    {\phase~(s,(L,h,R))~(s',(L',h',R'))}
\end{align}

The computation path beginning from \(p\).
\begin{align}
    \inferrule
    {\phase~p~q \\ p \neq q \\ \fpath~q~r \\ \cons~p~r~r'}
    {\fpath~p~r'}
    \\
    \inferrule
    {\halting~p}
    {\fpath~p~[p]}
\end{align}

\begin{align}
    \halting~x &\equiv \phase~x~x
\end{align}

\begin{align}
    \inferrule
    {\forall s ~ \forall h ~ | \{ w ~|~ \fwrite~s~h~w \} | \le 1 \\ \forall s ~ \forall h ~ |[\stay~s~h] + [\fleft~s~h] + [\fright~s~h]| \le 1}
    {\text{the machine is deterministic}}
\end{align}

\section{What}

Turing machine as mono-unary algebra of states (configuration-tape pairs)

Universal Turing machine

Lambda calculus

Recursive functions

\section{Regex, cfg, Brzozowsky}

If \(a\) is a type, then \(\Regex~a\) is a type.
Usually we call the \(a\) in \(\Regex~a\) the \emph{alphabet}.

\begin{align}
    &\vdash \fnull : \Regex~a
    \\
    &\vdash \fempty : \Regex~a
    \\
    x : a &\vdash x : \Regex~a
    \\
    x : \Regex~a, ~ y : \Regex~a &\vdash xy : \Regex~a
    \\
    x : \Regex~a, ~ y : \Regex~a &\vdash x|y : \Regex~a
    \\
    x : \Regex~a &\vdash x^* : \Regex~a
\end{align}

Sometimes we parenthesize. The expression \(x|y^*\) means \(x|(y^*)\),
which is different from \((x|y)^*\).

Let there be a function \(\match : \Regex~a \to \List~a \to \Bool\).
\begin{align}
    \match~\fnull~x &\vdash
    \\
    &\vdash \match~\fempty~[]
    \\
    x : a, ~ y = [x] &\vdash \match~x~y
    \\
    \match~r~x, ~ \match~s~y &\vdash \match~(rs)~(xy)
    \\
    \match~r~x \vee \match~s~x &\vdash \match~(r|s)~x
    \\
    &\vdash \match~r^*~[]
    \\
    \match~r~x, \match~(r^*)~y &\vdash \match~(r^*)~(xy)
\end{align}

Recall that a language is a \emph{set} of strings.
We define multiplication slightly differently.
We replace ordered pair with string concatenation:
\begin{align}
    Q \times D &= \{ qd ~|~ q : Q, ~ d : D \}.
\end{align}

\section{Laziness}

Complete laziness, full laziness, interaction sets

Compile Java to lambda calculus

High level intermediate language

\section{Descriptive complexity}

% https://en.wikipedia.org/wiki/Fagin%27s_theorem
Fagin's theorem:
There is a bijection between second-order logic predicates and NP problems. (?)

See Neil Immerman's book. (?)

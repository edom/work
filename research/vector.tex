\chapter{Vector}

\section{Vector space}

\index{vector!concatenation}%
\index{concatenation!vector}%
\index{vector concatenation}%
Define the \emph{vector concatenation} of \(a : \Real^m\) and \(b : \Real^n\)
as \(a|b : \Real^p\)
where \(p = m + n\),
\(a|b = (a_1 , \ldots , a_m , b_1 , \ldots , b_n)\),
and a scalar is treated as a vector of length 1.

\index{vector!column}%
\index{column vector}%
A \emph{column vector} of length \(n\) is a \(n \times 1\) matrix.

\index{vector space}%
\index{space!vector}%
A \emph{vector space} is a set and some vector operations...
\index{vector}%
A \emph{vector} is an element of a vector space.

\index{vectors!orthogonal}%
\index{orthogonal vectors}%
Two vectors \(x\) and \(y\) are \emph{orthogonal} iff \(x \cdot y = 0\).
\index{vectors!parallel}%
\index{parallel vectors}%
Two vectors \(x\) and \(y\) are \emph{parallel} iff \(x \cdot y = \norm{x} \cdot \norm{y}\).

\index{dot product}%
\index{vectors!dot product}%
Relationship between length and dot product: \(\norm{x}^2 = x \cdot x\).
Dot product distributes addition: \(x \cdot (y+z) = x \cdot y + x \cdot z\).
Geometric interpretation of dot product: \(a \cdot b = \norm{a} \cdot \norm{b} \cdot \cos \theta\).

\index{unit vector}%
\index{vectors!unit}%
A \emph{unit vector} is a vector whose length is 1.

\index{vector projection}%
\index{vectors!projection}%
\index{projection!of a vector to another vector}%
The \emph{projection} of \(a\) to \(b\) is \((a \cdot b) \cdot b / |b|^2\).

\section{Matrix}

\index{scalar-matrix multiplication}%
\emph{Scalar-matrix multiplication} is \((ka)_{ij} = k \cdot a_{ij}\).
\index{matrix addition}%
\index{addition!matrix}%
\index{matrix!addition}%
\emph{Matrix addition} is \((a + b)_{ij} = a_{ij} + b_{ij}\).
\index{matrix multiplication}%
\index{multiplication!matrix}%
\index{matrix!multiplication}%
\emph{Matrix multiplication} is \((ab)_{ij} = \sum_{k=1}^n a_{ik} b_{kj}\) where
\(a : R^{m \times n}, b : R^{n \times p}, c : R^{m \times p}\).

\index{coefficient matrix}%
\index{matrix!coefficient}%
\index{system of linear equations}%
\index{unknown}%
A \emph{system of linear equations} is a matrix equation \(A x = b\)
where \(A\) is the \emph{coefficient matrix} and \(x\) is the \emph{unknown}.
\index{overdetermined system of linear equations}%
\index{system of linear equations!overdetermined}%
That system is \emph{overdetermined} iff \(A\) has more rows than columns.

\section{Least-squares solution}

\index{least-squares!solution of an overdetermined system of linear equations}%
\index{system of linear equations!overdetermined!least-squares solution}%
\index{system of linear equations!least-squares solution}%
If \(A : R^{m \times n}\) and \(b : R^m\),
then the \emph{least-squares solution} of \(A x = b\)
is the \(y\) that minimizes \(\norm{A y - b}^2\).
\index{normal equation}%
That \(y\) is also the solution of the corresponding \emph{normal equation}
\((A^T A) y = A^T b\).

\section{Hyperplane}

\index{hyperplane}%
\index{hyperplane!below}%
\index{hyperplane!below-or-on}%
\index{hyperplane!on}%
\index{hyperplane!above}%
\index{hyperplane!above-or-on}%
A \emph{hyperplane}
\(h : \Real^\infty \to \Real\)
is \(h~x = n \cdot (x - p)\)
where \(n\) is the \emph{normal} of \(h\)
and \(p\) is a point on \(h\).
The point \(x\)
is \emph{below} \(h\) iff \( h~x < 0 \),
is \emph{below-or-on} \(h\) iff \( h~x \le 0 \),
is \emph{on} \(h\) iff \( h~x = 0 \),
is \emph{above} \(h\) iff \( h~x > 0 \),
and
is \emph{above-or-on} \(h\) iff \( h~x \ge 0 \).

\index{hyperplane equation!matrix form}%
\index{matrix form of hyperplane equation}%
The \emph{matrix form} of the hyperplane equation \(f~x = a \cdot x + b\)
is \(f~x = (a|b)^T (x|1)\).

The \emph{distance} of a point \(x\) to hyperplane \(h = n \cdot (x - p)\)
is the length of the projection of \(x-p\) to \(n\).

\section{Multivariate calculus}

\section{Vector calculus}

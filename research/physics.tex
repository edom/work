\chapter{Physics}

\section{Mechanics}

Newton's law:
\(F = dp\) where \(F(t)\) is force acting on the point mass at time \(t\)
and \(p(t)\) is the momentum of the point mass at time \(t\).

State space

Configuration space

Phase space

Hamiltonian mechanics

\section{Quantum mechanics}

\index{observable}%
An \emph{observable} is a linear self-adjoint operator on a Hilbert space.

\index{Schr\"odinger equation}%
The \emph{Schr\"odinger equation} is ...

\index{Maxwell's equations}%
Maxwell's equations are ...

\section{General relativity}

\index{tensor}%
A \emph{tensor} is ...

\index{Einstein field equations}%
Einstein field equations are ...

\section{Old content (geometry.md)}

The standard basis of $\mathbb{R}^3$
is $\{e_1,e_2,e_3\}$
where $e_1 = (1,0,0)$, $e_2 = (0,1,0)$, and $e_3 = (0,0,1)$,
which can also be written as the matrix
\[
\begin{bmatrix}e_1&e_2&e_3\end{bmatrix}
= \begin{bmatrix}1&0&0\\0&1&0\\0&0&1\end{bmatrix}
\]
where each basis vector becomes a column in the matrix.

A coordinate system transformation multiplies the basis with the transformation matrix.

Matrix arises naturally for describing linear transformations on a vector space.

Every linear endofunction of an $n$-dimensional vector space can be written as a vector of $n$ of inner products.

We can derive a basis for $V^*$ from a basis for $V$.
Let us write the basis for $V$ as \(E = \{ e_1, \ldots, e_n\}\).
We then define $G = \{ g_1, \ldots, g_n \}$ where \(g_k(x) = x \cdot e_k\).
If such $G$ also spans the entire $V^*$,
then $G$ is a basis for $V^*$,
and we call such $G$ the dual basis of $E$.

A more interesting thing happens when we operate a vector and a covector.
The product between a covector $f : V^*$ and vector $\vec{x} : V$
is simply $f~\vec{x}$ (function application)?

Now we can talk about changing basis.
A basis transformation is a coordinate system transformation,
and in this case this transformation has the type
$(\mathbb{R}^n \to \mathbb{R}^n) \to (\mathbb{R}^n \to \mathbb{R}^n)$.
Such basis transformation $E' = T~E$ can be written out
as $\vec{e}'_k = T_k~(\vec{e}_1, \ldots, \vec{e}_n)$,
which can be written out even more in the greatest detail as
\[
(\vec{e}'_k)_i = (T_k)_i~(\vec{e}_1, \ldots, \vec{e}_n)
\]
which are actually $n^2$ equations,
and each $(T_k)_i$ is a function that takes $n^2$ real numbers.
If the transformation is linear,
we can write the transformation as matrix multiplication:
\[
E' = ET
\]
which expands into $n$ equations each:
\[
\vec{e}_i' = \sum_{k=1}^n T_{ik} \vec{e}_k
\]
which, in turn, expands into $n$ equations again each:
\[
e_{ij}' = \sum_{k=1}^n T_{ik} \cdot e_{kj}
\]

Sometimes we want to use another basis to locate the same point.
That is, if we have a vector $x$ in basis $E$, and a vector $y$ in basis $TE$,
we want $Ex = TEy$.
We want to change the basis from $E$ to $TE$,
so old coordinate $x$ become $y$,
but we want $y$ in $TE$ such that $TEy$ is still $Ex$,
which we can state mathematically:
\begin{align*}
TEy &= Ex
\\ T^{-1}TEy &= T^{-1}Ex
\\ Ey &= T^{-1}Ex
\end{align*}
which says that the change of coordinate goes against the change of basis,
so we say that the vector $x$ is *contravariant* to the basis transformation $T$.
This means that if we move the origin of the coordinate system 3 units to the right,
then we will have to move the coordinates 3 units to the left
if we want the new coordinate to locate the same point.

What about covectors?
Covector $f$.
\[
f(TEy) = f(Ex)
\]
Due to the linearity of covectors:
\begin{align*}
f(Ex) &= f\left(\sum_i x_i \vec{e}_i\right) = \sum_i f(x_i \vec{e}_i)
\\ f(TEy) &= f\left(\sum_i y_i T\vec{e}_i \right) = \sum_i f(y_i T\vec{e}_i)
\\ \vec{e}'_k = \sum_i T_{ki} \vec{e}_i
\end{align*}

(todo show that covector is covariant)

* A linear function is multilinear.
* Otherwise a function is multilinear iff every partial application of it is also multilinear.

Now that we have covectors, we are ready to define tensors.

Metric tensor.

Differential geometry. Curvilinear coordinates. Space curvature.
How do you describe a (curved) surface?

As a linear map, a matrix is a vector of covectors.

\section{(old content)}

\section{Coordinate systems}

A \emph{coordinate system} $M : C \to S$ is a surjective mapping from
\emph{coordinate space} $C$ to \emph{target space} $S$.
A \emph{coordinate} is a point in \(C\).
The coordinate system tells us how to get to a point.

The \(n\)-dimensional real coordinate space is $\mathbb{R}^n$.
% https://en.wikipedia.org/wiki/Real_coordinate_space
It is also called the real $n$-space.
A point in the real $n$-space is an $n$-tuple of real numbers $(x_1,\ldots,x_n)$.

$(x,y)$ is the tuple of coordinates,
$x$ is the x-coordinate, and $y$ is the y-coordinate.

Coordinate systems unify geometry and
% https://en.wikipedia.org/wiki/Mathematical_analysis
mathematical analysis,
allowing geometric problems to be solved by
numbers, calculus, and algebra,
so that computers can
find the intersection of geometric objects
by solving the corresponding system of equations,
and find the size of a geometric object by solving the corresponding integral.

\section{Mappings inside real coordinate spaces}

We have shown that we can use a real $n$-tuple as a coordinate to the real $n$-space.
In other words, we can map the real $n$-space to itself.
The identity coordinate system for the real $n$-space is
$I : \mathbb{R}^n \to \mathbb{R}^n$ where $I(x) = x$;
this $I$ is also the standard basis for the real $n$-space.

We also call a vector space a linear space.

A physics-field fits the definition of a coordinate system.

There is another way to think of a coordinate in $\mathbb{R}^n$:
as a function $N \to \mathbb{R}$ where $N = \{1,2,3,\ldots,n\}$.
We can think of an $n$-dimensional $F$-vector as a function $N \to F$ where $N = \{1,2,3,\ldots,n\}$.
We can forget about dimensions and think of a $F$-vector as a function $\mathbb{N} \to F$.

We can also use vector spaces to talk conveniently about geometric objects.
With vector spaces, we can define a line by vector collinearity,
and define a plane by its normal vector.

Let there be two bases $J$ and $K$.
Let $T$ be coordinate transformation from $J$ to $K$
(that is $J~x = K~(T~x)$)
and $U$ be basis transformation from $J$ to $K$
(that is $K = U~J$).
\[
J~x = (U~J)~(T~x)
\]
\[
J = U \circ J \circ T
\]

Interesting things happen when we change the basis.
$T : E \to F$.

\section{Coordinate transformation}

Let's say we have one space $S$,
and two coordinate systems $J : M \to S$ and $K : N \to S$.
A coordinate transformation from $J$ to $K$ (we name this transformation $T : M \to N$)
transforms a $J$-coordinate
to an $K$-coordinate describing the same point.
This transformation relates both coordinate systems as
$J~x = K~(T~x)$, which means that if $x$ is a coordinate in $J$, then $T~x$ is a coordinate in $K$ locating the same point.
We can also write the equation as $J = K \circ T$.

To consider each component of the coordinate separately,
we write
$T~(x_1,\ldots,x_m) = (y_1,\ldots,y_n)$
where
\begin{align*}
y_1 &= t_1~(x_1,\ldots,x_m)
\\ &\vdots
\\ y_n &= t_n~(x_1,\ldots,x_m).
\end{align*}
Thus we can think of $T$ as an $n$-tuple $(t_1,\ldots,t_n)$
whose each component $t_k$ takes an $m$-tuple.
We can extend the definition of function application so that it works on tuples:
\[
(t_1,\ldots,t_n)~\vec{x} = (t_1~\vec{x}, \ldots, t_n~\vec{x})
\]
but why would we?

If we define that, we can see how a change in a tuple component translates
to a change in the other tuple component.
\[
\frac{\partial y_i}{\partial x_j} = pd~j~t_i
\]

A space mapping maps the underlying space $M : R \to S$.

Transformation.
Linear transformation.
$T(ax+by) = aTx + bTy$.

The transformation $T~x = 2\cdot x$ can be viewed as two things:
as a space transformation, it makes everything bigger;
as a coordinate transformation, it makes everything smaller.
Coordinate transformation works in reverse.
You can move the point, or you can change the coordinate.

Covariance.

Distance-preserving transformation.
$d~(T~x)~(T~y) = d~x~y$.

$T$-symmetry.
$f~(T~x) = T~(f~x)$?

Inverse transformation.
Composition of transformations.

\section{Coordinate system transformations}

A coordinate system is a mapping (which is another word for 'function'),
so a coordinate system transformation is a mapping that maps a mapping to another mapping;
we use the word 'transformation' (which is just another word for 'mapping') so that
we can write the more serious-sounding 'coordinate system transformation'
instead of the less awe-inspiring 'space mapping mapping',
although they mean the same thing.
Thus a coordinate system transformation
from $K : Q \to S$ to $L : R \to S$ will have the type
$(Q \to S) \to (R \to S)$.
You see, $Q$ is a space,
so each of $Q \to S$ and $R \to S$ is a space mapping,
and therefore $(Q \to S) \to (R \to S)$ is a space mapping mapping.

Let's say we have two spaces $R$ and $S$.
$T : R \to S$.

Embedding and projection are mappings between spaces.
Embedding maps a lower-dimensional space to a higher-dimensional space;
projection maps a higher-dimensional space to a lower-dimensional space.

\section{Physical fields}

Mathematics and physics use the same term ``field'' to mean different things.
% https://en.wikipedia.org/wiki/Field_(physics)

A physical field is a function $f : R \to S$.
Usually $R$ is a real coordinate space.
If $S$ is a vector, the field is a vector field.
If $S$ is a scalar, the field is a scalar field.

Both a field and a coordinate system are mappings between two spaces,
but a field does not have to be surjective.

\section{Coordinate transformations}

We can use several coordinate systems on the same space.
Some coordinate systems are more convenient to work with.
To specify a place on Earth, we can use the
geographic coordinate system (latitudes and longitudes).
% https://en.wikipedia.org/wiki/Geographic_coordinate_system
A coordinate transformation does not move the point.

If a coordinate system is a bijection,
then it describes an isomorphism between
its coordinate space and the space it describes.
This means we can pick any of them we find most convenient,
and whatever works with it will work with the other.

A point in a space can have different coordinates in different coordinate systems.
Both the Cartesian coordinate $(r\cos\theta, r\sin\theta)$ and the polar coordinate $(r,\theta)$
describe the same point in 2-dimensional Euclidean space.
\[
C_2~(r\cos\theta, r\sin\theta) = P~(r,\theta)
\]

\[
T~(r,\theta) = (r \cos \theta, r \sin \theta)
\]

\[
\frac{\partial x}{\partial r} = \cos \theta
\]

\section{Fixpoints of transformations}

We say that a point is a fixpoint (invariant)
of a transformation iff the transformation maps it to itself.
$f(x) = x$.
We can also say that $f$ is a fixtransform of $x$.

We can embed a plane on a sphere.

To describe an embedding,
we can use words, or we can use algebra:
we pick a coordinate system for each space,
and describe the embedding of the coordinates.
An embedding $E : R \to S$ is a mapping from a space $R$ to (a subset of) another space $S$.
Let $J : M \to R$ and $K : N \to S$ be coordinate systems for those spaces, respectively.
Let $T : M \to N$ be the coordinate transformation that corresponds to that embedding.
Let $x$ be a $J$-coordinate.
Then we have:
\[
K~(T~x) = E~(J~x)
\]
which can also be written
\[
K \circ T = E \circ J.
\]
Spherical coordinate system
use three: radius,: $(r,\theta,\phi)$. Here the radius is fixed so we can use $(\theta,\phi)$.

\section{Euclidean metrics}

The Euclidean metric for \(\Real^n\) is
\(
    d(x,y) = \sqrt{\sum_{k=1}^n (y_k-x_k)^2}
\).
It is the length of the shortest straight line segment from \(x\) to \(y\).

\section{Projective spaces}

To grasp projective space, see real projective space.

Descartes's Cartesian coordinate system.

Klein's erlangen program.

Using algebra, we can describe a circle whose radius is $r$
and whose center is the origin in a 2-dimensional Euclidean space with Cartesian coordinate system
as $\{C_2~(x,y) ~|~ x^2+y^2 = r^2\}$.
We can find the intersection of two geometric objects
by solving the system of their equations.

\section{Flavors of geometry: synthetic and analytic}

When asked "What is a line in a 2-dimensional Euclidean space?",
a student of
synthetic geometry
may answer "It is the infinite extension (in both direction)
of the shortest geometric object connecting two points,"
while a student of
analytic geometry
may answer
``It is $\{ (x,y) ~|~ ax+by=c \text{ where } a,b,c\in\Real \}$.''
% https://en.wikipedia.org/wiki/Synthetic_geometry
% https://en.wikipedia.org/wiki/Analytic_geometry
% http://en.wikipedia.org/wiki/Foundations_of_geometry
% http://en.wikipedia.org/wiki/Timeline_of_geometry
% https://en.wikipedia.org/wiki/Algebraic_geometry
Algebraic geometry studies the solution of equations.

Topology studies topological spaces.
Analytic geometry uses coordinates to define spaces,
while topology uses neighborhood to define spaces.

\section{Metrics}

With a metric, we can define
a (generalized) circle with radius $r$ and center $c$
to be the set of points
$\{x ~|~ d~c~x = r \}$.

An astronomer may need to tell another astronomer where the latter can find a celestial body.
He can give its coordinates in a coordinate system they have agreed on.
The astronomer can use a celestial coordinate system.
% https://en.wikipedia.org/wiki/Celestial_coordinate_system

\section{The basic idea of abstract geometry}

% https://en.wikipedia.org/wiki/Space_(mathematics)
We use a set to describe a space.
We don't distinguish a space and its description,
so 'space' *is* another word for 'set' (a collection),
and 'point' is another word for 'member' (something in that collection).

It is not only the spaces themselves that make geometry interesting,
but also the mapping (the functions) between spaces,
and the properties of those spaces,
and the way of building spaces from other spaces by changing properties.
After all, a space is just a set,
so if a space is all you want to know,
you can just study set theory instead of geometry.

There are many kinds of spaces we will talk about:

* algebraic structures (especially fields),
* coordinate space (a space of tuples),
* real coordinate space (a space of tuples of real numbers),
* vector space (a coordinate space with vector operations),
* inner product space (a space with an inner product),
* covector space (a space whose member is a covector, defined below).
* tensor space.

There are many ways to make a mapping between two spaces,
as we will see:

* phield (mapping between two spaces, usually from a coordinate space),
* coordinate system (surjective mapping between two spaces),
* natural vectorization of a ring (mapping from a ring to one of its natural vector spaces),
* basis (linear coordinate system for a vector space),
* covector (linear mapping from a vector space to its ring space),
* cobasis (basis for a covector space).

Then, we will eat our own tail by stating that all those mappings are members of their respective function spaces
(a function space is a space whose members are functions):

* coordinate system transformation (a mapping between two mappings),

\section{Irrelevant}

A linear function is $f(x+y) = f(x) + f(y)$.
A bilinear function \(f\) is left-linear and right-linear:
\(
f(x+z,y) = f(x,y) + f(z,y)
\)
and
\(
f(x,y+z) = f(x,y) + f(x,z)
\).

Define \(p(n,f,x)\):
$p(1,f,x) = f(x)$;
$p(n,f,x) = p(n-1,f,x)$???;
$p(n,f,x)$ means apply $x$ to the $n$th argument of $f$:
$p(2,f,x) = y \to f(y,x)$.
$p(3,f,x) = y z \to f(y,z,x)$.

A bilinear function $f$ is a function such that $p(1,f,x)$ is linear
and $p(2,f,x)$ is linear:

A multilinear function is
\[
f~(x + e) = f~(x) + f~(x + e)???
\]
